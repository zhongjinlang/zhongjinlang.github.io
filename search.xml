<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[第六篇:消息总线(Spring Cloud Bus)]]></title>
    <url>%2F2019%2F05%2F04%2Fspringcloud%2F%E6%B6%88%E6%81%AF%E6%80%BB%E7%BA%BF(Spring%20Cloud%20Bus)%2F</url>
    <content type="text"><![CDATA[引言基于上一篇章，我们实现了config-serve管理配置中心，config-client获取配置中心的配置。此时我们做如下实验: 修改GitHub上的配置文件 访问config-client会发现配置文件并没有立刻更新到工程，只有重启才会读取配置 那我们如果想在不重启微服务的情况下更新配置如何来实现呢? 我们使用SpringCloudBus来实现配置的自动更新 SpringCloudBusSpring Cloud Bus 将分布式的节点用轻量的消息代理连接起来。它可以用于广播配置文件的更改或者服务之间的通讯，也可以用于监控。本文要讲述的是用Spring Cloud Bus实现通知微服务架构的配置文件的更改 改造config-client基于上一篇章，修改其内容 添加依赖123456789&lt;!-- 消息总线 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-bus-amqp&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt; 可发现，需要使用rabbitMQ 添加配置 123456789101112131415161718 # 消息总线management: endpoints: web: exposure: include: bus-refresh # 消息总线 bus: enabled: true trace: enabled: true # mq rabbitmq: host: localhost port: 5672 username: guest password: guest 启动类 12345678910111213141516171819@SpringBootApplication@RestController// 实现高可用添加的@EnableEurekaClient@EnableDiscoveryClient@RefreshScope // 热加载配置public class ConfigClientApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ConfigClientApplication.class, args); &#125; @Value("$&#123;foo&#125;") private String foo; @RequestMapping(value = "/conf.do") public String hi()&#123; return foo; &#125;&#125; 依次启动eureka、config-serve、config-client:8881、8882启动两个，浏览器访问 http://localhost:8882/conf.do或8881，如图所示 此时我们更改GitHub中的配置信息为 version 5，如果是安装传统做法(引言中所述)，需要重启服务，才能达到配置文件的更新。 发送 POST请求 http://localhost:8881/actuator/bus-refresh, 你会发现config-client会重新读取配置文件 再次访问已经获取到最新的配置文件信息 /actuator/bus-refresh接口可以指定服务，即使用”destination”参数，比如 “/actuator/bus-refresh?destination=customers:**” 即刷新服务名为customers的所有服务 上述不搭建小集群也可实现 总结 当git文件更改时，客户端发送POST请求给config-client，此时client通过MQ发送消息给消息总线，由消息总线向其他服务传递，从而使得整个服务达到更新配置]]></content>
      <categories>
        <category>springcloud</category>
      </categories>
      <tags>
        <tag>springcloudbus</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第五篇:分布式配置中心(Spring Cloud Config)]]></title>
    <url>%2F2019%2F05%2F03%2Fspringcloud%2F%E5%88%86%E5%B8%83%E5%BC%8F%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83(Spring%20Cloud%20Config)%2F</url>
    <content type="text"><![CDATA[引言在分布式系统中，由于服务数量巨多，为了方便服务配置文件统一管理，实时更新，所以需要分布式配置中心组件。在Spring Cloud中，有分布式配置中心组件spring cloud config ，它支持配置服务放在配置服务的内存中（即本地），也支持放在远程Git仓库中在spring cloud config 组件中，分两个角色，一是config server，二是config client Config Server是一个可横向扩展、集中式的配置服务器，它用于集中管理应用程序各个环境下的配置 Config Client是Config Server的客户端，用于操作存储在Config Server中的配置内容 搭建config-server本工程用于管理分布式配置文件 依赖POM如下 1234567891011&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 配置中心服务端--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 启动类加上@EnableConfigServer表示启动配置服务器功能 1234567@SpringBootApplication@EnableConfigServer // 开启配置服务器功能public class ConfigApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ConfigApplication.class, args); &#125;&#125; 配置 12345678910111213spring: application: name: config-server # 服务名 cloud: config: server: git: uri: https://github.com/zhongjinlang/SpringCloudConfig.git #配置git仓库地址 search-paths: respo #配置仓库路径 username: #git仓库用户名(公开不许添加) passphrase: #git仓库密码 label: master # 配置仓库分支 配置文件内容为路径如图所示 其中配置文件命名规则：前者为服务名称，后者为开发环境(测试 生产) 启动程序，浏览器访问 http://localhost:8888/config-client-dev.properties 可看到配置文件的内容 搭建config client 依赖POM文件如下 123456789101112&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 配置中心客户端--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 配置文件 bootstrap.yml会有’配置云端的图标’ 123456789101112server: port: 8881spring: application: name: config-client cloud: config: label: master # git分支 profile: dev # 开发环境配置文件(dev test pro) uri: http://localhost:8888/ # 配置中心服务地址 TODO: 如果配置中心配置了server的端口为8882，那么访问使用8882(客户端加载到的配置文件的配置项会覆盖本项目已有配置) 客户端的spring.application.name配置config-clent是和Git服务器上面的文件名相对应的，如果你的客户端是其他名字就报错找不到参数 测试获取配置中心的配置 123456789101112131415@SpringBootApplication@RestControllerpublic class ConfigClientApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ConfigClientApplication.class, args); &#125; @Value("$&#123;foo&#125;") private String foo; @RequestMapping(value = "/conf.do") public String hi()&#123; return foo; &#125;&#125; 可见，config-client已加载了配置中心的配置 高可用的分布式配置中心上述我们将的是: 一个服务如何从配置中心读取文件，配置中心如何从远程git读取配置文件，当服务实例很多时，都从配置中心读取文件，这时可以考虑将配置中心做成一个微服务，将其集群化，从而达到高可用 其实就是使用了eureka注册中心，并且使用feign来实现配置中心的负载均衡 改造config-server将配置中心服务进行发布 添加服务发现依赖 12345&lt;!-- 配置中心搭建高可用&gt; 服务发现依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt; 添加配置 1234eureka: client: service-url: defaultZone: http://localhost:8761/eureka/ 指定注册中心地址eureka-server 启动类123456789@SpringBootApplication@EnableConfigServer // 开启配置服务器功能@EnableEurekaClient // 消费者 高可用添加@EnableDiscoveryClient // 服务发现 高可用添加public class ConfigApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ConfigApplication.class, args); &#125;&#125; 改造config-client 一样将服务进行发布 12345&lt;!-- 高可用添加 服务发现依赖 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt; 配置 1234567891011121314151617181920212223server: port: 8881spring: application: name: config-client cloud: config: label: master # git分支 profile: dev # 开发环境配置文件 uri: http://localhost:8888/ # 配置中心服务地址 # 高可用添加： discovery: enabled: true # 读取注册中心的内容，从配置中心读取文件 service-id: config-server # 配置中心服务名# 高可用添加eureka: client: service-url: defaultZone: http://localhost:8761/eureka/ # 注册中心地址 实现高可用配置中心 启动类 12345678910111213141516171819@SpringBootApplication@RestController// 实现高可用添加的@EnableEurekaClient@EnableDiscoveryClient@RefreshScopepublic class ConfigClientApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ConfigClientApplication.class, args); &#125; @Value("$&#123;foo&#125;") private String foo; @RequestMapping(value = "/conf.do") public String hi()&#123; return foo; &#125;&#125; 依次启动eureka-serve、config-server、config-client，eureka注册中心管理界面如下 在读取配置文件不再写ip地址，而是服务名，这时如果配置服务部署多份，通过负载均衡，从而高可用 TODO: 这里并没有另外搭建一个配置中心服务，上述过程理解其原理即可 总结 在分布式环境中，为了方便管理配置文件，所以需要分布式配置中心，spring-cloud-config可将配置存储到git 当某个服务需要配置时，直接在其配置中获取配置中心服务的配置信息]]></content>
      <categories>
        <category>springcloud</category>
      </categories>
      <tags>
        <tag>spring cloud config</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第四篇:网关(Zuul)]]></title>
    <url>%2F2019%2F05%2F03%2Fspringcloud%2F%E7%BD%91%E5%85%B3(Zuul)%2F</url>
    <content type="text"><![CDATA[引言不同的微服务一般有不同的网络地址，而外部的客户端可能需要调用多个服务的接口才能完成一个业务需求。比如一个电影购票的收集APP,可能回调用电影分类微服务，用户微服务，支付微服务等。如果客户端直接和微服务进行通信，会存在一下问题 客户端会多次请求不同微服务，增加客户端的复杂性 存在跨域请求，在一定场景下处理相对复杂 认证复杂，每一个服务都需要独立认证 难以重构，随着项目的迭代，可能需要重新划分微服务，如果客户端直接和微服务通信，那么重构会难以实施 某些微服务可能使用了其他协议，直接访问有一定困难 上述问题，都可以借助微服务网关解决。微服务网关是介于客户端和服务器端之间的中间层，所有的外部请求都会先经过微服务网关 zuul简介Zuul的主要功能是路由转发和过滤器。路由功能是微服务的一部分，比如／api/user转发到到user服务，/api/shop转发到到shop服务。zuul有如下功能： 身份认证和安全: 识别每一个资源的验证要求，并拒绝那些不符的请求 审查与监控 动态路由：动态将请求路由到不同后端集群 压力测试：逐渐增加指向集群的流量，以了解性能 负载分配：为每一种负载类型分配对应容量，并弃用超出限定值的请求 静态响应处理：边缘位置进行响应，避免转发到内部集群 多区域弹性：跨域AWS Region进行请求路由，旨在实现ELB(ElasticLoad Balancing)使用多样化 此时微服务架构如图所示 准备工作在原有的工程上，创建一个新的工程 搭建service-zuul工程 依赖POM文件如下 1234567891011121314151617&lt;dependencies&gt; &lt;!-- eureka客户端 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- web --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- zull核心依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-zuul&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 启动类加上 @EnableZuulProxy表示启动zuul功能 123456789@SpringBootApplication@EnableEurekaClient@EnableDiscoveryClient@EnableZuulProxy // 开启zull功能public class ZuulApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ZuulApplication.class, args); &#125;&#125; 配置路由网关 1234567891011121314151617181920eureka: client: serviceUrl: defaultZone: http://localhost:8761/eureka/ # 注册中心地址server: port: 8769spring: application: name: service-zuul # 服务名zuul: routes: # 路由配置 api-a: path: /api-a/** serviceId: service-ribbon # 服务名 api-b: path: /api-b/** serviceId: service-feign # 服务名 以 /api-a开头的请求都转发给service-ribbon服务 以 /api-b开头的请求都转发给service-feign服务 浏览器访问 http://localhost:8769/api-a/hi?name=lisi，如图所示 浏览器访问 http://localhost:8769/api-b/test.do， 如图所示 说明只需要访问网关服务，根据网关路由的配置，会转发到不同的服务执行 zuul过滤zuul不仅只是路由，并且还能过滤，做一些安全验证。定义一个zuul过滤器12345678910111213141516171819202122232425262728293031323334353637383940@Component@Slf4jpublic class MyFilter extends ZuulFilter &#123; @Override public String filterType() &#123; return "pre"; // 前置过滤器 &#125; @Override public int filterOrder() &#123; return 0; // 优先级为0, 数字越大，优先级越高 &#125; @Override public boolean shouldFilter() &#123; return true; //是否执行该过滤器 &#125; @Override public Object run() throws ZuulException &#123; RequestContext ctx = RequestContext.getCurrentContext(); HttpServletRequest request = ctx.getRequest(); log.info(String.format("%s &gt;&gt;&gt; %s", request.getMethod(), request.getRequestURL().toString())); Object accessToken = request.getParameter("token"); if(accessToken == null) &#123; log.warn("token is empty"); ctx.setSendZuulResponse(false); ctx.setResponseStatusCode(401); try &#123; ctx.getResponse().getWriter().write("token is empty"); &#125;catch (Exception e)&#123;&#125; return null; &#125; log.info("ok"); return null; &#125;&#125; filterType: 返回一个字符串，代表过滤器的类型，在zuul中定义了四种不同生命周期的过滤器类型 pre：路由之前调用 routing：路由之时调用 post： 路由之后调用 error：发送错误调用 filterOrder：过滤的顺序通过int值来定义过滤器的执行顺序 shouldFilter: 返回一个boolean类型来判断该过滤器是否要执行，所以通过此函数可实现过滤器的开关。在上例中，我们直接返回true，所以该过滤器总是生效 run: 过滤器的具体逻辑。可用很复杂，包括查sql，nosql去判断该请求到底有没有权限访问 重新启动工程，浏览器访问 http://localhost:8769/api-b/test.do，如图所示 浏览器访问 http://localhost:8769/api-b/test.do?token=123，如图所示 因为我们在逻辑中判断了请求需要携带tonken 注意：使用了网关服务，熔断器无效的解决方法在zuul配置中加入123ribbon: ReadTimeout: 60000 ConnectTimeout: 60000 总结 zuul路由就是客户端的请求先经过zuul网关, 网关会根据不同的请求URL转发到对应的服务 zuul过滤器可以对请求进入网关之前做一些处理，只需继承ZuulFilter类]]></content>
      <categories>
        <category>springcloud</category>
      </categories>
      <tags>
        <tag>zuul</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第三篇:熔断器(Hystrix)]]></title>
    <url>%2F2019%2F05%2F03%2Fspringcloud%2F%E7%86%94%E6%96%AD%E5%99%A8(Hystrix)%2F</url>
    <content type="text"><![CDATA[为什么需要熔断器在微服务架构中通常会有多个服务层调用，基础服务的故障可能会导致级联故障，进而造成整个系统不可用的情况，这种现象被称为服务雪崩效应。服务雪崩效应是一种因“服务提供者”的不可用导致“服务消费者”的不可用,并将不可用逐渐放大的过程如果下图所示：A作为服务提供者，B为A的服务消费者，C和D是B的服务消费者。A不可用引起了B的不可用，并将不可用像滚雪球一样放大到C和D时，雪崩效应就形成了 HystrixNetflix开源了Hystrix组件，实现了断路器模式，SpringCloud对这一组件进行了整合Hystrix 能使你的系统在出现依赖服务失效的时候，通过隔离系统所依赖的服务，防止服务级联失败，同时提供失败回退机制，更优雅地应对失效，并使你的系统能更快地从异常中恢复 准备工作启动上一篇章的注册中心，以及service-hi:8762工程 在ribbon中使用熔断器 改造上一篇章的service-ribbon工程，加入如下依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt;&lt;/dependency&gt; 启动类加上@EnableHystrix 12345678910111213141516@SpringBootApplication@EnableEurekaClient // 发布服务【ribon】@EnableDiscoveryClient // 服务发现【启动消费服务】@EnableHystrix // 开启熔断器public class RibbonApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(RibbonApplication.class, args); &#125; @Bean @LoadBalanced RestTemplate restTemplate() &#123; return new RestTemplate(); &#125;&#125; 改造HelloService 1234567891011121314151617@Servicepublic class HelloService &#123; @Autowired private RestTemplate restTemplate; // 对该方法创建熔断器的功能 @HystrixCommand(fallbackMethod = "hiError") public String hiService(String name) &#123; return restTemplate.getForObject("http://SERVICE-HI/hi?name=" + name, String.class); &#125; // 熔断器返回的方法 public String hiError(String name) &#123; return "hi," + name + ",sorry,error!"; &#125;&#125; @HystrixCommand注解对方法启动熔断功能启动工程，浏览器访问 http://localhost:8764/hi?name=zhangsan，如图所示 此时我们将服务提供者service-hi服务关闭，再访问该路径，如图所示 当service-hi工程不可用时，service-ribbon调用service-hi时，会执行快速失败，直接返回一组字符串，而不是等待响应时间，很好的控制了servlet容器的线程阻塞 Feign中使用熔断器Feign是自带断路器的，在D版本的Spring Cloud之后，它没有默认打开。需要在配置文件中配置打开它，在配置文件加以下代码123feign: hystrix: enabled: true 改造service-feign(消费方)，修改远程服务接口123456@FeignClient(value = "service-hi", fallback = ClientServiceHiHystric.class) // 远程服务名称 | 熔断处理public interface ClientServiceHi &#123; @RequestMapping(value = "/hi",method = RequestMethod.GET) String sayHiFromClientOne(@RequestParam(value = "name") String name); // 如果PathVariable注解也需要加上别名&#125; 在@FeignClient注解中加上，fallback = ClientServiceHiHystric.class表示服务错误时执行该类的处理方法 ClientServiceHiHystric错误处理方法123456789@Componentpublic class ClientServiceHiHystric implements ClientServiceHi&#123; // 服务错误处理方法 @Override public String sayHiFromClientOne(String name) &#123; return "sory" + name; &#125;&#125; 首先，实现接口，重写方法，并返回字符串 启动service-feign，浏览器中访问 http://localhost:8765/test.do，如图所示 此时我们将服务提供者service-hi服务关闭，再访问该URL，如图所示证明熔断器起作用了 总结 熔断机制：服务提供者如果挂了，服务消费者可能也会导致挂掉，防止级联失败。如果服务提供则挂了，消费者调用的时候返回指定的错误信息即可 feign自带Hystrix不需额外依赖：(消费方)配置开启、在@FeignClient注解加上fallback的指定类，该类处理服务错误的时执行的方法]]></content>
      <categories>
        <category>springcloud</category>
      </categories>
      <tags>
        <tag>hystrix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第二篇:服务消费(Ribbon—Feign)]]></title>
    <url>%2F2019%2F05%2F03%2Fspringcloud%2F%E6%9C%8D%E5%8A%A1%E6%B6%88%E8%B4%B9(Ribbon%E2%80%94Feign)%2F</url>
    <content type="text"><![CDATA[ribbon简介在前面的文章中，我们讲了使用Eureka作为服务注册中心，在服务启动后，各个微服务会将自己注册到Eureka server。那么服务之间是如何调用？又是如何进行负载均衡的呢？本文讲讲服务之间调用及负载均衡Ribbon。 目前，在Spring cloud 中服务之间通过restful方式调用有两种方式 restTemplate+Ribbon feign 从实践上看，采用feign的方式更优雅（feign内部也使用了ribbon做负载均衡） 准备工作基于上一篇章，启动注册中心，启动server-hi:8762和8763，模拟小集群，在idea启动多个实例如下 此时各个服务启动状态如下 搭建服务消费者 依赖POM文件如下1234567891011121314&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-ribbon&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 消费者就像controller，调用服务提供者service，因此消费者要web依赖 配置 12345678910eureka: client: serviceUrl: defaultZone: http://localhost:8761/eureka/server: port: 8764spring: application: name: service-ribbon 启动类 1234567891011121314@SpringBootApplication@EnableEurekaClient // 发布服务【ribon】@EnableDiscoveryClient // 服务发现【启动消费服务】public class RibbonApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(RibbonApplication.class, args); &#125; @Bean @LoadBalanced // 均衡负载 RestTemplate restTemplate() &#123; return new RestTemplate(); &#125;&#125; 编写一个service类，通过restTemplate消费上一篇章中的/hi接口 123456789101112@Servicepublic class HelloService &#123; @Autowired private RestTemplate restTemplate; // 远程服务接口 public String hiService(String name) &#123; return restTemplate.getForObject("http://SERVICE-HI/hi?name="+name,String.class); &#125;&#125; 通过controller调用上述方法 1234567891011@RestControllerpublic class HelloControler &#123; @Autowired private HelloService helloService; @GetMapping("/hi") public String hi(@RequestParam String name)&#123; return helloService.hiService(name); &#125;&#125; 浏览器不断的访问http://localhost:8764/hi?name=zhangsan, 会发现交替执行集群8762和8763，实现了均衡负载的效果 Feign简介Feign是一个声明式的伪Http客户端，它使得写Http客户端变得更简单。使用Feign，只需要创建一个接口并注解。它具有可插拔的注解特性，可使用Feign 注解和JAX-RS注解。Feign支持可插拔的编码器和解码器。Feign默认集成了Ribbon，并和Eureka结合，默认实现了负载均衡的效果 简而言之： Feign 采用的是基于接口的注解 Feign 整合了ribbon，具有负载均衡的能力 整合了Hystrix，具有熔断的能力 准备工作上述我们使用了ribbon实现服务之间的调用以及均衡负载的体现，本节我们将使用feign实现启动注册中心8761、service-hi:8762、8763 搭建feign服务 依赖POM文件如下 1234567891011121314151617&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 使用feign消费服务 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 启动类 123456789@SpringBootApplication@EnableEurekaClient // 发布服务@EnableDiscoveryClient // 消费服务【发现其他服务】@EnableFeignClients // 开启feign功能public class FeignApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(FeignApplication.class, args); &#125;&#125; 配置 12345678910eureka: client: serviceUrl: defaultZone: http://localhost:8761/eureka/server: port: 8765spring: application: name: service-feign 定义feign接口，该接口定义你要调用的远程方法，拷贝方法即可 123456@FeignClient(value = "service-hi") // 远程服务名称public interface ClientServiceHi &#123; @RequestMapping(value = "/hi",method = RequestMethod.GET) String sayHiFromClientOne(@RequestParam(value = "name") String name); // 如果PathVariable注解也需要加上别名&#125; controller消费远程服务 1234567891011@RestControllerpublic class HiController &#123; @Autowired private ClientServiceHi clientServiceHi; @GetMapping("test.do") public String sayHi() &#123; return clientServiceHi.sayHiFromClientOne("zhangsan"); &#125;&#125; 浏览器不断访问 http://localhost:8765/test.do，会发现和ribbon一样，交替执行集群8762和8763，实现了均衡负载的效果 总结Feign实现服务之间的调用：启动类开启@EnableFeignClients注解，表示使用feigin，定义feigin接口，该接口定义了你要调用远程服务的方法，使用注解@FeignClient]]></content>
      <categories>
        <category>springcloud</category>
      </categories>
      <tags>
        <tag>ribbon</tag>
        <tag>feign</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第一篇:发布服务(Eureka)]]></title>
    <url>%2F2019%2F05%2F02%2Fspringcloud%2F%E5%8F%91%E5%B8%83%E6%9C%8D%E5%8A%A1(Eureka)%2F</url>
    <content type="text"><![CDATA[springcloud简介Spring Cloud是一系列框架的有序集合。它利用Spring Boot的开发便利性巧妙地简化了分布式系统基础设施的开发，如服务发现注册、配置中心、消息总线、负载均衡、熔断器、数据监控等，都可以用Spring Boot的开发风格做到一键启动和部署。Spring并没有重复制造轮子，它只是将目前各家公司开发的比较成熟、经得起实际考验的服务框架组合起来，通过Spring Boot风格进行再封装屏蔽掉了复杂的配置和实现原理，最终给开发者留出了一套简单易懂、易部署和易维护的分布式系统开发工具包 Spring Boot可以离开Spring Cloud独立使用开发项目，但是Spring Cloud离不开Spring Boot，属于依赖的关系。 springcloud组件 服务发现——Netflix Eureka 服务调用——Netflix Feign 熔断器——Netflix Hystrix 服务网关——Netflix Zuul 分布式配置——Spring Cloud Config 消息总线 —— Spring Cloud Bus springcloud版本 Spring Boot Spring Cloud 1.2.x Angel版本 1.3.x Brixton版本 1.4.x Camden版本 1.5.x Dalston版本、Edgware版本 2.0.x Finchley版本 注册中心Eureka Eureka Server提供服务注册服务，各个节点启动后，会在Eureka Server中进行注册，这样EurekaServer中的服务注册表中将会存储所有可用服务节点的信息，服务节点的信息可以在界面中直观的看到 Eureka Client是一个java客户端，用于简化与Eureka Server的交互，客户端同时也就别一个内置的、使用轮询(round-robin)负载算法的负载均衡器。在应用启动后，将会向Eureka Server发送心跳,默认周期为30秒，如果Eureka Server在多个心跳周期内没有接收到某个节点的心跳，Eureka Server将会从服务注册表中把这个服务节点移除(默认90秒) Eureka Server之间通过复制的方式完成数据的同步，Eureka还提供了客户端缓存机制，即使所有的Eureka Server都挂掉，客户端依然可以利用缓存中的信息消费其他服务的API。综上，Eureka通过心跳检查、客户端缓存等机制，确保了系统的高可用性、灵活性和可伸缩性 准备工作spring Boot版本为2.0.3.RELEASE，Spring Cloud版本为Finchley.RELEASE 父工程POM文件依赖如下12345678910111213141516171819202122232425262728293031323334353637383940414243444546&lt;!-- spring-boot起步依赖 --&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.3.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;/parent&gt; &lt;!-- 版本锁定 --&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;spring-cloud.version&gt;Finchley.RELEASE&lt;/spring-cloud.version&gt; &lt;/properties&gt; &lt;!-- 测试 --&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;!-- 锁定springcloud版本 --&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-cloud.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; 搭建eureka-serve工程 此工程作为注册中心，依赖文件如下 1234567&lt;!-- 注册中心服务依赖 --&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 启动类 1234567@SpringBootApplication@EnableEurekaServer // 开启注册中心public class EurekaApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(EurekaApplication.class, args); &#125;&#125; @EnableEurekaServer简单的理解为启动注册中心服务 配置 12345678910111213141516server: port: 8761eureka: instance: hostname: localhost client: registerWithEureka: false # 不注册自己 fetchRegistry: false # 不检索自己 serviceUrl: defaultZone: http://$&#123;eureka.instance.hostname&#125;:$&#123;server.port&#125;/eureka/spring: application: name: eureka-server eureka界面管理信息 此时因为还没有服务进行注册呢 服务提供者eureka client当client向server注册时，它会提供一些元数据，例如主机和端口，URL，主页等。Eureka server 从每个client实例接收心跳消息。 如果心跳超时，则通常将该实例从注册server中删除 依赖如下 12345678910111213&lt;dependencies&gt; &lt;!-- 服务提供者client--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- web--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 启动类 12345678910111213141516@SpringBootApplication@RestController@EnableEurekaClient //发布服务public class HiApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(HiApplication.class, args); &#125; @Value("$&#123;server.port&#125;") String port; @RequestMapping("/hi") public String home(@RequestParam(value = "name", defaultValue = "forezp") String name) &#123; return "hi " + name + " ,i am from port:" + port; &#125;&#125; 配置 1234567891011server: port: 8762spring: application: name: service-hi # 指定服务名，用于服务之间相互调用eureka: client: serviceUrl: defaultZone: http://localhost:8761/eureka/ # 注册中心地址 eureka界面管理信息 此时服务SERVICE-HI 已被注册了 总结 @EnableEurekaServer：启动注册中心服务(单独的eureka工程) @EnableEurekaClient：发布服务]]></content>
      <categories>
        <category>springcloud</category>
      </categories>
      <tags>
        <tag>eureka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[阿里短信服务(mq使用场景)]]></title>
    <url>%2F2019%2F05%2F02%2Fmq%2F%E9%98%BF%E9%87%8C%E7%9F%AD%E4%BF%A1%E6%9C%8D%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[需求分析 https://github.com/zhongjinlang/sendmessage 注册账户并且校验手机验证码，校验成功才可进行注册。实现思路如下: 表结构如下因为需要判断手机号是否注册，通常在每个user表中(这里省去了其他的字段)，都需要有一个mobile字段，这样更为合理 搭建发送验证码核心依赖12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt;&lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt; 123456789101112131415spring: datasource: url: jdbc:mysql://localhost:3306/test?serverTimezone=UTC&amp;useUnicode=true&amp;characterEncoding=utf8&amp;useSSL=false driver-class-name: com.mysql.cj.jdbc.Driver username: root password: mysqladmin redis: host: 192.168.211.139 jpa: show-sql: true rabbitmq: host: 192.168.181.128 UserService-interface我们需要完成用户注册之前验证码的校验，因此我们定义两个方法：1234567891011121314151617public interface UserService &#123; /** * 发送验证码 * @param mobile 手机号 * @return */ ResultVo sendCode(String mobile); /** * 用户注册 * @param user 用户 * @param code 验证码 * @return */ ResultVo register(User user, String code);&#125; 发送验证码其实发送验证码就是随机生成6位数字, 具体实现如下12345678910111213141516171819202122232425262728293031public ResultVo sendCode(String mobile) &#123; // 校验 if (StringUtils.isEmpty(mobile))&#123; return new ResultVo(1, "手机号错误"); &#125; // 判断该手机号是否注册 User result = userDao.findByMobile(mobile); if (result != null)&#123; return new ResultVo(1, "手机号已被注册"); &#125; // 生成随机数 Random random = new Random(); int max = 999999; int min = 100000; int code = random.nextInt(max); if (code &lt; min) &#123; code = code + min; &#125; log.info("【生成的验证码为】=&#123;&#125;, 【手机号为】=&#123;&#125;", code, mobile); // 存入redis redisTemplate.boundValueOps("msgcode_" + mobile).set(code + "", 1, TimeUnit.MINUTES); // 讲验证码和手机号发送到消息队列 Map&lt;String, String&gt; parameter = new HashMap&lt;&gt;(); parameter.put("mobile", mobile); parameter.put("code", code + ""); rabbitTemplate.convertAndSend("msg", parameter); return new ResultVo(0, "验证码发送成功"); &#125; 我们将上述代码进行测试：123456@Test public void sendMessages() &#123; String mobile = "1101"; ResultVo resultVo = userService.sendCode(mobile); System.out.println(resultVo); &#125; 观察日志、redis、mq浏览器页面 用户注册根据流程图思考，注册是有条件的，也就是输入的验证码正确之后才可进行注册，具体实现如下:1234567891011121314151617181920212223public ResultVo register(User user, String code) &#123; if (StringUtils.isEmpty(code))&#123; return new ResultVo(1, "验证码不能为空"); &#125; String msgCode = (String) redisTemplate.boundValueOps("msgcode_" + user.getMobile()).get(); log.info("【用户注册】redis中验证码为 = &#123;&#125;", msgCode); if (msgCode == null) &#123; throw new RuntimeException("验证码不存在"); &#125; if (!msgCode.equals(code)) &#123; return new ResultVo(1, "验证码不正确"); &#125; User result = userDao.save(user); if (result != null) &#123; return new ResultVo(0, "注册成功"); &#125; return new ResultVo(1, "注册失败");&#125; 将上述代码进行测试: 先发送验证码，记录验证码用于注册用户的方法参数2上12345678910@Testpublic void register() &#123; User user = new User(); user.setUsername("zhangsan"); user.setMobile("123"); // 生成验证码的手机号 user.setPassword("123"); ResultVo register = userService.register(user, "377144"); // 验证码 System.out.println(register);&#125; 搭建阿里云发送短信服务我们通过阿里云的短信服务来进行短信的发送, 首先需要为短信添加签名和模板等。我们采用新版的发送短信API，具体文档与测试接口:https://api.aliyun.com/new#/?product=Dysmsapi 依赖12345678910&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.aliyun&lt;/groupId&gt; &lt;artifactId&gt;aliyun-java-sdk-core&lt;/artifactId&gt; &lt;version&gt;4.0.3&lt;/version&gt;&lt;/dependency&gt; 123456789101112server: port: 8081spring: rabbitmq: host: 192.168.181.128# 从阿里短信服务中查找aliyun: accessKeyId: xxx accessSecret: xxx SignName: xxx TemplateCode: xxx 发送短信核心类123456789101112131415161718192021222324252627282930313233343536373839@Component@ConfigurationProperties("aliyun")@Datapublic class CommonRpc &#123; private String accessKeyId; private String accessSecret; private String signName; // 短信签名名称 private String templateCode; // 短信模板code /** * 发送短信 * @param phoneNumbers 手机号 * @param templateParam 验证码【json格式】 */ public void send( String phoneNumbers, String templateParam)&#123; DefaultProfile profile = DefaultProfile.getProfile("cn-hangzhou", accessKeyId, accessSecret); IAcsClient client = new DefaultAcsClient(profile); CommonRequest request = new CommonRequest(); request.setMethod(MethodType.POST); request.setDomain("dysmsapi.aliyuncs.com"); request.setVersion("2017-05-25"); request.setAction("SendSms"); request.putQueryParameter("RegionId", "cn-hangzhou"); request.putQueryParameter("TemplateParam", templateParam); request.putQueryParameter("PhoneNumbers", phoneNumbers); request.putQueryParameter("SignName", signName); request.putQueryParameter("TemplateCode", templateCode); try &#123; CommonResponse response = client.getCommonResponse(request); System.out.println(response.getData()); &#125; catch (ServerException e) &#123; e.printStackTrace(); &#125; catch (ClientException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 测试结果如下123456@Test public void send() &#123; Map&lt;String, String&gt; code = new HashMap&lt;&gt;(); code.put("code", "123456"); commonRpc.send("17239837261", JSON.toJSONString(code)); &#125; 1&#123;"Message":"OK","RequestId":"15510BA0-B641-472F-8A3D-D85406A0F15D","BizId":"520100556727328952^0","Code":"OK"&#125; 阿里短信服务接口返回OK，证明发送短信成功，接下来我们要从消息队列中获取两个参数 code 生成的随机数 phone 手机号 监听MQ消息注意监听的队列为msg，如果在项目中，通常将其定义为enum类中，容易维护1234567891011121314151617181920212223242526@Component@RabbitListener(queues = "msg")@Slf4jpublic class MessageListener &#123; @Autowired private CommonRpc commonRpc; @RabbitHandler public void sendMessage(Map&lt;String, String&gt; map)&#123; System.out.println("监听消息...."); String mobile = map.get("mobile"); String code = map.get("code"); Map&lt;String, String&gt; param = new HashMap&lt;&gt;(); param.put("code", code); log.info("【监听消息】手机号=&#123;&#125;, 验证码=&#123;&#125;", mobile, code); try &#123; commonRpc.send(mobile, JSON.toJSONString(param)); &#125;catch (Exception e)&#123; log.error(e.getMessage(), e); &#125; &#125;&#125; 启动项目，会自动监听msg队列中的消息 总结注册模块和发送短信模块分离，如果有其他模块使用短信服务，那么通过MQ做到了项目的解耦]]></content>
      <categories>
        <category>message-mq</category>
      </categories>
      <tags>
        <tag>rabbitMQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[认证机制]]></title>
    <url>%2F2019%2F05%2F01%2F%E9%9A%8F%E7%AC%94%2F%E8%AE%A4%E8%AF%81%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[引言所谓的认证，其实就是登入。而登入我们会想到使用session来存储用户登入信息等。对于session和token，为什么需要使用tonken这种认证方式，在web认证的方式也众多，因此我们需要对认证这方面的知识进行分析 HTTP Basic AuthHTTP Basic Auth简单点说明就是每次请求API时都提供用户的username和password，简言之，Basic Auth是配合RESTful API 使用的最简单的认证方式，只需提供用户名密码即可，但由于有把用户名密码暴露给第三方客户端的风险，在生产环境下被使用的越来越少。因此，在开发对外开放的RESTful API时，尽量避免采用HTTP Basic Auth Cookie AuthCookie认证机制就是为一次请求认证在服务端创建一个Session对象，同时在客户端的浏览器端创建了一个Cookie对象；通过客户端带上来Cookie对象来与服务器端的session对象匹配来实现状态管理的。默认的，当我们关闭浏览器的时候，cookie会被删除。但可以通过修改cookie 的expire time使cookie在一定时间内有效 OAuthOAuth（开放授权）是一个开放的授权标准，允许用户让第三方应用访问该用户在某一web服务上存储的私密的资源（如照片，视频，联系人列表），而无需将用户名和密码提供给第三方应用。 OAuth允许用户提供一个令牌，而不是用户名和密码来访问他们存放在特定服务提供者的数据。每一个令牌授权一个特定的第三方系统（例如，视频编辑网站)在特定的时段（例如，接下来的2小时内）内访问特定的资源（例如仅仅是某一相册中的视频）。这样，OAuth让用户可以授权第三方网站访问他们存储在另外服务提供者的某些特定信息，而非所有内容 这种基于OAuth的认证机制适用于个人消费者类的互联网产品，如社交类APP等应用，但是不太适合拥有自有认证权限管理的企业应用 Token AuthToken机制相对于Cookie机制又有什么好处呢? 支持跨域访问: Cookie是不允许垮域访问的，这一点对Token机制是不存在的，前提是传输的用户认证信息通过HTTP头传输. 无状态(也称：服务端可扩展行):Token机制在服务端不需要存储session信息，因为Token 自身包含了所有登录用户的信息，只需要在客户端的cookie或本地介质存储状态信息 更适用CDN: 可以通过内容分发网络请求你服务端的所有资料（如：javascript，HTML,图片等），而你的服务端只要提供API即可. 去耦: 不需要绑定到一个特定的身份验证方案。Token可以在任何地方生成，只要在你的API被调用的时候，你可以进行Token生成调用即可. 更适用于移动应用: 当你的客户端是一个原生平台（iOS, Android，Windows 8等）时，Cookie是不被支持的（你需要通过Cookie容器进行处理），这时采用Token认证机制就会简单得多。 CSRF:因为不再依赖于Cookie，所以你就不需要考虑对CSRF（跨站请求伪造）的防范。 性能: 一次网络往返时间（通过数据库查询session信息）总比做一次HMACSHA256计算 的Token验证和解析要费时得多. 不需要为登录页面做特殊处理: 如果你使用Protractor 做功能测试的时候，不再需要为登录页面做特殊处理. 基于标准化:你的API可以采用标准化的 JSON Web Token (JWT). 这个标准已经存在多个后端库（.NET, Ruby, Java,Python, PHP）和多家公司的支持（如：Firebase,Google, Microsoft） 基于JWT的Token认证机制实现JSON Web Token（JWT）是一个非常轻巧的规范。这个规范允许我们使用JWT在用户和服务器之间传递安全可靠的信息 JWT的组成一个JWT实际上就是一个字符串，它由三部分组成，头部、载荷与签名 头部(Header)头部用于描述关于该JWT的最基本的信息，例如其类型以及签名所用的算法等。这也可以被表示成一个JSON对象1234&#123; "typ": "JWT", "alg": "HS256"&#125; BASE64编码之后的字符串如下:1eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9 载荷(Payload)Payload里面是Token的具体内容，也就是Token的数据声明（Claim），这些内容里面有一些是标准字段，也可以添加其他需要添加的内容，如userId,email等 12345678910&#123; "iss": "Online JWT Builder", "iat": 1416797419, "exp": 1448333419, "aud": "www.example.com", "sub": "jrocket@example.com", "GivenName": "Johnny", "Surname": "Rocket", "Email": "jrocket@example.com", "Role": [ "Manager", "Project Administrator" ] &#125; 其中标准字段各含义如下:1234567iss: jwt签发者sub: jwt所面向的用户aud: 接收jwt的一方exp: jwt的过期时间，这个过期时间必须要大于签发时间nbf: 定义在什么时间之前，该jwt都是不可用的.iat: jwt的签发时间jti: jwt的唯一身份标识，主要用来作为一次性token,从而回避重放攻击 签名上面的两个编码后的字符串都用句号.连接在一起（头部在前），就形成了1eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJmcm9tX3VzZXIiOiJCIiwidGFyZ2V0X3VzZXIiOiJBIn0 将上面拼接完的字符串用HS256算法进行加密。在加密的时候，还需要提供一个密钥（secret）。如果我们用mystar作为密钥的话，那么就可以得到我们加密后的内容:1rSWamyAYwuHCo7IFAgd1oRpSP7nzL7BF5t7ItqpKViM 此时完整的JWT：1eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJmcm9tX3VzZXIiOiJCIiwidGFyZ2V0X3VzZXIiOiJBIn0.rSWamyAYwuHCo7IFAgd1oRpSP7nzL7BF5t7ItqpKViM 在请求URL中也会携带这串JWT字符串1https://your.awesome-app.com/make-friend/?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJmcm9tX3VzZXIiOiJCIiwidGFyZ2V0X3VzZXIiOiJBIn0.rSWamyAYwuHCo7IFAgd1oRpSP7nzL7BF5t7ItqpKViM JWT认证|鉴权流程基于Token的认证机制会在每一次请求中都带上完成签名的Token信息，这个Token信息可能在COOKIE中，也可能在HTTP的Authorization头中 认证 用户在页面输入用户名和密码，发送请求到服务端 服务端会验证账号密码是否正确 服务端生成tonken字符串 返回客户端，将tonken保存在cookie中 鉴权 从cookie中获取tonken信息，通过请求头发送给服务端 服务端通过tonken信息判断当前用户的权限 如果没有权限，返回没有权限的提示 有权限，继续操作 JWT的JAVA实现Java中对JWT的支持可以考虑使用JJWT开源库；JJWT实现了JWT, JWS, JWE 和 JWA RFC规范；下面将简单举例说明其使用 环境：spring boot + jjwtjjwt依赖12345&lt;dependency&gt; &lt;groupId&gt;io.jsonwebtoken&lt;/groupId&gt; &lt;artifactId&gt;jjwt&lt;/artifactId&gt; &lt;version&gt;0.9.1&lt;/version&gt;&lt;/dependency&gt; 创建tonken与解析创建tonken测试代码1234567891011121314151617181920public class JjwtApplicationTests &#123; // 创建tonken @Test public void createTonken() &#123; long timeMillis = System.currentTimeMillis(); long newTime = timeMillis + 60 * 2000; JwtBuilder builder = Jwts.builder() .setId("userid") // jti .setSubject("username") // sub .setIssuedAt(new Date()) // iat 创建tonken的时间 .setExpiration(new Date(newTime)) // 过期时间 .signWith(SignatureAlgorithm.HS256,"ROOT")// 加密方式+密钥 // 可存储其定义信息【角色信息】 .claim("roles", "user") ; log.info("【生成的tonken】=&#123;&#125; ", builder.compact()); &#125; 密钥与过期时间通常写在配置文件中 生成的tonken字符串：1eyJhbGciOiJIUzI1NiJ9.eyJqdGkiOiJ1c2VyaWQiLCJzdWIiOiJ1c2VybmFtZSIsImlhdCI6MTU1NjcxNzM4MCwiZXhwIjoxNTU2NzE3NTAwLCJyb2xlcyI6InVzZXIifQ.O6Tpx2xMnD-3SrUhbQGxTgvvONEHAslRmh6ClIcbxGI 解析tonken测试代码123456789101112131415@Test public void parseTonken()&#123; String token = "eyJhbGciOiJIUzI1NiJ9.eyJqdGkiOiJ1c2VyaWQiLCJzdWIiOiJ1c2VybmFtZSIsImlhdCI6MTU1NjcxNzM4MCwiZXhwIjoxNTU2NzE3NTAwLCJyb2xlcyI6InVzZXIifQ.O6Tpx2xMnD-3SrUhbQGxTgvvONEHAslRmh6ClIcbxGI"; Claims claims = Jwts.parser() .setSigningKey("ROOT") // 密钥 .parseClaimsJws(token) // tonken .getBody(); // 载荷 System.out.println("用户id" + claims.getId() ); System.out.println("用户名" + claims.getSubject() ); System.out.println("签发时间" + claims.getIssuedAt() ); System.out.println("当前时间:" + new Date()); System.out.println("过期时间:" + claims.getExpiration()); System.out.println("自定义载荷信息:" + claims.get("roles")); &#125; 输出的日志信息为:123456用户iduserid用户名username签发时间Wed May 01 21:29:40 CST 2019当前时间:Wed May 01 21:31:01 CST 2019过期时间:Wed May 01 21:31:40 CST 2019自定义载荷信息:user 抽取工具类12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364@Component@Data@ConfigurationProperties("tonken")public class TonkenUtils &#123; private String key; // 密钥 private long expiration; // 过期时间 /** * 生成tonken * @param id 登入用户id * @param subject 用户名 * @return tonken */ public String createTonken(String id, String subject)&#123; long nowMillis = System.currentTimeMillis(); Date now = new Date(nowMillis); JwtBuilder builder = Jwts.builder() .setId(id) .setSubject(subject) .setIssuedAt(now) .signWith(SignatureAlgorithm.HS256, key); if (expiration &gt; 0)&#123; builder.setExpiration(new Date(nowMillis + expiration) ); &#125; return builder.compact(); &#125; /** * 生成含有自定义信息的tonken * @param id 登入用户id * @param subject 用户名 * @param claim 自定义信息【如 user、admin角色】 * @return tonken */ public String createTonken(String id, String subject, String claim)&#123; long nowMillis = System.currentTimeMillis(); Date now = new Date(nowMillis); JwtBuilder builder = Jwts.builder() .setId(id) .setSubject(subject) .setIssuedAt(now) .signWith(SignatureAlgorithm.HS256, key) .claim("roles", claim); if (expiration &gt; 0)&#123; builder.setExpiration(new Date(nowMillis + expiration) ); &#125; return builder.compact(); &#125; /** * 解析tonken * @param key 密钥 * @return */ public Claims parseTonken(String key)&#123; return Jwts.parser() .setSigningKey(key) .parseClaimsJws(key) // 被解析的tonken字符串从客户端获取 .getBody(); // 载荷信息 &#125;&#125; application.yml123tonken: key: root expiration: 360000 总结 jwt有三部分组成：头部(加密方式)、载荷(有效信息)、签名(密钥) tonken是无状态的，有服务端生成，不需要存储session信息，因为它包含了用户的信息]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>HTTP Basic Auth</tag>
        <tag>Cookie Auth</tag>
        <tag>OAuth</tag>
        <tag>Token Auth</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RabbitMQ入门]]></title>
    <url>%2F2019%2F04%2F28%2Fmq%2FRabbitMQ%2F</url>
    <content type="text"><![CDATA[RabbitMQ简介 代码：https://github.com/zhongjinlang/rabbitmq RabbitMQ 是实现 AMQP（高级消息队列协议）的消息中间件的一种，最初起源于金融系统，用于在分布式系统中存储转发消息，在易用性、扩展性、高可用性等方面表现不俗。 RabbitMQ 主要是为了实现系统之间的双向解耦而实现的。当生产者大量产生数据时，消费者无法快速消费，那么需要一个中间层。保存这个数据。 AMQP，即 Advanced Message Queuing Protocol，高级消息队列协议，是应用层协议的一个开放标准，为面向消息的中间件设计。消息中间件主要用于组件之间的解耦，消息的发送者无需知道消息使用者的存在，反之亦然。AMQP 的主要特征是面向消息、队列、路由（包括点对点和发布/订阅）、可靠性、安全。 RabbitMQ 是一个开源的 AMQP 实现，服务器端用Erlang语言编写，支持多种客户端，如：Python、Ruby、.NET、Java、JMS、C、PHP、ActionScript、XMPP、STOMP 等，支持 AJAX。用于在分布式系统中存储转发消息，在易用性、扩展性、高可用性等方面表现不俗 相关概念通常消息队列都有三个概念：生产消息、队列、消费消息。RabbitMQ 在这个基本概念之上, 多做了一层抽象, 在发消息者和队列之间, 加入了交换器 (Exchange) 这样发消息者和队列就没有直接联系, 转而变成发消息者把消息发送给交换器, 交换器根据调度策略再把消息再给队列 Exchange生产者将消息发送到Exchange(交换器)中，它并不存储任何数据，它只主要是接收消息并且转发到绑定的队列。交换器有四种类型: Direct topic Headers Fanout RoutingKey生产者在将消息发送给Exchange的时候，一般会指定一个routing key，来指定这个消息的路由规则RabbitMQ为routing key设定的长度限制为255 bytes 安装 download: https://www.rabbitmq.com/releases/rabbitmq-server/ 账号密码guest进入主界面: Direct Exchange该模式将消息发送到指定的队列中，它不需要绑定交换器 环境：springboot 核心依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt;&lt;/dependency&gt; application.yml 12345spring: rabbitmq: host: 192.168.181.128 username: guest password: guest 创建一个队列 12345678910@Configurationpublic class RabbitMQConfig &#123; public static final String QUEUE_NAME = "direct_name"; // 指定队列名称和是否持久化 @Bean public Queue directQueue()&#123; return new Queue(QUEUE_NAME, true); &#125;&#125; 注意其Queue所在的包: org.springframework.amqp.core.Queue 消息生产者123456789101112@RunWith(SpringRunner.class)@SpringBootTestpublic class Producter &#123; @Autowired private RabbitTemplate rabbitTemplate; @Test public void senMsg()&#123; // 指定要发送的队列和数据 rabbitTemplate.convertAndSend(RabbitMQConfig.QUEUE_NAME, new User(2, "lisi", "1234")); &#125;&#125; 发送消息之后在页面客户端显示如下 消息消费者12345678910@Slf4j@Component@RabbitListener(queues = RabbitMQConfig.QUEUE_NAME) // 监听的队列是哪个public class Consumer &#123; @RabbitHandler // 处理业务代码 public void handlerMsg(User user)&#123; log.info("消费的信息为: &#123;&#125;", user.toString()); &#125;&#125; 启动application后，自动会获取到消息，以及界面此时队列的信息total为0 Fanout Exchange该模式与rocketMQ的广播模式一样，也就是说消息可被多个服务所读取 rabbitMQ会将消息发送给交换器，而交换器会转发到与它绑定的队列中 发送消息时，需要指定交换器名称，不需要指定队列名称(“”表示) 创建两个队列并绑定到一个交换器中1234567891011121314151617181920212223242526272829303132333435363738@Configurationpublic class FanoutRabbitConfig &#123; // 指定交换器名称 public static final String EXCHANGE_NAME = "exchange_name"; // 指定队列名称 public static final String QUEUQ_ONE_NAME = "queue_one"; public static final String QUEUQ_TWO_NAME = "queue_two"; // 创建两个队列 @Bean public Queue queueOne() &#123; return new Queue(QUEUQ_ONE_NAME); &#125; @Bean public Queue queueTwo() &#123; return new Queue(QUEUQ_TWO_NAME); &#125; // 交换器 @Bean public FanoutExchange fanoutExchange()&#123; return new FanoutExchange(EXCHANGE_NAME); &#125; // 绑定第一个队列 @Bean public Binding bindingA(Queue queueOne, FanoutExchange fanoutExchange)&#123; return BindingBuilder.bind(queueOne).to(fanoutExchange); &#125; // 绑定第二个队列 @Bean public Binding bindingB(Queue queueTwo, FanoutExchange fanoutExchange)&#123; return BindingBuilder.bind(queueTwo).to(fanoutExchange); &#125;&#125; 发送消息123456789101112@RunWith(SpringRunner.class)@SpringBootTestpublic class Producter &#123; @Autowired private RabbitTemplate rabbitTemplate; @Test public void senMsgToMany()&#123; // 发送消息到交换器即可，它会负责转发到指定的队列 rabbitTemplate.convertAndSend(FanoutRabbitConfig.EXCHANGE_NAME, "", "hello world"); &#125;&#125; 此时客户端界面有如下信息 消费消息 队列一 12345678910@Component@RabbitListener(queues = FanoutRabbitConfig.QUEUQ_ONE_NAME) // 指定消费的队列@Slf4jpublic class FanoutConsumerOne &#123; @RabbitHandler public void showMessage(String message)&#123; log.info("One队列监听到消息: &#123;&#125;", message); &#125;&#125; 队列二 12345678910@Component@RabbitListener(queues = FanoutRabbitConfig.QUEUQ_TWO_NAME)@Slf4jpublic class FanoutConsumerTwo &#123; @RabbitHandler public void showMessage(String message)&#123; log.info("Two队列监听到消息: &#123;&#125;", message); &#125;&#125; 启动服务有日志如下信息 Topic Exchangetopic 是RabbitMQ中最灵活的一种方式，可以根据routing_key自由的绑定不同的队列 创建两个队列绑定到主题123456789101112131415161718192021222324252627282930313233343536373839@Configurationpublic class TopicRabbitConfig &#123; // 指定交换器名称 public static final String TOP_EXCHANGE = "top_exchange"; // 指定队列名称 public static final String QUEUQ_ONE_NAME = "topic.message"; public static final String QUEUQ_TWO_NAME = "topic.messages"; // 创建两个队列 @Bean public Queue one() &#123; return new Queue(QUEUQ_ONE_NAME); &#125; @Bean public Queue two() &#123; return new Queue(QUEUQ_TWO_NAME); &#125; // 创建一个主题交换器 @Bean public TopicExchange exchange() &#123; return new TopicExchange(TOP_EXCHANGE); &#125; // 绑定队列 // .with("topic.message") 表示 one这个队列只匹配topic.message @Bean public Binding bindingA(Queue one, TopicExchange exchange) &#123; return BindingBuilder.bind(one).to(exchange).with("topic.message"); &#125; // with("topic.#") 表示 two这个队列同时匹配两个队列 @Bean public Binding bindingB(Queue two, TopicExchange exchange) &#123; return BindingBuilder.bind(two).to(exchange).with("topic.#"); &#125;&#125; one队列只匹配一个topic.message, 而two队列匹配上述队列中的所有队列（因为topic.开头） 发送消息1234567891011121314151617@RunWith(SpringRunner.class)@SpringBootTestpublic class Producter &#123; @Autowired private RabbitTemplate rabbitTemplate; // 队列一 @Test public void sendTopic_Message()&#123; rabbitTemplate.convertAndSend(TopicRabbitConfig.TOP_EXCHANGE, "topic.12313","i am message one"); &#125; @Test public void sendTopic_Messages()&#123; rabbitTemplate.convertAndSend(TopicRabbitConfig.TOP_EXCHANGE, "topic.message", "i am message two"); &#125;&#125; topic.12313它会匹配到队列中的topic.# 也就是队列two: topic.message它会匹配到队列中的topic.message和topic.# 输出结果观察启动类日志如下 消费消息 队列一 12345678910@Component@RabbitListener(queues = TopicRabbitConfig.QUEUQ_ONE_NAME)@Slf4jpublic class TopicConsumerOne &#123; @RabbitHandler public void showMessage(String message)&#123; log.info("One-message队列信息: &#123;&#125;", message); &#125;&#125; 队列二 12345678910@Component@RabbitListener(queues = TopicRabbitConfig.QUEUQ_TWO_NAME)@Slf4jpublic class TopicConsumerTwo &#123; @RabbitHandler public void showMessage(String message)&#123; log.info("Two-messages队列信息: &#123;&#125;", message); &#125;&#125; 总结 直接模式Direct：将消息发送到指定的队列中，只有一个消费者消费。发送消息要指定队列名称 广播模式Fanout Exchange：将消息发送到多个队列中，广播模式，可被多个消费者所消费。发送消息要指定交换器名称即可，队列名称不需要 主题模式(Topic)：根据不同的主题(字符串匹配)会发送到不同的队列中]]></content>
      <categories>
        <category>message-mq</category>
      </categories>
      <tags>
        <tag>rabbitMQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[消息中间件作用]]></title>
    <url>%2F2019%2F04%2F28%2Fmq%2F%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[消息中间件简介消息队列中间件是分布式系统中重要的组件，主要解决应用耦合，异步消息，流量削锋等问题实现高性能，高可用，可伸缩和最终一致性[架构],使用较多的消息队列有ActiveMQ，RabbitMQ，ZeroMQ，Kafka，MetaMQ，RocketMQ。如下是MQ的一些使用场景介绍 异步处理场景说明：用户注册后，需要发注册邮件和注册短信 通常我们的做法是：讲注册信息存储到数据库，之后发送邮件、发送短信传统的方式系统的性能（并发量，吞吐量，响应时间）会有瓶颈 引入消息队列，将不是必须的业务逻辑，异步处理。改造后的架构如下 应用耦合场景说明：用户下单后，订单系统需要通知库存系统。传统的做法是，订单系统调用库存系统的接口，如下图 缺点:如果库存服务无法访问，则订单服务减库存失败，导致订单系统也失败，明细耦合度太高。 引入消息队列结构如下图： 订单系统：用户下单将消息写入消息队列 库存系统：订阅下单消息，进行库存的操作 下单后，订单系统写入消息队列就不再关心其他的后续操作了。实现订单系统与库存系统的应用解耦 流量削锋应用场景：秒杀活动，一般会因为流量过大，导致流量暴增，应用挂掉。为解决这个问题，一般需要在应用前端加入消息队列 可以控制活动的人数 可以缓解短时间内高流量压垮应用 用户的请求，服务器接收后，首先写入消息队列。假如消息队列长度超过最大数量，则直接抛弃用户请求或跳转到错误页面 秒杀业务根据消息队列中的请求信息，再做后续处理 总结 消息队列使用场景 应用解耦：A服务访问B服务，如果B服务挂了，那么会导致A服务调用错误。我们可以将A服务发送消息到MQ中，然后不再关系其他后续操作。由B服务订阅这个消息来处理业务 异步处理：用户注册之后发送邮箱激活和短信激活，传统的做法是三个任务一起完成之后返回（响应150ms）。我们可以在用户注册之后发送广播消息，此时另外两个服务订阅处理（响应50ms） 流量削锋：例如在秒杀场景，一般流量会很大，可能会导致服务挂了。我们可在用户请求之后，先加入到队列中。如果队列超过了一定的值，进行处理]]></content>
      <categories>
        <category>message-mq</category>
      </categories>
      <tags>
        <tag>消息中间件</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[高并发解决方案]]></title>
    <url>%2F2019%2F04%2F26%2Fconcurrence%2F%E9%AB%98%E5%B9%B6%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[扩容 所有代码: https://github.com/zhongjinlang/concurrent 简单点的升级内存,复杂点的,增加服务器,分担压力 垂直扩容：提高系统部件能力 水平扩容：增加更多系统成员来实现 扩容数据库 读操作扩展：redis、CDN等缓存 写操作扩展：Cassandra、Hbase等 缓存应用需要支撑大量并发量，但数据库的性能有限，所以使用缓存来减少数据库压力与提高访问性能 缓存特性 命中率 = 命中数 / （命中数 + 没有命中数） 最大元素(空间) 清空策略：FIFO/LFU/LRU/过期时间/随机 影响缓存命中率的因素 业务场景和业务需求缓存通常适合读多写少的业务场景，反之的使用意义并不多，命中率会很低 缓存的设计（策略和粒度)通常情况下缓存的粒度越小，命中率越高 缓存的容量和基础设施缓存的容量有限就会容易引起缓存的失效和被淘汰 缓存分类和应用场景 本地缓存：变成实现(成员变量、局部变量、静态变量)、guava cache 分布式缓存: memcache、redis 消息队列消息队列已经逐渐成为企业IT系统内部通信的核心手段。它具有低耦合、可靠投递、广播、流量控制、最终一致性等一系列功能，成为异步RPC的主要手段之一 发送短信使用场景比如用户下单成功时给用户发短信，如果没有这个消息队列，我们会选择同步调用发短信的接口，并等待短息发送成功，这时候假设短信接口实现出现问题了，或者短信调用端超时了，又或者短信发送达到上限了，我们是选择重试几次还是放弃，还是选择把这个放到数据库过一段时间再看看呢，不管怎样，实现都很复杂我们可以将发短信这个请求放在消息队列里，消息队列按照一定的顺序挨个处理队列里的消息，当处理到发送短信的任务时，通知短信服务发送消息，如果出现之前出现的问题，那么把这个消息重新放到消息队列中 消息队列的好处 成功完成了一个异步解耦的过程 保证了最终一致性，通过在队列中存放任务保证它最终一定会执行 广播, 如果没有消息队列，每当一个新的业务方接入，我们都要联调一次新接口。有了消息队列，我们只需要关心消息是否送达了队列，至于谁希望订阅，是下游的事情，无疑极大地减少了开发和联调的工作量 提速, 有了消息队列就不需要同步等待，我们可以直接并行处理 削峰和流控,不对于不需要实时处理的请求来说，当并发量特别大的时候，可以先在消息队列中作缓存，然后陆续发送给对应的服务去处理 拆分单个服务器再优化，它的处理能力都是有上限的。随着项目需求完成越来越多，应用自然也会越来越大，架构师将一个应用整体拆分成多个应用 拆分的原则 业务优先，确定业务边界 循序渐进，边拆分边测试 兼顾技术：重构、分层 可靠测试 拆分的思考 应用之间的通信：RPC（dubbo等）、消息队列 应用之间的数据库设计：每个应用都有独立的数据库 避免事务操作跨应用，分布式事务是一个非常消耗资源的问题。这样应用和应用的耦合度降低 应用拆分 服务化——Dubbo 微服务——SpringCloud 限流限流可以认为服务降级的一种，限流就是限制系统的输入和输出流量已达到保护系统的目的。一般来说系统的吞吐量是可以被测算的，为了保证系统的稳定运行，一旦达到的需要限制的阈值，就需要限制流量并采取一些措施以完成限制流量的目的。比如：延迟处理，拒绝处理，或者部分拒绝处理等等 限流本质上是控制某段代码在一定时间内执行的次数 限流算法 计数器 漏桶算法 令牌桶算法 服务降级与服务熔断服务降级服务压力剧增的时候根据当前的业务情况及流量对一些服务和页面有策略的降级，以此缓解服务器的压力，以保证核心任务的进行。同时保证部分甚至大部分任务客户能得到正确的相应。也就是当前的请求处理不了了或者出错了，给一个默认的返回 服务熔断在股票市场，熔断这个词大家都不陌生，是指当股指波幅达到某个点后，交易所为控制风险采取的暂停交易措施。相应的，服务熔断一般是指软件系统中，由于某些原因使得服务出现了过载现象，为防止造成整个系统故障，从而采用的一种保护措施，所以很多地方把熔断亦称为过载保护 总结 限流：控制一段代码在一定时间内执行的次数 服务降级：服务器压力很大的时间，但又要给客户端响应正确的数据，可以设计好一个默认的返回信息 服务熔断：为了防止服务器系统故障，采取的一种保护措施]]></content>
      <categories>
        <category>Java并发系列文章</category>
      </categories>
      <tags>
        <tag>限流</tag>
        <tag>降级</tag>
        <tag>熔断</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[线程池]]></title>
    <url>%2F2019%2F04%2F26%2Fconcurrence%2F%E7%BA%BF%E7%A8%8B%E6%B1%A0%2F</url>
    <content type="text"><![CDATA[前言如果并发的线程数量很多，并且每个线程都是执行一个时间很短的任务就结束了，这样频繁创建线程就会大大降低系统的效率，因为频繁创建线程和销毁线程需要时间。那么有没有一种办法使得线程可以复用，就是执行完一个任务，并不被销毁，而是可以继续执行其他的任务？在Java中可以通过线程池来达到这样的效果 new Thread的弊端 每次new Thread新建对象，性能差 线程缺乏统一管理，可能无限制的新建线程，互相竞争，有可能占用过多系统资源 缺少更多的功能，如更多的执行、定期执行、线程中断 ThreadPoolExecutorjava.uitl.concurrent.ThreadPoolExecutor类是线程池中最核心的一个类，因此如果要透彻地了解Java中的线程池，必须先了解这个类 所有的线程池 构造核心参数 corePoolSize：核心线程数量 maximumPoolSize：线程最大线程数 workQueue: 阻塞队列，存储等待执行的任务，很重要，会对线程池允许过程产生重要影响 keepAliveTime: 表示线程没有任务执行时最多保持多久时间会终止 unit：参数keepAliveTime的时间单位，有7种取值，在TimeUnit类中有7种静态属性 threadFactory: 线程工厂，用来创建下线程 rejectHandler: 当拒绝处理任务时的策略 核心方法 execute()：提交任务，交给线程池执行 submit(): 提交任务，能够返回执行结果 execute + future shutdown(): 关闭线程池，等待任务都执行完 shutdownNow(): 关闭线程之，不等待任务执行完，暂停 线程监控方法 getTaskCount(): 线程池已执行和未执行的任务总数 getCompletedTaskCount: 已完成的任务数量 getPoolSize(): 线程池当前的线程数量 getActiveCount(): 当前线程池中正在执行任务的线程数量 线程池类图 四种线程池Executors：提供了一系列静态工厂方法用于创建各种线程池 newCachedThreadPool：创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程 newFixedThreadPool: 创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待 newScheduledThreadPool: 创建一个定长线程池，支持定时及周期性任务执行 newSingleThreadExecutor: 创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行 缓存线程池123456789101112131415161718@Slf4jpublic class ThreadPoolExample1 &#123; public static void main(String[] args) &#123; ExecutorService executorService = Executors.newCachedThreadPool(); for (int i = 0; i &lt; 10; i++)&#123; final int index = i; executorService.execute(new Runnable() &#123; @Override public void run() &#123; log.info("task:&#123;&#125; ", index); &#125; &#125;); &#125; executorService.shutdown(); &#125;&#125;]]></content>
      <categories>
        <category>Java并发系列文章</category>
      </categories>
      <tags>
        <tag>线程池</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[J.U.C之AQS]]></title>
    <url>%2F2019%2F04%2F25%2Fconcurrence%2FJ.U.C%E4%B9%8BAQS%2F</url>
    <content type="text"><![CDATA[AbstractQueuedSynchronizer(AQS)概述类如其名，抽象的队列式的同步器，AQS定义了一套多线程访问共享资源的同步器框架，许多同步类实现都依赖于它，如常用的ReentrantLock、Semaphore、CountDownLatch。它维护了一个volatile int state（代表共享资源）和一个FIFO线程等待队列（多线程争用资源被阻塞时会进入此队列） 使用Node实现FIFO队列，可以同于构建锁或其他同步装置的基础框架 利用了一个int类型表示状态 子类通过继承并通过实现它的方法管理其状态acquire和release的方法操纵状态 可以同时实现排它锁和共享锁模式（独占、共享） JDK提供了许多AQS的子类，如下是常用的同步组件: CountDownLatchCountDownLatch是一个同步工具类，它允许一个或多个线程一直等待，直到其他线程的操作执行完后再执行CountDownLatch是通过一个计数器来实现的，计数器的初始值为线程的数量。每当一个线程完成了自己的任务后，计数器的值就会减1。当计数器值到达0时，它表示所有的线程已经完成了任务，然后在闭锁上等待的线程就可以恢复执行任务使用场景 实现最大的并行性 开始执行前等待n个线程完成各自任务 死锁检测 使用演示12345678910111213141516171819202122232425262728293031323334353637@Slf4jpublic class CountDownLatchExample1 &#123; // 给定测试的线程数 private final static int threadCount = 200; public static void main(String[] args) throws InterruptedException &#123; ExecutorService exec = Executors.newCachedThreadPool(); final CountDownLatch countDownLatch = new CountDownLatch(threadCount); for (int i = 0; i &lt; threadCount; i++) &#123; final int threadNum = i; // 从线程池中开启线程 exec.execute(() -&gt; &#123; try &#123; // 调用方法 test(threadNum); &#125; catch (Exception e) &#123; log.error("exception", e); &#125; finally &#123; // 计数器-1 countDownLatch.countDown(); &#125; &#125;); &#125; // 线程等待 countDownLatch.await(); log.info("完成"); // 关闭资源 exec.shutdown(); &#125; private static void test(int threadNum) throws Exception &#123; log.info("&#123;&#125;", threadNum); Thread.sleep(100); &#125;&#125; 使用了await，从输出结果可看出”完成”这句话是在所有线程执行完之后才执行的。因此await可保证之前的线程执行完例如我们写了很多个线程去完成一个任务，希望这个任务在指定的时间内完成可使用如下代码 Semaphore它可控制同一时间并发线程的数目 通常用于限制可以访问某些资源（物理或逻辑的）线程数目 面试题思考在很多情况下，可能有多个线程需要访问数目很少的资源。假想在服务器上运行着若干个回答客户端请求的线程。这些线程需要连接到同一数据库，但任一时刻只能获得一定数目的数据库连接。你要怎样才能够有效地将这些固定数目的数据库连接分配给大量的线程？ 给方法加同步锁，保证同一时刻只能有一个人去调用此方法，其他所有线程排队等待，但是此种情况下即使你的数据库链接有10个，也始终只有一个处于使用状态。这样将会大大的浪费系统资源，而且系统的运行效率非常的低下 另外一种方法当然是使用信号量，通过信号量许可与数据库可用连接数相同的数目，将大大的提高效率和性能 演示控制并发数量12345678910111213141516171819202122232425262728293031323334@Slf4jpublic class SemaphoreExample1 &#123; // 给定测试的线程数 private final static int threadCount = 20; public static void main(String[] args) throws InterruptedException &#123; ExecutorService exec = Executors.newCachedThreadPool(); // 给定允许的并发数 final Semaphore semaphore = new Semaphore(3); for (int i = 0; i &lt; threadCount; i++) &#123; final int threadNum = i; // 从线程池中开启线程 exec.execute(() -&gt; &#123; try &#123; // 调用方法 // 对并发控制的代码前后要包裹semaphore相关函数 semaphore.acquire(); // 获得许可 test(threadNum); semaphore.release(); // 释放许可 &#125; catch (Exception e) &#123; log.error("exception", e); &#125; &#125;); &#125; log.info("完成"); // 关闭资源 exec.shutdown(); &#125; private static void test(int threadNum) throws Exception &#123; log.info("&#123;&#125;", threadNum); Thread.sleep(1000); &#125;&#125; 输出结果可看出每一秒只有3个线程。证明了Semaphore对并发的控制 CyclicBarrierCyclicBarrier是一个同步辅助类，允许一组线程互相等待，直到到达某个公共屏障点 (common barrier point)。因为该 barrier 在释放等待线程后可以重用，所以称它为循环 的 barrier CountDownLatch和CyclicBarrier区别 CountDownLatch的作用是允许1或N个线程等待其他线程完成执行；而CyclicBarrier则是允许N个线程相互等待 CountDownLatch的计数器无法被重置；CyclicBarrier的计数器可以被重置后使用，因此它被称为是循环的barrier ReentrantLock在Java中通常实现锁有两种方式，一种是synchronized关键字，另一种是Lock。二者其实并没有什么必然联系，但是各有各的特点，在使用中可以进行取舍的使用。首先我们先对比下两者 Lock接口的实现之一：ReentrantLock(可重入性) 锁的实现：synchronization基于JVM 性能的区别 功能区别 ReentrantLock独有的功能(CAS算法) 可指定公平锁(先等待的线程先获取锁)还是非公平锁 提供了一个Condition类，可分组唤醒需要唤醒的线程 提供了中断等待锁线程的机制，lock.lockInterruptibly() 演示使用ReentrantLock123456789101112131415161718192021222324252627282930313233343536373839404142434445@Slf4j@ThreadSafepublic class LockExample2 &#123; // 请求总数 public static int clientTotal = 5000; // 同时并发执行的线程数 public static int threadTotal = 200; public static int count = 0; // 是哟个JUC的锁 private final static Lock lock = new ReentrantLock(); public static void main(String[] args) throws Exception&#123; ExecutorService executorService = Executors.newCachedThreadPool(); final Semaphore semaphore = new Semaphore(threadTotal); final CountDownLatch countDownLatch = new CountDownLatch(clientTotal); for (int i = 0; i &lt; clientTotal; i++)&#123; executorService.execute(()-&gt;&#123; try &#123; semaphore.acquire(); add(); semaphore.release(); &#125; catch (Exception e) &#123; log.error("exception", e); &#125; countDownLatch.countDown(); &#125;); &#125; countDownLatch.await(); executorService.shutdown(); log.info("count:&#123;&#125;", count); &#125; private static void add()&#123; // 加锁 lock.lock(); try &#123; count++; &#125;finally &#123; // 释放锁 lock.unlock(); &#125; &#125;&#125; ReentrantReadWriteLockReentrantReadWriteLock是Lock的另一种实现方式，我们已经知道了ReentrantLock是一个排他锁，同一时间只允许一个线程访问，而ReentrantReadWriteLock允许多个读线程同时访问，但不允许写线程和读线程、写线程和写线程同时访问。相对于排他锁，提高了并发性。在实际应用中，大部分情况下对共享数据（如缓存）的访问都是读操作远多于写操作，这时ReentrantReadWriteLock能够提供比排他锁更好的并发性和吞吐量 使用演示12345678910111213141516171819202122232425262728293031323334353637383940414243@Slf4j@ThreadSafepublic class LockExample3 &#123; private final Map&lt;String, Data&gt; map = new TreeMap&lt;&gt;(); private final ReentrantReadWriteLock lock = new ReentrantReadWriteLock(); // 定义读锁和写锁 private final Lock readLock = lock.readLock(); private final Lock writeLock = lock.writeLock(); // 对外提供线程安全的接口 public Data get(String key) &#123; readLock.lock(); // 读锁 try &#123; return map.get(key); &#125; finally &#123; readLock.unlock(); // 解锁 &#125; &#125; public Set&lt;String&gt; getAllKeys() &#123; readLock.lock(); // 读锁 try &#123; return map.keySet(); &#125; finally &#123; readLock.unlock(); // 解锁 &#125; &#125; public Data put(String key, Data value) &#123; writeLock.lock(); // 写锁 try &#123; return map.put(key, value); &#125; finally &#123; readLock.unlock(); // 解锁 &#125; &#125; class Data &#123; &#125;&#125; Callable | Runnable我们知道创建线程有两种方式：继承Thread、实现Runnable接口。这两种方式都有一个缺陷：在执行完任务之后无法获取执行结果从Java 1.5开始，就提供了Callable和Future，通过它们可以在任务执行完毕之后得到任务执行结果 Callable与Runnable对比123public interface Runnable &#123; public abstract void run();&#125; 只声明了run()方法，返回值为void，所以在执行完任务之后无法返回任何结果123public interface Callable&lt;V&gt; &#123; V call() throws Exception;&#125; 它是一个泛型接口，call返回类型就是传递进行来的V类型。通常与ExecutorService配合使用 Future | FutureTaskFuture就是对于具体的Runnable或者Callable任务的执行结果进行取消、查询是否完成、获取结果等必要时可以通过get方法获取执行结果，该方法会阻塞直到任务返回结果 FutureTask接口定义12public class FutureTask&lt;V&gt; implements RunnableFuture&lt;V&gt; &#123;&#125;public interface RunnableFuture&lt;V&gt; extends Runnable, Future&lt;V&gt; &#123;&#125; 它既可以作为Runnable被线程执行，又可以作为Future得到Callable的返回值 Future简单使用1234567891011121314151617181920212223242526@Slf4jpublic class FutureExample &#123; static class MyCallable implements Callable&lt;String&gt;&#123; @Override public String call() throws Exception &#123; log.info("do something in callable"); Thread.sleep(5000); return "Done"; &#125; &#125; public static void main(String[] args) throws InterruptedException, ExecutionException &#123; // 获取线程结果 ExecutorService exec= Executors.newCachedThreadPool(); // 提交任务 获取结果 Future&lt;String&gt; future = exec.submit(new MyCallable()); log.info("do something in main"); Thread.sleep(1000); // 阻塞 String result = future.get(); log.info("result: &#123;&#125;", result); &#125;&#125; FutureTask12345678910111213141516171819202122@Slf4jpublic class FutureTaskExample &#123; public static void main(String[] args) throws InterruptedException, ExecutionException &#123; FutureTask&lt;String&gt; futureTask = new FutureTask&lt;&gt;(new Callable&lt;String&gt;() &#123; @Override public String call() throws Exception &#123; log.info("do something in callable"); Thread.sleep(5000); return "Done"; &#125; &#125;); new Thread(futureTask).start(); log.info("do something in main"); Thread.sleep(1000); // 阻塞 String result = futureTask.get(); log.info("result: &#123;&#125;", result); &#125;&#125; 与Future对比简单了许多，直接在构造函数中创建callable接口对象 总结 synchronization锁由JVM会自动加锁和解锁。Lock类的锁需要手动加锁和必须释放锁(放在finally保证安全) 当只有少量线程时推荐使用synchronization。当线程由趋势增长或可预算可使用ReentrantLock Semaphore它可控制并发的数量 ReentrantReadWriteLock提供了读写锁 开启线程有继承Thread、实现Runnable接口，它们共同的缺陷就是在执行完任务之后无法获取执行结果。而callable接口的call方法有返回值 Future可以获取别人的线程任务方法的返回值，例如callable的 call()方法]]></content>
      <categories>
        <category>Java并发系列文章</category>
      </categories>
      <tags>
        <tag>AQS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[线程安全策略]]></title>
    <url>%2F2019%2F04%2F24%2Fconcurrence%2F%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E7%AD%96%E7%95%A5%2F</url>
    <content type="text"><![CDATA[不可变对象 不可变对象需要满足的条件 对象创建后状态不能修改 对象所有的域都是final 对象是正确创建的（在对象创建期间，this引用没有逸出） final 使用final来定义不可变对象 final关键字：类、方法、变量 修饰类：不能被继承 修饰方法：锁定方法不被继承类修改 修饰变量：基本数据类型变量（数值被初始化后不能被修改）、引用类型的变量（对象被初始后不能改变引用） 使用final修饰变量和引用1234567891011121314151617181920212223242526@Slf4j@NotThreadSafepublic class ImmutableExample1 &#123; private final static Integer a = 1; private final static String b = "2"; private final static Map&lt;Integer, Integer&gt; map = Maps.newHashMap(); static &#123; map.put(1, 2); map.put(3, 4); map.put(5, 6); &#125; public static void main(String[] args) &#123; // 基础数据类型不可修改 //a = 2; //b = "3"; // 不可改变引用 //map = Maps.newLinkedHashMap(); // 没有安全发布可使用，它是线程不安全的 map.put(1,3); log.info("&#123;&#125;", map.get(1)); &#125;&#125; final修饰引用数据类型不可改变引用。但是可修改值，所以Map是线程不安全的类 collections.unmodifiable除了final，JDK还提供了utils.collections.unmodifiable前缀的方法来定义不可变的对象 使用unmodifiableMap123456789101112131415161718@Slf4j@ThreadSafepublic class ImmutableExample2 &#123; private static Map&lt;Integer, Integer&gt; map = Maps.newHashMap(); static &#123; map.put(1, 2); map.put(3, 4); map.put(5, 6); // 处理后的map不可被修改 map = Collections.unmodifiableMap(map); &#125; public static void main(String[] args) &#123; map.put(1,3); log.info("&#123;&#125;", map.get(1)); // 不可操作 &#125;&#125; 使用unmodifiableMap使得map对象的值不可修改，因此上述代码达到了线程安全 线程封闭通过不可变对象在多个线程之间保证对象是线程安全的。归根到底我们是躲避了并发的问题。避免并发除了设计不可变对象，还有一个方法线程封闭：就是把对象封装到一个线程中，只有一个线程能看到该对象 Ad-hoc完全使用逻辑代码来控制实现，最糟糕的方法 堆栈封闭局部变量，多个线程访问一个方法的时候，方法中的局部变量都会被拷贝到一份到线程的栈中（我们经常在方法中声明的变量 ） ThreadLoad线程封闭特别好的封闭方法，内部实现通过一个mao，key是线程的名称，value为要封闭的对象。每一个线程中的对象都对应着它的map中的值 线程不安全类与写法线程不安全：如果一个类的对象同时可以被多个线程访问，如果没有做同步或并发处理。那么可能就会表现出线程不安全的现象本节介绍JDK自带的一些常用的类，这些类都不是线程安全的。 StringBuilder | StringBuffer StringBuilder是线程不安全的，性能高 StringBuffer是线程安全的，性能低 测试StringBuilder是否是线程安全12345678910111213141516171819202122232425262728293031323334353637@Slf4j@NotThreadSafepublic class StringExampele1 &#123; // 请求总数 public static int clientTotal = 5000; // 同时并发执行的线程数 public static int threadTotal = 200; public static StringBuilder stringBuilder = new StringBuilder(); public static void main(String[] args) throws Exception&#123; ExecutorService executorService = Executors.newCachedThreadPool(); final Semaphore semaphore = new Semaphore(threadTotal); final CountDownLatch countDownLatch = new CountDownLatch(clientTotal); for (int i = 0; i &lt; clientTotal; i++)&#123; executorService.execute(()-&gt;&#123; try &#123; semaphore.acquire(); update(); semaphore.release(); &#125; catch (Exception e) &#123; log.error("exception", e); &#125; countDownLatch.countDown(); &#125;); &#125; countDownLatch.await(); executorService.shutdown(); // 输出累加字符串个数 log.info("size:&#123;&#125;", stringBuilder.length() ); &#125; // 字符串累加 private static void update()&#123; stringBuilder.append("1"); &#125;&#125; 输出的个数不稳定，因此StringBuilder不是线程安全的。而采用StringBuffer是线程安全的分析StringBuffer源码分析123456@Override public synchronized StringBuffer append(String str) &#123; toStringCache = null; super.append(str); return this; &#125; SimpleDateFormatSimpleDateFormat的错误写法1234567891011121314151617181920212223242526272829303132333435363738394041@Slf4j@NotThreadSafepublic class DateFormateExample1 &#123; // TODO: 并不是局部变量 private static SimpleDateFormat simpleDateFormat = new SimpleDateFormat("yyyyMMdd"); // 请求总数 public static int clientTotal = 5000; // 同时并发执行的线程数 public static int threadTotal = 200; public static void main(String[] args) throws Exception&#123; ExecutorService executorService = Executors.newCachedThreadPool(); final Semaphore semaphore = new Semaphore(threadTotal); final CountDownLatch countDownLatch = new CountDownLatch(clientTotal); for (int i = 0; i &lt; clientTotal; i++)&#123; executorService.execute(()-&gt;&#123; try &#123; semaphore.acquire(); update(); semaphore.release(); &#125; catch (Exception e) &#123; log.error("exception", e); &#125; countDownLatch.countDown(); &#125;); &#125; countDownLatch.await(); executorService.shutdown(); &#125; // 字符串累加 private static void update()&#123; try &#123; simpleDateFormat.parse("2019422"); &#125; catch (ParseException e) &#123; log.error("parse exception", e); &#125; &#125;&#125; 上述代码运行会有异常。这是常犯的错误，如果我们将对象声明为局部变量（堆栈封闭）就不会有这种情况了 正确的写法123456789// 字符串累加private static void update()&#123; try &#123; SimpleDateFormat simpleDateFormat = new SimpleDateFormat("yyyyMMdd"); simpleDateFormat.parse("2019422"); &#125; catch (ParseException e) &#123; log.error("parse exception", e); &#125;&#125; 每次声明一个对象来使用这样就不会出现线程不安全带来的异常 ArrayList | HashSet | HashMap集合类是我们最为常用的类，通常我们都将其定义在方法中（局部变量）。因此很少出现线程不安全的情况。但是一但当定义为static时且有多个线程修改时，就容易出现线程不安全的问题 ArrayList123456789101112131415161718192021222324252627282930313233343536373839@Slf4j@NotThreadSafepublic class ArrayListExample &#123; // 请求总数 public static int clientTotal = 5000; // 同时并发执行的线程数 public static int threadTotal = 200; private static List&lt;Integer&gt; list = new ArrayList&lt;&gt;(); public static void main(String[] args) throws Exception&#123; ExecutorService executorService = Executors.newCachedThreadPool(); final Semaphore semaphore = new Semaphore(threadTotal); final CountDownLatch countDownLatch = new CountDownLatch(clientTotal); for (int i = 0; i &lt; clientTotal; i++)&#123; final int count = i; executorService.execute(()-&gt;&#123; try &#123; semaphore.acquire(); update(count); semaphore.release(); &#125; catch (Exception e) &#123; log.error("exception", e); &#125; countDownLatch.countDown(); &#125;); &#125; countDownLatch.await(); executorService.shutdown(); // 线程执行完输出 log.info("size: &#123;&#125;", list.size()); &#125; // 累加 private static void update(int i)&#123; list.add(i); &#125;&#125; 输出结果不是我们期望的值，说明arraylist在做add时有可能线程不安全。当然HashSet和HashMap同理 写法需要多考虑线程不安全的写法通常是这样的：先检查再执行，例如:123if (判断某个值)&#123; // 处理某个值...&#125; 我们思考一下这种写法，当判断的时候它可能满足条件，如果两个线程都进入了判断，那么都会分别进行处理，这个时就会产生线程不安全。出现不安全的点在于，分成了两个操作之后j即使之前的过程(判断)是线程安全的，后面(处理)也是线程安全的，但它们”间隙的过程中”并不是原子性的实际开发中，当我们在判断一个对象是否满足某个条件再执行某些处理的时候，需要考虑到这个对象是否是多线程共享的，如果是，那么就需要将对象加锁。或保证它们的操作具有原子性的 线同步容器针对上述线程不安全的类ArrayList、HashSet、HashMap。JDK提供了对应的线程安全的类来使用 ArrayList &gt; Vectory | StackVectory和stack类结构:1public class Vector&lt;E&gt;extends AbstractList&lt;E&gt;implements List&lt;E&gt;, ... 1public class Stack&lt;E&gt;extends Vector&lt;E&gt; 使用vector测试线程安全123456789101112131415161718192021222324252627282930313233343536373839@Slf4j@ThreadSafepublic class VectorExample &#123; // 请求总数 public static int clientTotal = 5000; // 同时并发执行的线程数 public static int threadTotal = 200; private static List&lt;Integer&gt; list = new Vector&lt;&gt;(); public static void main(String[] args) throws Exception&#123; ExecutorService executorService = Executors.newCachedThreadPool(); final Semaphore semaphore = new Semaphore(threadTotal); final CountDownLatch countDownLatch = new CountDownLatch(clientTotal); for (int i = 0; i &lt; clientTotal; i++)&#123; final int count = i; executorService.execute(()-&gt;&#123; try &#123; semaphore.acquire(); update(count); semaphore.release(); &#125; catch (Exception e) &#123; log.error("exception", e); &#125; countDownLatch.countDown(); &#125;); &#125; countDownLatch.await(); executorService.shutdown(); // 线程执行完输出 log.info("size: &#123;&#125;", list.size()); &#125; // 累加 private static void update(int i)&#123; list.add(i); &#125;&#125; 观察其add的实现123456public synchronized boolean add(E e) &#123; modCount++; ensureCapacityHelper(elementCount + 1); elementData[elementCount++] = e; return true; &#125; 同步器也有不安全的情况123456789101112131415161718192021222324252627282930313233343536// 同步容器也有线程不安全的情况public class VectoryExample2 &#123; private static Vector&lt;Integer&gt; list = new Vector&lt;&gt;(); public static void main(String[] args) &#123; while (true)&#123; // 向集合中存10个值 for (int i = 0; i &lt; 10; i++)&#123; list.add(i); &#125; /** * vector虽然能保证同一时刻只有一个线程能访问他，但是不排除如下情况 * 1. 当t2线程执行到i &lt; list.size()时，t1线程也可能执行了i &lt; list.size()，它正好将当前i元素移出掉了 * 2. 这个时候get方法就获取不了所删除的元素了，因此抛出数组越界异常 */ // 开启两个线程 Thread t1 = new Thread(() -&gt; &#123; for (int i = 0; i &lt; list.size(); i++)&#123; list.remove(i); // 删除(synchronization) &#125; &#125;); Thread t2 = new Thread(() -&gt; &#123; for (int i = 0; i &lt; list.size(); i++)&#123; list.get(i); // 获取(synchronization) &#125; &#125;); // 启动两个线程 t1.start(); t2.start(); &#125; &#125;&#125; HashMap &gt; HashTableHashTable与HashMap不同，前者key和value不能为null。后者可以HashTable类结构1public class Hashtable&lt;K,V&gt;extends Dictionary&lt;K,V&gt;implements Map&lt;K,V&gt;, ... HashTable演示线程安全123456789101112131415161718192021222324252627282930313233343536373839@Slf4j@ThreadSafepublic class HashTableExample &#123; // 请求总数 public static int clientTotal = 5000; // 同时并发执行的线程数 public static int threadTotal = 200; private static Map&lt;Integer,Integer&gt; map = new Hashtable&lt;&gt;(); public static void main(String[] args) throws Exception&#123; ExecutorService executorService = Executors.newCachedThreadPool(); final Semaphore semaphore = new Semaphore(threadTotal); final CountDownLatch countDownLatch = new CountDownLatch(clientTotal); for (int i = 0; i &lt; clientTotal; i++)&#123; final int count = i; executorService.execute(()-&gt;&#123; try &#123; semaphore.acquire(); update(count); semaphore.release(); &#125; catch (Exception e) &#123; log.error("exception", e); &#125; countDownLatch.countDown(); &#125;); &#125; countDownLatch.await(); executorService.shutdown(); // 线程执行完输出 log.info("size: &#123;&#125;", map.size()); &#125; // 累加 private static void update(int i)&#123; map.put(i, i); &#125;&#125; 观察其put的实现123456public synchronized V put(K key, V value) &#123; // Make sure the value is not null if (value == null) &#123; throw new NullPointerException(); &#125; ... Collections.synchronization..使用集合工具类来创建同步容器类 将List构建为同步容器1234567891011121314151617181920212223242526272829303132333435363738394041@Slf4j@ThreadSafepublic class CollectionsExample1 &#123; // 请求总数 public static int clientTotal = 5000; // 同时并发执行的线程数 public static int threadTotal = 200; // 将List构建为同步的类 private static List&lt;Integer&gt; list = Collections.synchronizedList(Lists.newArrayList() ); public static void main(String[] args) throws Exception&#123; ExecutorService executorService = Executors.newCachedThreadPool(); final Semaphore semaphore = new Semaphore(threadTotal); final CountDownLatch countDownLatch = new CountDownLatch(clientTotal); for (int i = 0; i &lt; clientTotal; i++)&#123; final int count = i; executorService.execute(()-&gt;&#123; try &#123; semaphore.acquire(); update(count); semaphore.release(); &#125; catch (Exception e) &#123; log.error("exception", e); &#125; countDownLatch.countDown(); &#125;); &#125; countDownLatch.await(); executorService.shutdown(); // 线程执行完输出 log.info("size: &#123;&#125;", list.size()); &#125; // 累加 private static void update(int i)&#123; list.add(i); &#125;&#125; 上述代码是线程安全的 List.remove注意事项演示遍历集合并删除集合中指定元素的值 123456789101112131415161718192021222324252627282930313233343536373839404142434445@NotThreadSafepublic class VectoryExample3 &#123; // 三个方法：遍历集合对指定元素删除 // ConcurrentModificationException private static void test1(Vector&lt;Integer&gt; v1)&#123; for (Integer data : v1) &#123; if (data.equals(3))&#123; v1.remove(data); &#125; &#125; &#125; //ConcurrentModificationException private static void test2(Vector&lt;Integer&gt; v1)&#123; Iterator&lt;Integer&gt; iterator = v1.iterator(); while (iterator.hasNext())&#123; Integer data = iterator.next(); if (data.equals(3))&#123; v1.remove(data); &#125; &#125; &#125; // ok private static void test3(Vector&lt;Integer&gt; v1)&#123; for (int i = 0; i &lt; v1.size(); i++)&#123; if (v1.get(i).equals(3))&#123; v1.remove(i); &#125; &#125; &#125; public static void main(String[] args) &#123; Vector&lt;Integer&gt; vector = new Vector&lt;&gt;(); vector.add(1); vector.add(2); vector.add(3); test1(vector); //test2(vector); //test3(vector); &#125;&#125; 上述代码执行会出现如下异常信息我们进入checkForComodification观察源代码我们可以发现，对于一个集合遍历的同时，如果对集合进行修改的操作导致了modCount和expectedModCount不一致，从而抛出该异常 结论 如果使用了foreach和iterator循环集合时，尽量不要在操作过程中做remove等相关的更新操作 如果需要删除，使用iterator.remove()方法，或for循环获取id再进行删除 并发容器JDK提供了线程安全的集合和Map，在utils.concurrent包 ArrayList-&gt; CopyOnWriteArrayList HashSet-&gt; CopyOnWriteArraySet TreeSet-&gt; ConcurrentSkipListSet CopyOnWriteArrayListCopyOnWrite容器即写时复制的容器。通俗的理解是当我们往一个容器添加元素的时候，不直接往当前容器添加，而是先将当前容器进行Copy，复制出一个新的容器，然后新的容器里添加元素，添加完元素之后，再将原容器的引用指向新的容器。这样做的好处是我们可以对CopyOnWrite容器进行并发的读，而不需要加锁，因为当前容器不会添加任何元素。所以CopyOnWrite容器也是一种读写分离的思想，读和写不同的容器。使用场景：读多写少 观察其add方法实现1234567891011121314public boolean add(E e) &#123; final ReentrantLock lock = this.lock; // 采用lock锁 lock.lock(); try &#123; Object[] elements = getArray(); int len = elements.length; Object[] newElements = Arrays.copyOf(elements, len + 1); // 拷贝数组 newElements[len] = e; // 创建一个数组后指向新的数组 setArray(newElements); return true; &#125; finally &#123; lock.unlock(); &#125; &#125; 总结 JDK提供的线程安全类 根据实际分析变量，是否可以变为不可变对象，如果可以尽量将一个对象变为不可变对象。这样在多线程环境下就不会出现线程安全问题 线程封闭: 把对象封装到一个线程中，只有一个线程可以看到这个对象(ThreadLoad) List删除指定元素要注意可能会抛出ConcurrentModificationException。解iterator.remove()方法或for循环或id再进行删除。如果在多线程环境下采用synchronization或并发容器代替vector(同步容器)]]></content>
      <categories>
        <category>Java并发系列文章</category>
      </categories>
      <tags>
        <tag>final</tag>
        <tag>集合</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[安全发布对象]]></title>
    <url>%2F2019%2F04%2F22%2Fconcurrence%2F%E5%AE%89%E5%85%A8%E5%8F%91%E5%B8%83%E5%AF%B9%E8%B1%A1%2F</url>
    <content type="text"><![CDATA[什么是发布对象?发布对象：使一个对象能够被当前范围之外的外码所使用对象逸出：一种错误的发布，当一个对象还没有构造完成时，就被其他线程所见了 不安全的发布对象案例123456789101112131415161718@Slf4j@NotThreadSafepublic class UnsafePublish &#123; private String[] status = &#123;"a", "b", "c"&#125;; public String[] getStatus() &#123; return status; &#125; public static void main(String[] args) &#123; UnsafePublish unsafePublish = new UnsafePublish(); log.info("&#123;&#125;", Arrays.toString(unsafePublish.getStatus())); // abc unsafePublish.getStatus()[0] = "z"; log.info("&#123;&#125;", Arrays.toString(unsafePublish.getStatus())); // zbc &#125;&#125; 可能产生对象逸出12345678910111213141516171819202122@Slf4j@NotThreadSafe@NotRecommendpublic class Escape &#123; private int thisCanBeEscape = 0; public Escape() &#123; new innerClass(); &#125; private class innerClass&#123; // 对象没有被正确构造之前就发布对象，可能会不安全 public innerClass() &#123; log.info("&#123;&#125;", Escape.this.thisCanBeEscape); // 启动了另一个对象引用 &#125; &#125; public static void main(String[] args) &#123; new Escape(); &#125;&#125; 安全发布对象安全发布对象的四种方法： 在静态初始化函数中初始化一个对象引用 将对象的引用保存到volatile类型域或者AtomicReference对象中 将对象的引用保存到某个正确的构造对象的final类型域中 将对象的引用保存到一个由锁保护的域中 此时我们会想到采用单例模式来构建一个对象 单例-懒汉模式1234567891011121314151617181920/** * 懒汉模式：单例实例在第一次使用时创建 * 单线程环境下安全，但是多线程环境不安全 */@NotThreadSafepublic class SingleExample1 &#123; private SingleExample1()&#123;&#125; // 单例对象 private static SingleExample1 instance = null; // 静态工厂方法 public static SingleExample1 getInstance()&#123; if (instance == null)&#123; // 不安全，如果有其他线程进入该判断 instance = new SingleExample1(); &#125; return instance; &#125;&#125; 懒汉模式线程不安全，当然可以使用synchronization修饰方法这样就线程安全了。但是不推荐，会导致性能下降 单例-饿汉模式1234567891011121314151617/** * 饿汗模式：单例实例在类加载时就进行创建 * */@ThreadSafepublic class SingleExample2 &#123; private SingleExample2()&#123;&#125; // 单例对象 private static SingleExample2 instance = new SingleExample2(); // 静态工厂方法 public static SingleExample2 getInstance()&#123; return instance; &#125;&#125; 饿汉模式是线程安全的 优化懒汉模式使用双重检测机制1234567891011121314151617181920@NotThreadSafepublic class SingleExample4 &#123; private SingleExample4()&#123;&#125; // 单例对象 private volatile static SingleExample4 instance = null; // 静态工厂方法 public static SingleExample4 getInstance()&#123; if (instance == null) &#123; // 双从检测机制 synchronized (SingleExample4.class)&#123; // 同步锁 if (instance == null)&#123; instance = new SingleExample4(); &#125; &#125; &#125; return instance; &#125;&#125; 注意：必须加上volatile否则还是线程不安全的。因为可能会导致指令重排问题。而volatile有个使用场景其中的双重检测机制 枚举发布安全对象12345678910111213141516171819202122232425262728@ThreadSafe@Recommendpublic class SingleExample5 &#123; private SingleExample5()&#123;&#125; // 返回枚举声明的对象 public static SingleExample5 getInstance()&#123; return Singleton.INSTANCE.getInstance(); &#125; private enum Singleton&#123; INSTANCE; private SingleExample5 single; // 给私有变量创建对象 // JVM保证这个方法只会被调用一次 Singleton() &#123; single = new SingleExample5(); &#125; // 返回私有变量 public SingleExample5 getInstance()&#123; return single; &#125; &#125;&#125; 枚举发布安全对象是对比单例模式更为推荐的。因为它会在实际调用的时候才会初始化，不会造成资源的浪费 总结 发布对象：使一个对象能够被当前范围之外的外码所使用 对象逸出：一种错误的发布，当一个对象还没有构造完成时，就被其他线程所见了 单例-懒汉模式：对象在第一次使用时进行创建，它是线程不安全的。可使用volatile的双重检测机制来实现 单例-饿汉模式：类装载的时候就进行创建，它是线程安全的 volatile可禁止指令重排，具有有序性]]></content>
      <categories>
        <category>Java并发系列文章</category>
      </categories>
      <tags>
        <tag>单例</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[线程安全性]]></title>
    <url>%2F2019%2F04%2F22%2Fconcurrence%2F%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E6%80%A7%2F</url>
    <content type="text"><![CDATA[线程安全性概述当多个线程访问某个类时，不管运行时环境采用何种调度方式，或者这些进程将如何交替执行，并且在主调代码中不需要任何额外的同步或协同，这个类能表现出正确的行为，那么就称这个类是线程安全的线程安全在主要三个方面体现： 原子性：提供互斥访问，同一时刻只能有一个线程对数据进行操作，（atomic,synchronized） 可见性：一个线程对主内存的修改可以及时地被其他线程看到，（synchronized,volatile） 有序性：一个线程观察其他线程中的指令执行顺序，由于指令重排序，该观察结果一般杂乱无序 我们分别对上述概念进行一一描述 原子性—Atomic AtomicInteger、AtomicLong、LongAdder将上一篇的代码修改如下：1234567891011121314151617181920212223242526272829303132333435363738@Slf4j@ThreadSafepublic class ConcurrentExample2 &#123; // 请求总数 public static int clientTotal = 5000; // 同时并发执行的线程数 public static int threadTotal = 50; // TODO: Atomic public static AtomicInteger count = new AtomicInteger(0); public static void main(String[] args) throws Exception&#123; ExecutorService executorService = Executors.newCachedThreadPool(); final Semaphore semaphore = new Semaphore(threadTotal); final CountDownLatch countDownLatch = new CountDownLatch(clientTotal); for (int i = 0; i &lt; clientTotal; i++)&#123; executorService.execute(()-&gt;&#123; try &#123; semaphore.acquire(); add(); semaphore.release(); &#125; catch (Exception e) &#123; log.error("exception", e); &#125; countDownLatch.countDown(); &#125;); &#125; countDownLatch.await(); executorService.shutdown(); log.info("count:&#123;&#125;", count); &#125; // 计数 private static void add()&#123; // TODO: Atomic count.incrementAndGet(); &#125;&#125; 此时测试数字为5000，保证了数据的一致性，我们来分析atomic源码 也可使用AtomicLong、LongAdder替代AtomicInteger incrementAndGet()源码分析第一部分123public final int incrementAndGet() &#123; return unsafe.getAndAddInt(this, valueOffset, 1) + 1; &#125; 第二部分12345678public final int getAndAddInt(Object var1, long var2, int var4) &#123; int var5; do &#123; var5 = this.getIntVolatile(var1, var2); &#125; while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4)); return var5; &#125; 在一个死循环内不断的尝试修改值，直到修改成功。实现原理采用CAS： CASCAS的全称是Compare And Swap 即比较交换，其算法核心思想如下 执行函数：CAS(V,E,N) V表示要更新的变量 E表示预期值-N表示新值 CAS 指的是现代 CPU 广泛支持的一种对内存中的共享数据进行操作的一种特殊指令。这个指令会对内存中的共享数据做原子的读写操作。简单介绍一下这个指令的操作过程：首先，CPU 会将内存中将要被更改的数据与期望的值做比较。然后，当这两个值相等时，CPU 才会将内存中的数值替换为新的值。否则便不做操作。最后，CPU 会将旧的数值返回。这一系列的操作是原子的。它们虽然看似复杂，但却是 Java 5 并发机制优于原有锁机制的根本。简单来说，CAS 的含义是“我认为原有的值应该是什么，如果是，则将原有的值更新为新值，否则不做修改，并告诉我原来的值是多少” AtomicReference、AtomicIntegerFieldUpdater AtomicReference对对象进行原子操作 AtomicIntegerFieldUpdater可以对指定类的指定 volatile int 字段进行原子更新 AtomicReference测试原子性 1234567891011121314151617@Slf4j@ThreadSafepublic class ConcurrentExample4 &#123; private static AtomicReference&lt;Integer&gt; count = new AtomicReference&lt;&gt;(0); public static void main(String[] args) &#123; // 当为0的时候赋值2...以此类推 count.compareAndSet(0,2); // 2 count.compareAndSet(0,1); // no count.compareAndSet(1,3); // no count.compareAndSet(2,4); // 4 count.compareAndSet(3,5); // no log.info("count:&#123;&#125;", count.get() ); // 输出4 &#125;&#125; AtomicIntegerFieldUpdater测试原子性12345678910111213141516171819202122232425@Slf4j@ThreadSafepublic class ConcurrentExample5 &#123; // T: 要更新的类字节码。fieleName: 类中的字段名称(volatile修饰且非static) // 原子性更新某个类的指定字段的值 private static AtomicIntegerFieldUpdater&lt;ConcurrentExample5&gt; updater = AtomicIntegerFieldUpdater.newUpdater(ConcurrentExample5.class, "count"); @Getter public volatile int count = 100; private static ConcurrentExample5 example5 = new ConcurrentExample5(); public static void main(String[] args) &#123; // 如果该类的字段为100那么将其更新为120 if (updater.compareAndSet(example5, 100, 120))&#123; log.info("更新成功【第一次】 &#123;&#125;", example5.getCount()); // info &#125; if (updater.compareAndSet(example5, 100, 120))&#123; log.info("更新成功【第二次】 &#123;&#125;", example5.getCount()); &#125;else &#123; log.info("更新失败【第二次】&#123;&#125;", example5.getCount() ); // info &#125; &#125;&#125; AtomicBoolean1234567891011121314151617181920212223242526272829303132333435363738@Slf4j@ThreadSafepublic class ConcurrentExample6 &#123; private static AtomicBoolean isHappend = new AtomicBoolean(false); // 请求总数 public static int clientTotal = 5000; // 同时并发执行的线程数 public static int threadTotal = 50; public static void main(String[] args) throws Exception&#123; ExecutorService executorService = Executors.newCachedThreadPool(); final Semaphore semaphore = new Semaphore(threadTotal); final CountDownLatch countDownLatch = new CountDownLatch(clientTotal); for (int i = 0; i &lt; clientTotal; i++)&#123; executorService.execute(()-&gt;&#123; try &#123; semaphore.acquire(); test(); semaphore.release(); &#125; catch (Exception e) &#123; log.error("exception", e); &#125; countDownLatch.countDown(); &#125;); &#125; countDownLatch.await(); executorService.shutdown(); log.info("执行了:&#123;&#125;", isHappend.get() ); &#125; private static void test()&#123; // 如果当前值为false，设置为true if (isHappend.compareAndSet(false,true))&#123; log.info("方法执行了:&#123;&#125;", isHappend.get() ); // 执行一次 &#125; &#125;&#125; 上述代码，让test执行5000次，因为条件成立。因为条件成立了，其他线程将不会执行 使用场景：该如何让某一段代码只执行一次，绝对不会重复 原子性—锁原子性提供了互斥访问，同一时刻只能有一个线程进行操作。能保证同一时刻只有一个线程对其操作 Lock依赖特殊的CPU指令，实现代表类有：ReentrantLock synchronization它是Java的关键字，依赖于JVM来实现锁。因此这个关键字作用对象的作用范围内，都是同一时刻只能有一个线程 修饰代码块：范围【大括号括起来的代码】，作用的对象【调用这个代码块的对象】 修饰方法：范围【整个方法】，作用的对象【调用这个方法的对象】 修饰静态方法：范围【整个静态方法】，作用的对象【这个类的所有对象】 修饰类：范围【括号括起来的部分】，作用的对象【这个类的所有对象】 作用于同一个对象验证使用synchronization修饰方法和代码块，作用于同一个对象12345678910111213141516171819202122232425262728@Slf4jpublic class SyncExample1 &#123; // 修饰代码块：作用于一个对象 public void test1()&#123; synchronized (this)&#123; for(int i = 0; i &lt; 10; i++)&#123; log.info("test1 - &#123;&#125;", i); &#125; &#125; &#125; // 修饰一个方法：作用于一个对象 public synchronized void test2()&#123; for(int i = 0; i &lt; 10; i++)&#123; log.info("test2 - &#123;&#125;", i); &#125; &#125; public static void main(String[] args) &#123; SyncExample1 example1 = new SyncExample1(); // 线程池：保证 ExecutorService executorService = Executors.newCachedThreadPool(); // 开启两个线程执行方法【一个对象:example1】 executorService.execute(() -&gt; example1.test2()); executorService.execute(() -&gt; example1.test2()); &#125;&#125; 第一个线程输出0-9，第二个线程输出0-9… 作用于不同的对象验证使用不同的对象会乱序输出123456789101112131415161718192021222324252627282930@Slf4jpublic class SyncExample1 &#123; // 修饰代码块：作用于一个对象 public void test1()&#123; synchronized (this)&#123; for(int i = 0; i &lt; 10; i++)&#123; log.info("test1 - &#123;&#125;", i); &#125; &#125; &#125; // 修饰一个方法：作用于一个对象 public synchronized void test2()&#123; for(int i = 0; i &lt; 10; i++)&#123; log.info("test2 - &#123;&#125;", i); &#125; &#125; public static void main(String[] args) &#123; SyncExample1 example1 = new SyncExample1(); // TODO 再声明一个对象 SyncExample1 example2 = new SyncExample1(); // 线程池 ExecutorService executorService = Executors.newCachedThreadPool(); // 开启两个线程执行方法【一个对象:example1】 executorService.execute(() -&gt; example1.test2()); executorService.execute(() -&gt; example2.test2()); // TODO 不同的对象进行调用 &#125;&#125; 此时输出结果为： 作用于这个类的所有对象验证使用synchronization修饰静态方法和类，作用于该类的所有对象都是线程安全的123456789101112131415161718192021222324252627282930@Slf4jpublic class SyncExample2 &#123; // 修饰一个类 public static void test1()&#123; synchronized (SyncExample2.class)&#123; for(int i = 0; i &lt; 10; i++)&#123; log.info("test1 - &#123;&#125;", i); &#125; &#125; &#125; // 修饰一个静态方法：作用于这个类的所有对象 public static synchronized void test2()&#123; for(int i = 0; i &lt; 10; i++)&#123; log.info("test2 - &#123;&#125;", i); &#125; &#125; public static void main(String[] args) &#123; SyncExample2 example1 = new SyncExample2(); // TODO 再声明一个对象 SyncExample2 example2 = new SyncExample2(); // 线程池 ExecutorService executorService = Executors.newCachedThreadPool(); // 开启两个线程执行方法【一个对象:example1】 executorService.execute(() -&gt; example1.test1()); executorService.execute(() -&gt; example2.test1()); // TODO 不同的对象进行调用 &#125;&#125; 注意: synchronization修饰方法和代码块不同，上述代码正确顺序执行 原子性对比 synchronization：不可中断的锁，适合线程竞争不激烈的情况，可读性好 Lock：可中断的锁，多样同步，竞争激烈时能维持常态 Atmoic：竞争激烈时能维持常态，比Lock性能好。但是只能同步一个值 可见性一个线程对主内存的修改可即使的被其他线程观察到导致共享变量在线程间不可见的原因 线程交叉线执行 重排序结合线程交叉线执行 共享变量更新后的值没有在工作内存与主存之间即使更新(Java内存模型) 对于可见性JVM提供了synchronization和volatile JVM对于synchronization的两条规定 线程解锁前，必须把共享变量最新的值刷新到主内存中 线程加锁时，将清空工作内存中共享变量的值，从而使用共享变量时需要从主内存中重新读取最新的值（加锁与解锁是同一把锁） volatile当一个共享变量被volatile修饰时，它会保证修改的值会立即被更新到主存，当有其他线程需要读取时，它会去内存中读取新值。注意volatile不具备原子性 通过加入内存屏障和静止重排序优化来实现 对volatile变量写操作时，会在写操作后加入一条store屏障指令，将本地内存中的共享变量值刷新到主内存 对volatile变量读操作时，会在读操作前加入一条load屏障指令，从主内存中读取共享变量 使用场景首先必须具备以下条件 对变量的写操作不依赖于当前值 该变量没有包含在具有其他变量的不变式中 1. 标记变量的值123456789volatile boolean flag = false; while(!flag)&#123; doSomething();&#125; public void setFlag() &#123; flag = true;&#125; 2.double check123456789101112131415class Singleton&#123; private volatile static Singleton instance = null; private Singleton() &#123; &#125; public static Singleton getInstance() &#123; if(instance==null) &#123; synchronized (Singleton.class) &#123; if(instance==null) instance = new Singleton(); &#125; &#125; return instance; &#125;&#125; 有序性在Java内存模型中，允许编译器和处理器对指令进行重排序，但是重排序过程不会影响到单线程程序的执行，却会影响到多线程并发执行的正确性 Java内存模型具备一些先天的“有序性”，即不需要通过任何手段就能够得到保证的有序性，这个通常也称为 happens-before 原则。如果两个操作的执行次序无法从happens-before原则推导出来，那么它们就不能保证它们的有序性，虚拟机可以随意地对它们进行重排序 通过volatile、synchronization、lock volatile静止指令重排，保证了有序性 总结 原子性：原子性主要提供了互斥访问，同一时刻只能有一个线程进行操作。JDK提供了Atomic包、CAS算法、synchronization、Lock 可见性：可见性是指一个线程对主内存的修改可以即使的被其他线程观察到。JDK提供了synchronization、volatile 有序性：happens-before原则。volatile静止指令重排，保证了有序性]]></content>
      <categories>
        <category>Java并发系列文章</category>
      </categories>
      <tags>
        <tag>原子性</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL高级特性]]></title>
    <url>%2F2019%2F04%2F21%2Fmysql%2FMySQL%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7%2F</url>
    <content type="text"><![CDATA[前言本章节来自 高性能MySQL 第七章 MySQL高级特性本章节介绍MySQL5.0开始引入的高级特性，例如分区、触发器 分区表对于用户来说，分区表是一个独立的逻辑表，用户无法访问底层的各个分区。但是底层由多个物理子表组成。分区的主要目的就是将数据按照一个较粗的粒度分在不同的表中。如下场景分区可起到非常大的作用： 表非常大以至于无法全部都放在内存中，或者只在表的最后有热点数据，其他均是热点数据 分区表的数据容易维护 分区表的的数据可分布在不同的物理设备上 如果需要，还可以备份和恢复符独立的分区，在大的数据集场景效率非常好 分区别的一些限制 一个表最多有1024个分区 分区字段中有主键或者唯一索引的列，必须包含进行来 分区表中无法使用外键约束 分区表的原理从存储引擎的角度看，底层表和一个普通表没有任何不同，存储引擎也无需知道这是一个普通表还是一个分区表的一部分。将每一年的销售额存放在不同的分区中123456789CREATE TABLE sales( order_date datetime NOT NULL)PARTITION BY RANGE (year(order_date))( PARTITION P_2010 VALUES LESS THAN (2010), PARTITION P_2011 VALUES LESS THAN (2011), PARTITION P_2012 VALUES LESS THAN (2012), PARTITION p_catchall VALUES LESS THAN MAXVALUE); 如何使用分区表如果表数据巨大（10TB），那么这个时候B-Tree索引就无法起作用了，如infobright放弃B-Tree，选择了一些更粗颗粒度的但消耗更少的方式检索数。分区以代价非常小的方式定位到需要的数据在哪一片区域。在这片区域中，可以顺序扫描，可以建立索引，还可将数据缓存到内存等操作。为了保证大数据量的可扩展性，有如下策略 全量扫描数据，不需要索引使用简单的分区方式存放表，不要任何索引，根据分区的规则大致定位需要的数据位置 索引数据，分离热点可将热点数据单独方在一个分区中。例如希望从一个非常大的表中查询出一段时间内的记录（热点）。而这个表中包含了很多年的历史记录 合并表合并表是一种早期的、简单的分区实现，和分区别相比有一些不同的限制，并且缺乏优化。分区别对于用户来说是透明的、不可访问的。单合并表允许用户访问，分区表是一种被淘汰的技术，在未来的版本中可能被删除 视图视图本身是一个虚拟表，不存在任何数据。在使用SQL语句访问视图时，它返回的数据是MySQL从其他表中生成的 总结 分区表对于用户来说是不能访问底层的各个分区，使用场景：将热点数据单独放在一个分区中]]></content>
      <categories>
        <category>高性能MySQL读书笔记</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[并发基础]]></title>
    <url>%2F2019%2F04%2F21%2Fconcurrence%2F%E5%B9%B6%E5%8F%91%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[基本概念并发：同时拥有两个或多个线程，如果程序在单核处理器上运行，多个线程会交替执行，这些线程是同时存在的。如果运行在多核处理器上，此时，程序中的每个线程都将分配到一个处理器核上，因此可同时运行 高并发(high concurrent)：是互联网分布式系统架构设计中必须考虑的因素之一，它通常是指，通过设计保证系统能够同时并行处理很多请求 并发：多个线程操作相同的资源，保证线程安全，合理使用资源 高并发：服务能同时处理很多请求，提高程序性能 CPU多级缓存随着现代半导体工艺的发展，CPU的频率越来远快，相对内存快了一个数量级，对于访存的操作CPU就需要等待主存，这样会导致资源的白白浪费。所以cache的出现是为了解决CPU与内存速度不匹配的问题 cache 的工作原理是基于“局部性”原理，它包含以下两个方面： 时间局部性：如果某个数据被访问，那么不久将来它很可能再次被访问 空间局部性：如果某个数据被访问，那么与它相邻的数据也可能被访问 cache中保存着cpu刚用过的数据或者是循环使用的数据，这时，从cache中读取数据就会很快，减少了cpu等待的时间，提高了系统的性能 缓存带来的问题cache 给系统带来性能上飞跃的同时，也引入了新的问题“缓存一致性问题”。设想如下场景（cpu一共有两个核，core1和core2）：以i++为例，i的初始值是0.那么在开始每个核都存储了i的值0，当第core1块做i++的时候，其缓存中的值变成了1，即使马上回写到主内存，那么在回写之后core2缓存中的i值依然是0，其执行i++，回写到内存就会覆盖第一块内核的操作，使得最终的结果是1，而不是预期中的2 缓存一致性(MESI)为了达到数据访问的一致，需要各个处理器在访问缓存时遵循一些协议，在读写时根据协议来操作，常见的协议有MSI，MESI，MOSI等。我们介绍其中最经典的MESI协议 在MESI协议中，每个cache line有4个状态，可用2个bit表示，它们分别是： M(Modified): 这行数据有效，数据被修改了，和内存中的数据不一致，数据只存在于本Cache中 E(Exclusive): 这行数据有效，数据和内存中的数据一致，数据只存在于本Cache中 S(Shared): 这行数据有效，数据和内存中的数据一致，数据存在于很多Cache中 I(Invalid): 这行数据无效 CPU多级缓存-乱序执行优化处理器为提高运算速度而做出违背代码原有顺序的优化 乱序执行优化出现问题的原因在单核时代处理器做出的优化可以保证执行结果不会远离预期目标，但是，在多核时代却并非如此。在多核时代，同时会有多个核同时执行指令，每一个核的指令都可能被乱序。另外,处理器还引入了L1，L2,…,Ln等多级缓存机制，每个核心都有自己的缓存机制，这样就导致了逻辑次序上后写入内存的数据未必真的最后写入。最后就带来一个问题，如果不做任何防护措施，处理器最终得出的结果和逻辑得出结果会大不相同。比如，在一个核上执行写入操作，并在最后写一个标记用来表示操作完毕，之后从另外一个核上通过判断这个标记来判定所需要的数据是否已经就绪，这种做法就存在一定风险：标记位先被写入但之前的操作却并未完成(可能是未计算完成，也可能是数据没有从处理器缓存刷新到主存中，最终导致另外的核使用了错误的数据) Java内存模型 JMM规定了线程的工作内存和主内存的交互关系，以及线程之间的可见性和程序的执行顺序。一方面，要为程序员提供足够强的内存可见性保证；另一方面，对编译器和处理器的限制要尽可能地放松。JMM对程序员屏蔽了CPU以及OS内存的使用问题，能够使程序在不同的CPU和OS内存上都能够达到预期的效果。 Java采用内存共享的模式来实现线程之间的通信。编译器和处理器可以对程序进行重排序优化处理，但是需要遵守一些规则，不能随意重排序 Java内存模型—同步八种操作 lock(锁定)：作用于主内存的变量，把一个变量标记为一条线程独占状态 unlock(解锁)：作用于主内存的变量，把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定 read(读取)：作用于主内存的变量，把一个变量值从主内存传输到线程的工作内存中，以便随后的load动作使用 load(载入)：作用于工作内存的变量，它把read操作从主内存中得到的变量值放入工作内存的变量副本中 use(使用)：作用于工作内存的变量，把工作内存中的一个变量值传递给执行引擎 assign(赋值)：作用于工作内存的变量，它把一个从执行引擎接收到的值赋给工作内存的变量 store(存储)：作用于工作内存的变量，把工作内存中的一个变量的值传送到主内存中，以便随后的write的操作 write(写入)：作用于工作内存的变量，它把store操作从工作内存中的一个变量的值传送到主内存的变量中 同步规则分析 不允许一个线程无原因地（没有发生过任何assign操作）把数据从工作内存同步会主内存中 一个新的变量只能在主内存中诞生，不允许在工作内存中直接使用一个未被初始化（load或者assign）的变量。即就是对一个变量实施use和store操作之前，必须先自行assign和load操作。 一个变量在同一时刻只允许一条线程对其进行lock操作，但lock操作可以被同一线程重复执行多次，多次执行lock后，只有执行相同次数的unlock操作，变量才会被解锁。lock和unlock必须成对出现。 如果对一个变量执行lock操作，将会清空工作内存中此变量的值，在执行引擎使用这个变量之前需要重新执行load或assign操作初始化变量的值。 如果一个变量事先没有被lock操作锁定，则不允许对它执行unlock操作；也不允许去unlock一个被其他线程锁定的变量。 -对一个变量执行unlock操作之前，必须先把此变量同步到主内存中（执行store和write操作） 并发的优势和风险优势: 速度：同时处理多个请求，响应更快；复杂的操作可以分成多个进程（或线程）同时进行 设计：程序设计在某些情况下更简单，也可以有更多的选择 资源利用：CPU能够等待IO的时候能够做一些其他的事情 风险: 安全性：多个线程共享数据时可能会产生于期望不相符的结果 活跃性：某个操作无法继续进行下去时，就会发生活跃性问题。比如：死锁、饥饿等问题。 性能：线程过多时会使得：CPU频繁切换，调度时间增多；同步机制；消耗过多内存 总结 CPU多级缓存：缓存一致性、乱序执行优化 Java内存模型： JMM规定、抽象结构、同步八种操作以及规则 Java并发的优势与风险]]></content>
      <categories>
        <category>Java并发系列文章</category>
      </categories>
      <tags>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[查询性能优化]]></title>
    <url>%2F2019%2F04%2F21%2Fmysql%2F%E6%9F%A5%E8%AF%A2%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[前言本章节来自 高性能MySQL 第六章 查询性能优化查询优化、索引优化、库表结构优化需要齐头并进，一个不落，本章节理解MySQL如何真正的指向查询，并明白高效的低效的原因何在 为什么查询速度会慢如果把查询看作是一个任务，那么它由一系列子任务组成，每个子任务都会消耗一定的时间。因此我们要优化查询实际上就是优化子任务。 查询生命周期：从客户，到服务器，然后再服务器上进行解析，生成指向计划，执行，后返回结果给客户端 在每一个消耗大量实际的查询案例中，都可能看到一些不必要的额外操作、重复、某些操作执行太慢等 慢查询基础：优化数据访问查询性能低下最基本的原因是访问数据太多 确认程序是否在检索大量不需要的数据 确认MySQL服务器层是否存在分析大量不需要的数据 是否向数据库请求了不需要的数据有些查询会请求超过实际需要的数据，然后这些多余的数据会被应用程序丢弃。这会给MySQL服务器带来额外的负担，并增加网络开销等 查询不需要的记录我们通常会认为MySQL只会返回需要的数据，实际MySQL是先返回全部结果集后进行计算 多表关联时返回全部列千万不要写select * 这样会导致查询所有关联表的字段数据。应该只取需要的列 总是取出所有列当编写select *时，会让优化器无法完成索引覆盖扫描这类优化。但也并不是坏事，如果你的程序中使用了缓存机制，可能有其好处 重复查询相同的数据如果不断的重复执行相同的查询，每次返回完全相同的数据。比较好的解决方案是，当初次查询的时候将这个数据缓存起来。例如用户每次评论都需要查询用户头像的URL MySQL是否存在扫描额外的记录衡量查询开销的三个指标 响应时间 扫描的行数 返回的行数 它们大致反映了MySQL在内部执行查询时需要访问多少数据，并可大概推算出查询运行的时间。这三个指标都会记录到MySQL的慢日志中 响应时间 响应时间 = 服务时间 + 排队时间服务时间：数据库处理查询真正花了多少时间，排队时间是指服务器因为等待某些资源而没有真正执行查询的时间——可能是I/O、锁等待… 扫描的行数和返回的行数理想情况下扫描的行数和返回的行数应该是相同的。实际情况下这种完美的事并不多 扫描的行数和访问类型在explain语句中的type列反应了访问类型，访问类型有多种，如全表扫描(ALL)、索引扫描、范围扫描等等。这些类型速度慢到快，扫描行数多到少 索引让MySQL以最高效、扫描行数最少的方式找到需要的记录 重构查询的方式一个复杂查询还是多个简单查询设计查询时需要考虑的重要问题是，是否需要将一个复杂的查询分成多个简单的查询。在以前总是认为网络通信，查询解析是一件代价很高的事情 第一种情况不必考虑，现代网络比以前快很多 第二种情况其实在MySQL设计中连接和断开连接的处理非常高效，每秒内部能扫描百万行数据 切分查询有时候对一个大的查询我们可将切分小查询，例如删除旧的数据，将一个大的delete语句切分成多个较小的查询 每次删除数据后，都暂停一会再做下一次删除，这样可以将服务器上原本一次性的压力分散到一个时间很长的时间段中 分散关联查询例如做多表关联查询，有如下语句1234select * from tagjoin tag_post on tag_post.tag.id=tag.idjoin post on tag_post.post_id=post.idwhere tag.tag='mysql' 可以分解为：123select * from tag where tag='mysql'select * from tag_post where tag_id=?select * from post where post.id in(?) 分解关联查询有如下优势： 让缓存效率更高，方便其他程序从缓存中查询单表对象 执行单个查询减少锁的竞争 对数据拆分，做到高性能和可扩展等 查询执行的基础MySQL执行一个查询的流程： 客户端发送一条查询语句给服务器 服务器检查查询缓存，如果缓存中有数据，直接返回。否则进入下一个阶段 服务器进行SQL解析，预处理再由优化器生成对应的执行计划 MySQL根据优化器生成的执行计划，调用存储引擎的API来执行查询 最后将结果返回客户端 我们对其上述的流程进一步的解析 MySQL客户端/服务器通信协议在任何一个时刻，要么由服务器向客户端发送数据，要么客户端向服务器发送数据，这两个动作不能同时发生。 客户端用一个单独的数据包将查询传给服务器，一旦客户端发送了请求，它能做的事就只能等待 相反，服务器响应给客户端的数据通常很多，由多个数据包组成。当开始响应时，客户端必须完整接收整个返回结果，并不能简单的取出前面几条结果（类似拉取数据的过程） 获取结果集看上去是从MySQL服务器获取，实际从函数库(连接MySQL的库函数)的缓存中获取数据 查询状态对于一个MySQL连接，或者说一个线程，任何时刻都由一个连接状态，该状态表示了MySQL当前在做什么。使用SHOW FULL PROCESSLIST命令查询，command列表示当前的状态。有如下状态： sleep：线程正在等待客户端发送新的请求 query：线程正在执行查询或正在将结果发送给客户端 locked：在MySQL服务层，该线程等待表锁 analyzeing and statisticas：线程正在收集存储引擎的统计信息，并生成查询的执行计划 copying to table [on disk]：线程正在执行查询，并将结果集复制到一个临时表中，这种状态通常在做group by union等 sorting result：线程正在对结果集进行排序 sending data：多种情况，线程可能在多个状态之间传送数据，或者在生成结果集等 查询缓存 这里指的是query cache 在解析一个查询语句之前，如果缓存开启，MySQL会优先检查这个查询是否在缓存，是直接返回，否则下一个阶段 查询优化处理此阶段进入查询优化，目标是将一个SQL转换成一个执行计划。MySQL会根据执行计划和存储引擎机械进行交互。这包含了多个子阶段：解析SQL、预处理、优化SQL执行计划，如果该过程有任何错误都可能和终止查询 语法解析器和预处理MySQL会将SQL语句解析为对应的解析树，检查数据表和数据列是否存在、正确等 查询优化器优化器是将SQL转换成执行计划，一条查询可以有多种执行方式，最后都返回相同的值。查询优化器是一个非常复杂的部件，它使用了很多优化策略来生成一个最优的执行计划 查询执行引擎MySQL根据执行计划给出的指令逐步执行，在该过程中，有大量的操作需要通过调用存储引擎实现的接口来完成，这些接口称为’handler API’ 返回结果给客户端最后一个阶段是将结果返回客户端，如果查询可以被缓存，那么MySQL在这个阶段会将结果存放到查询缓存中 查询优化器的提示(hint)如果对优化器选择的执行计划不满意，可使用优化器提供的几个提示(hint)来控制最终的执行计划 sql_small_result和sql_big_resultsql_smqll_result告诉优化器结果集很少，可以将结果集放在内存中的索引临时表，以避免排序操作。sql_big_result则告诉优化器结果集可能非常大，建议使用磁盘临时表做排序操作 p233介绍了更多了的hint 优化特定类型的查询 本节介绍的多数优化技巧都是和特定的版本有关的，对于其他版本未必适用 优化count()count聚合函数：可统计某个列值的数量，也可统计行数 使用count(*)时，并不会像我们猜想的那样扩展成所有的列，实际上，它会忽略所有的列而直接统计所有的行数 如果希望知道的是结果集的行数，最好使用count(*)，这样写意义清晰，性能也会更好 优化group by和distinct使用sql_big_result和sql_small_result来让优化器按照你希望的方式运行 总结 优化数据访问：访问的数据量过大，是否查询了不必要的数据 重构查询方式：将大的查询切分成小的查询，例如将多表查询分成单表查询 理解查询是如何被执行的，以及时间都消耗在那些地方 优化通常需要三管齐下，不做(查询缓存)，少做，快速的做]]></content>
      <categories>
        <category>高性能MySQL读书笔记</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[并发压力测试]]></title>
    <url>%2F2019%2F04%2F21%2Fconcurrence%2F%E5%B9%B6%E5%8F%91%E5%8E%8B%E5%8A%9B%E6%B5%8B%E8%AF%95%2F</url>
    <content type="text"><![CDATA[postmanPostman 是一个很强大的 API调试、Http请求的工具 我们将测试如下接口, 环境：springboot12345678@RestController@Slf4jpublic class TestController &#123; @RequestMapping("/test.do") public String test()&#123; return "test"; &#125;&#125; @Slf4j采用了lombok简化了代码，它可直接使用log.info()使用日志对象 使用之前我们先配置全局参数，方便日后的使用 设置全局变量 定义全局变量参数 测试接口 模拟并发创建一个分类目录，将上述的测试接口添加到该目录中，点击run 此时会出现新的窗口，进行并发测试 apache bencheApacheBench 是 Apache 服务器自带的一个web压力测试工具，简称ab。ab又是一个命令行工具，对发起负载的本机要求很低，根据ab命令可以创建很多的并发访问线程，模拟多个访问者同时对某一URL地址进行访问，因此可以用来测试目标服务器的负载压力。总的来说ab工具小巧简单，上手学习较快，可以提供需要的基本性能指标，但是没有图形化结果，不能监控 download: https://www.apachelounge.com/download/ ab命令进行并发测试 测试参数如下 jmeter Apache JMeter是Apache组织开发的基于Java的压力测试工具。用于对软件做压力测试，它最初被设计用于Web应用测 试但后来扩展到其他测试领域。 它可以用于测试静态和动态资源例如静态文件、Java 小服务程序、CGI 脚本、Java 对象、 数据库， FTP 服务器， 等等。JMeter 可以用于对服务器、网络或对象模拟巨大的负载，来在不同压力类别下测试它们的 强度和分析整体性能。另外，JMeter能够对应用程序做功能/回归测试，通过创建带有断言的脚本来验证你的程序返回了你期望的结果 download:https://mirrors.tuna.tsinghua.edu.cn/apache//jmeter/binaries/ 解压完毕在bin目录下执行jmeter.bat会启动如下界面 新建一个线程组 线程组配置 创建测试请求和查询结果 代码并发模拟 CountDownLatch计数器不断的向下减 该类可阻塞线程，并保证线程在满足特定的情况下继续执行 Semaphore字面意思为”信号量” 该类可阻塞进程，并且控制同一时间的请求并发量 如果我们想模拟并发测试的时，并在所有线程执行完输出执行结果，应该结合上诉两个类来完成。 代码实现123456789101112131415161718192021222324252627282930313233343536@Slf4j@NotThreadSafepublic class ConcurrentTest &#123; // 请求总数 public static int clientTotal = 5000; // 同时并发执行的线程数 public static int threadTotal = 50; public static int count = 0; public static void main(String[] args) throws Exception&#123; ExecutorService executorService = Executors.newCachedThreadPool(); final Semaphore semaphore = new Semaphore(threadTotal); final CountDownLatch countDownLatch = new CountDownLatch(clientTotal); for (int i = 0; i &lt; clientTotal; i++)&#123; executorService.execute(()-&gt;&#123; try &#123; semaphore.acquire(); add(); semaphore.release(); &#125; catch (Exception e) &#123; log.error("exception", e); &#125; countDownLatch.countDown(); &#125;); &#125; countDownLatch.await(); executorService.shutdown(); log.info("count:&#123;&#125;", count); &#125; // 计数 private static void add()&#123; count++; &#125;&#125; 不做同步的情况下，该结果是不一致的]]></content>
      <categories>
        <category>Java并发系列文章</category>
      </categories>
      <tags>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[创建高性能的索引]]></title>
    <url>%2F2019%2F04%2F20%2Fmysql%2F%E5%88%9B%E5%BB%BA%E9%AB%98%E6%80%A7%E8%83%BD%E7%9A%84%E7%B4%A2%E5%BC%95%2F</url>
    <content type="text"><![CDATA[前言本章节来自 高性能MySQL 第五章 创建高性能的索引索引在MySQL中也称为key，它是存储引擎用于快速找到记录的一种数据结构。索引能够轻易将查询性能提高几个数量级 索引基础存储引擎是如何使用索引的？ 首先在索引中找到对应的值，然后根据匹配的索引记录找到对应的数据行。也就是说，如果某个列建立了索引，那么会先在索引中查找。 可创建多个索引，如果多个列，那么顺序非常重要 索引的类型 索引在存储引擎层，因此不同的存储引擎对索引的工作方式也不一样，并不是所有的存储引擎都支持所有类型的索引 B-Tree索引 术语B-Tree是因为MySQL在create table和其他语句中也使用该关键字 内部算法实际使用B+Tree实现，InnoDB使用B+Tree，NDB集群使用T-Tree来存储索引 B-Tree与二叉树的形式存储索引，意味着所有的值都是顺序的，能够快速访问数据不需要进行全表扫描 B-Tree对索引是顺序组织存储，所以适合查找范围数据 哈希索引哈希索引基于哈希表实现，只有精确匹配索引所有列的查询才有效, 哈希索引会将所有的哈希码存储在索引中，同时在哈希表中存储每个数据行的指针 在MySQL中，只有memory引擎支持哈希索引 如果要查询很多关联的表，哈希索引非常使用用于查询 InnoDB有一种特殊的功能 自适应哈希索引 如果它注意到某些索引使用频繁，内部会基于B-Tree之上创建哈希索引 创建自定义索引我们可模拟InnoDB一样创建函数, 虽然还是使用B-Tree进行查找，但是使用哈希值来查询我们有如下表12345CREATE TABLE hash_test( id int unsigned NOT NULL AUTO_INCREMENT PRIMARY KEY , url varchar(255) NOT NULL , url_crc int unsigned NOT NULL DEFAULT 0) 例如url存储”http://www.mysql.com&quot;, 我们进行如下查询效率是非常低的，使用的是全表扫描1SELECT url FROM hash_test WHERE url = 'http://www.mysql.com'; 因此我们在上述表中添加了url_crc它用于存储URL的哈希值，通过哈希值来进行查询，效率是极高的123# 需要将值存储到url_crr列SELECT crc32('http://www.mysql.com');SELECT url FROM hash_test WHERE url = 'http://www.mysql.com' AND url_crc = crc32("http://www.mysql.com"); 上述过程的缺陷是需要手动设置哈希值，当然可使用触发器来完成。注意：哈希冲突问题，或可使用FNV64()哈希函数，冲突比CRC32()少 全文索引它查找的是文本中的关键词，而不是直接比较索引中的值。类似于搜索引擎做的事情 索引的优点 大大减少了服务器需要扫描的数据量 可以帮助服务器避免排序和临时表 可将随机I/O变为顺序IO 索引是最好的解决方案吗?只有当索引帮助存储引擎快速查找到记录带来的好处大于其带来的额外工作时，索引才是最有效的 高性能的索引策略正确的创建和使用索引是实现高性能查询的基础 独立的列不当的使用索引1select id from user where id + 1 = 5 如果查询总的列不是独立的，则MySQL不会使用索引。独立的列是指索引列不能是表达式的一部分，也不能是函数的参数 前缀索引和索引选择性如果需要索引很长的字符串，这会导致索引变的大且慢。我们可采用索引开始部分的字符来提高索引效率。但是也会降低索引的选择性。指定是如果你使用部分字符，那么出现重复的值越高 对于blob、text或很长的varcher类型的列必须采用前缀索引 多列索引在多个列上建立独立的单列索引大部分情况下并不能提高性能，在MySQL5.0版本引入了”索引合并”的策略，一定程度上表上的多个单列索引来定位指定的行 OR、AND、UNION以集合的方式会根据索引查询并不会进行全表扫描 选择合适的索引顺序在B-Tree索引中，意味着安装最左列进行排序，其次第二列 将选择性最高的列放到索引最前列 聚簇索引InnoDB的聚簇索引在同一个结构中保存了B-Tree索引和数据行，它的优点有 把相关数据保存在一起，例如实现电子邮箱时，可根据用户ID聚集数据获取全部邮件 数据访问更快，聚簇索引将索引和数据存储在一个B-Tree中 覆盖索引MySQL可直接获取列的数据，这样就不再需要读取数据行, 如果一个索引包含所有需要查询的字段的值，称为覆盖索引 覆盖索引必须要存储索引的值，并不是所有的存储引擎都支持覆盖索引 使用索引扫描来做排序 MySQL有两种方式生成有序的结果，排序、按索引顺序扫描 可使用explain select table 查看tyep值 如果为index则使用了索引扫描来做排序 压缩（前缀压缩）索引MyISAM使用前缀压缩来减少索引的大小，从而让更多的索引放入内存中 可以在create table语句中指定pack_keys参数来控制压缩索引的方式 冗余和重复的索引如果在相同列上创建多个索引, 那么MySQL需要单独维护重复的索引，这会影响性能 未使用的索引考虑删除 索引和锁索引可以让查询锁定更少的行，如果你的查询从不访问那些不需要的行，那么就会锁定更少的行 InnoDB行锁效率高，只有在访问行的时候才会对其加锁 总结 如果列中建立了索引，存储引擎会根据索引快速查询到记录。 InnoDB使用B-Tree索引，所有中都是顺序的，避免了全表扫描。哈希索引只有memory 可以使用CRC32(‘url’)获取哈希值，可通过哈希值来查询较长的字符串如URL地址，不要使用SHA1()和MD5()作为哈希函数 编写查询语句时尽可能选择合适的索引以避免单行查找，尽可能使用数据原生顺序从而避免而外的排序操作，尽可能使用索引覆盖查询 不要因”应该为where子句中出现的所有列创建索引”所谓的经验法来创建索引，而是要应该根找出消耗最长时间的查询来创建合适的索引]]></content>
      <categories>
        <category>高性能MySQL读书笔记</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Schema与数据类型优化]]></title>
    <url>%2F2019%2F04%2F19%2Fmysql%2FSchema%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[选择优化的数据类型本章节来自 高性能MySQL 第四章 Schema与数据类型优化 选择正确的数据类型对于获得高性能至关重要 更小的通常更好，尽量使用存储数据的最小数据类型 简单就好，例如整形比字符操作更快，而不是使用字符存储时间 尽量避免NULL，通常情况下最好将列指定为NOT NULL 整数类型存储整数可使用：tinyint、smallint、mediumint、int、bigint。分别使用8、16、24、32、64位存储空间 整数类型有可选的unsigend属性，表示不允许负值 整数计算通常使用bigint 实数类型实数是带有小数部分的数字 float（4字节）和double（8字节）支持浮点运算 decimal用于存储精确的小数, 因为decimal只是一种存储格式，在计算中会转换为double 只在对小数进行精确计算时才使用decimal，例如财务数据 字符串类型不同的存储引擎存储字符的方式可能不同 varchar存储可边长字符串，仅使用必要的空间 char类型是定长的，适合存储更短的字符串。当存储char值时，MySQL会删除所有的末尾空格 binary和varbinary用于存储二进制字符串，存储的是字节码而不是字符 blob和text：存储大数据而设计的字符串类型。前者为二进制，后者为字符串。它们与其他类型不同，存储引擎会做特殊处理，如果值太大，InnoDB会使用专门的”外部”存储区域进行存储 使用枚举类型存储字符串，与数字-字符串映射关系查找表 日期和时间类型MySQL能存储的最小时间颗粒度为秒，MariaDB支持微妙级别的时间类型，可使用bigint存储微秒级别的时间戳 datetime: 可保存大范围的值，1001年-9999年，精度为秒。8字节存储 timestamp: 保存了从1970-1-1午夜（格林尼治标准时间）以来的秒数, 使用4字节存储。 位数据类型位类型，不管底层存储格式和处理方式如何，从技术上来说都是字符串类型 bit：bit(1)定义一个包含单个位的字段, 存储一个或多个true/false set: 存储很多个true/false，以集合的形式来表示 选择标识符整数通常是标识列最好的选择，enum和set只适合标记固定的值，如人的性别、产品类型等，尽量避免字符串类型作为标识列，因为消耗空间随机字符如UUID存储会导致insert、select语句变慢。插入会随机写到索引不同位置，查询逻辑上相邻的行为分布在磁盘和内存分布在不同的位置。 如果存储UUID，移出’-‘，使用unhex()函数转换位16字节数字，存储在binary(16)。检索使用hex()函数格式化位十六进制的格式 schema设计中的陷阱 太多的列 太多的表关联，MySQL限制每个关联操作最多61张表。如果希望查询效率更高，单个查询最好在12个表以内做关联 防止过度的使用enum]]></content>
      <categories>
        <category>高性能MySQL读书笔记</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zookeeper分布式锁原理]]></title>
    <url>%2F2019%2F04%2F19%2Fzookeeper%2Fzookeeper%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[死锁 | 活锁概念死锁 如果有两个服务订单服务和商品服务，订单服务需要读取库存操作, 商品服务也需要读取库存操作(图1) 此时订单服务读取完库存之后并没有释放(没有提交)。当商品服务再次读取时，库存数据可能会不一致（脏读）。通常这种情况采用死锁 解决：在订单服务访问库存的时候，无论crud操作都加一把锁(未释放)。那么商品服务就不能访问库存了(图2) 图1 图2 活锁无论多少个服务，只对库存进行读取的操作 那么其他服务都可以去读取，否则都要进行加锁。这种情况成为活锁 分布式锁在分布式环境下，当不同的服务访问某一个共享资源数据(数据库)的时候，可能会发生数据不一致的情况 下订单流程如果在创建订单和扣除库存的操作没有完成（sleep），此时有其他请求进入时，那么库存的数量就可能会造成不一致(之前的值，因为sleep了) zookeeper分布式锁 在获取锁的时候，要根据锁是否被占用才可获取。如果没有占用创建锁 zk临时节点。临时节点会根据客户端会话的断开而断开（释放锁） 总结 什么是死锁：当A服务进行CRUD库存的时候，其他服务不可访问库存 什么是活锁：如果A服务只是进行读库存的操作，那么其他服务可访问库存 利用Zookeeper不能重复创建一个节点的特性来实现一个分布式锁，与redis很类似]]></content>
      <categories>
        <category>zookeeper</category>
      </categories>
      <tags>
        <tag>zookeeper</tag>
        <tag>分布式锁</tag>
        <tag>死锁</tag>
        <tag>活锁</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zookeeper集群]]></title>
    <url>%2F2019%2F04%2F18%2Fzookeeper%2Fzookeeper%E9%9B%86%E7%BE%A4%2F</url>
    <content type="text"><![CDATA[zookeeper集群概述zookeeper集群包含主从节点，心跳机制（选举模式），架构如下 选举模式: 如果上述图中的master宕机了, slave1和slave进行选举，只有其中一个为master。如果原来的master恢复了，那么会加入到集群中成为slave。集群个数建议为奇数因为需要选举的过程 搭建集群 配置数据文件 myid 1/2/3 对应 server.1/2/3 通过 ./zkCli.sh -server [ip]:[port] 检测集群是否配置成功 拷贝3份zookeeper文件, 在第一份文件中的zoo.cfg配置如下信息12345# 每个文件都需要加入该配置# master节点ip | 数据同步的端口 | 选举端口server.1=192.168.211.136:2888:3888server.2=192.168.211.136:2889:3889server.3=192.168.211.136:2890:3890 在dataDir数据源目录创建 myid 添加数字 1123456[root@zhongjinlang dataDir]# vim myid[root@zhongjinlang dataDir]# ll总用量 8-rw-r--r--. 1 root root 2 4月 18 00:42 myiddrwxr-xr-x. 2 root root 6 4月 18 00:32 version-2-rw-r--r--. 1 root root 4 4月 18 00:32 zookeeper_server.pid 其他文件修改端口 2182、2183和创建myid即可 分别启动 ./zkServer.sh start 并在2181中set一个节点1234567891011[zk: localhost:2181(CONNECTED) 1] create /data 123 Created /data[zk: localhost:2181(CONNECTED) 2] ls /[zookeeper, data]# 退出当前连接，连接2182[zk: localhost:2181(CONNECTED) 3] [root@zhongjinlang bin]# ./zkCli.sh -server localhost:2182# 此时发现从节点2182有了master的数据（2183也有）[zk: localhost:2182(CONNECTED) 0] ls /[zookeeper, data] 查看集群状态12345678[root@zhongjinlang bin]# echo stat | nc localhost 2181Mode: follower # 从节点[root@zhongjinlang bin]# echo stat | nc localhost 2182Mode: leader # 主节点[root@zhongjinlang bin]# echo stat | nc localhost 2183Mode: follower # 从节点 选举模式实验上述可看出2182为主节点，我们将2182进程kill，观察谁会成为主节点 123456789# 此时已经连接不了2182[root@zhongjinlang bin]# echo stat | nc localhost 2182Ncat: Connection refused.# 分别连接其他节点[root@zhongjinlang bin]# echo stat | nc localhost 2181Mode: follower[root@zhongjinlang bin]# echo stat | nc localhost 2183Mode: leader # 2183成为了主节点 总结 zookeeper集群包含主从节点、心跳机制。当主节点挂了，经过选举会将某一个从节点成为主节点，来保证整体服务的高可用]]></content>
      <categories>
        <category>zookeeper</category>
      </categories>
      <tags>
        <tag>zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zookeeperACL权限控制]]></title>
    <url>%2F2019%2F04%2F18%2Fzookeeper%2FzookeeperACL%E6%9D%83%E9%99%90%E6%8E%A7%E5%88%B6%2F</url>
    <content type="text"><![CDATA[何为ACL(access control lists)?可以对节点设置读写等权限，来保障数据的安全性，权限permission可以指定不同的范围以及角色 ACL命令行 getAcl：获取某个节点的权限信息 setAcl：设置某个节点的权限 addauth： 输入认证授权信息，注册用户将用户根据指定的权限才可登入 ACL的构成一 zookeeper的ACL通过[scheme:id:permission]来构成权限列表 scheme: 代表采用的某种全新机制 id: 代表允许访问的用户 permission: 权限组合字符串 ACL的构成二 - scheme world：只有一个用户, 语法: world:anyone:[permission] 默认情况下它表示任何人都可访问这一节点 auth：认证登入，需要注册用户且有权限。语法：auth:user:password:[permission] digest：需要对密码进行加密才可访问，语法：digest：username:BASE64(SHA1(password)):[permission] ip: 可限制某个ip的访问，语法：ip:192.168.1.1:[permission] super: 代表超级管理员，拥有所有权限 ACL的构成三 - permission权限字符串使用缩写 crdwa，分别表示： c: create创建子节点。表示设置了改权限才可进行创建子节点 r: read获取节点/子节点列表的权限 d: delete删除子节点权限 w: write写节点数据权限 a: admin权限才可分配permission ACL实战world创建一个节点并查看默认的权限123456[zk: localhost:2181(CONNECTED) 18] create /imooc/abc data Created /imooc/abc[zk: localhost:2181(CONNECTED) 19] getAcl /imooc/abc# 拥有所有权限'world,'anyone: cdrwa 设置权限：禁止删除1[zk: localhost:2181(CONNECTED) 20] setAcl /imooc/abc world:anyone:crwa 此时节点的权限、后新创建一个节点再进行删除测试（因为当前节点拥有之前的权限）12345678[zk: localhost:2181(CONNECTED) 21] getAcl /imooc/abc'world,'anyone: crwa[zk: localhost:2181(CONNECTED) 22] create /imooc/abc/xyz new-data-isnotdelete Created /imooc/abc/xyz[zk: localhost:2181(CONNECTED) 23] delete /imooc/abc/xyz# 提示权限不足Authentication is not valid : /imooc/abc/xyz auth明文登入注册账号并登入123456789101112[zk: localhost:2181(CONNECTED) 39] create /name/zhangsan zs Created /name/zhangsan[zk: localhost:2181(CONNECTED) 40] getAcl /name/zhangsan'world,'anyone: cdrwa# 登入提示没有这个用户[zk: localhost:2181(CONNECTED) 41] setAcl /name/zhangsan auth:zhangsan:123:cdrwa Acl is not valid : /name/zhangsan# 注册一个用户[zk: localhost:2181(CONNECTED) 42] addauth digest zhangsan:zhangsan# 再次登入[zk: localhost:2181(CONNECTED) 43] setAcl /name/zhangsan auth:zhangsan:123:cdrwa 此时权限信息123456789101112131415161718192021[zk: localhost:2181(CONNECTED) 44] getAcl /name/zhangsan# 密码存在数据库中是一个密文'digest,'zhangsan:7Tjni+rxBvYp1MDxthriuVT77Gw=: cdrwa``` ## digest使用密文方式登入*创建新的节点 并设置登入账号以及密码*```shell[zk: localhost:2181(CONNECTED) 6] getAcl /name/lisi'world,'anyone: cdrwa# 设置密码（密文）[zk: localhost:2181(CONNECTED) 7] setAcl /name/lisi digest:lisi:7Tjni+rxBvYp1MDxthriuVT77Gw=:cdra# 查看权限[zk: localhost:2181(CONNECTED) 8] getAcl /name/lisi'digest,'lisi:7Tjni+rxBvYp1MDxthriuVT77Gw=: cdra ip控制某个网段是否有权限来访问目录节点，通常用于控制客户端 创建一个新的节点12345678910111213141516[zk: localhost:2181(CONNECTED) 19] create /name/ip ipCreated /name/ip[zk: localhost:2181(CONNECTED) 20] getAcl /name/ip'world,'anyone: cdrwa# 设置权限[zk: localhost:2181(CONNECTED) 21] setAcl /name/ip ip:192.168.117.1:cdrwa[zk: localhost:2181(CONNECTED) 22] getAcl /name/ip'ip,'192.168.117.1: cdrwa# 此时虚拟机不可访问[zk: localhost:2181(CONNECTED) 23] get /name/ipAuthentication is not valid : /name/ip 总结 zookeeper的ACL可对节点进行权限控制来保障数据安全性 world：默认所有用户登入 auth：注册用户登入，注册密码时为明文 digest：注册用户登入，注册密码时为密文 ip: 可限制网段访问 super: 可访问所有权限 ACL使用场景一：开发/测试环境分离，开发者无权操作测试库的节点，只能看 ACL使用场景二：生产环境上控制指定IP的服务可以访问相关节点，防止混乱]]></content>
      <categories>
        <category>zookeeper</category>
      </categories>
      <tags>
        <tag>zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zookeeper的watch机制]]></title>
    <url>%2F2019%2F04%2F18%2Fzookeeper%2Fzookeeper%E7%9A%84watch%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[何为watch?针对每个节点的操作，都会有一个监督者watch。当节点发现变化时，如create、set、delete都会触发一个watch事件。zookeeper中的watch是一次性的，触发后立即销毁。注意是在zookeeper中 父节点，子节点增删改都会触发watch 针对不同类型的操作，触发的watch事件不同：如节点创建事件、节点删除事件、节点数据变化事件 使用watch父节点watch事件 创建父节点触发: NodeCreated 123456789101112# 先设置一个事件（set get都可以 使用help查看）[zk: localhost:2181(CONNECTED) 9] stat /imooc watch Node does not exist: /imooc[zk: localhost:2181(CONNECTED) 10] ls /[zookeeper][zk: localhost:2181(CONNECTED) 11] create /imooc 123# 触发了事件watch::WatchedEvent state:SyncConnected type:NodeCreated path:/imoocCreated /imooc 修改父节点数据触发：NodeDataChanged 删除父节点触发：NodeDeleted 子节点watch事件ls为父节点设置watch 创建子节点触发：NodeChildrenChanged123456789[zk: localhost:2181(CONNECTED) 4] ls /imooc[][zk: localhost:2181(CONNECTED) 5] ls /imooc watch [][zk: localhost:2181(CONNECTED) 7] create /imooc/abc 88 Created /imooc/abcWATCHER::WatchedEvent state:SyncConnected type:NodeChildrenChanged path:/imooc 触发了NodeChildrenChanged 删除子节点也是触发：NodeChildrenChanged 修改子节点不会触发事件 TODO：增加和删除触发的事件为什么一样：因为它们为子节点，子节点和父节点需要进行区分，父节点有不同的事件，对于父节点来说不需要关注子节点的事件。因为父节点只需要告诉客户端 哦我的子节点改变了NodeChildrenChanged事件 总结 watcher使用场景：在集群环境下，如果某个节点发生了变化，例如配置文件的变化，我们可通过watcher监听获取到数据，并将其同步到其他分布式的节点中，达到数据的一致性 zookeeper节点（子父）发生变化时，会触发watch事件，并且出发后立即销毁（在zookeeper中)不同的类型操作watch事件也不同（增、删、改） 在修改节点数据之前可设置watch，如果下次获取该节点时会触发不同的watch类似 父节点触发watch事件有： NodeCreated（增）、NodeDeleted（删）、NodeDataChanged（改） 子节点触发watch事件有: NodeChildrenChanged（增删）、修改不会触发事件因为对于父节点来说并不关心]]></content>
      <categories>
        <category>zookeeper</category>
      </categories>
      <tags>
        <tag>zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zookeeper命令使用]]></title>
    <url>%2F2019%2F04%2F18%2Fzookeeper%2Fzookeeper%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[常用命令 通过 ./zkCli.sh打开客户端进行命令行后台操作12[root@zhongjinlang bin]# zkCli.sh[zk: localhost:2181(CONNECTED) 0] ls | ls2查看zookeeper路径1234[zk: localhost:2181(CONNECTED) 0] ls /[zookeeper][zk: localhost:2181(CONNECTED) 2] ls /zookeeper[quota] 查看状态信息123456789101112131415161718192021222324[zk: localhost:2181(CONNECTED) 3] ls2 /[zookeeper]# 创建了之后，zk为这个节点所分配的IDcZxid = 0x0# create-timectime = Thu Jan 01 08:00:00 CST 1970# 修改后zk的IDmZxid = 0x0# 修改后节点的时间mtime = Thu Jan 01 08:00:00 CST 1970# 子节点IDpZxid = 0x0# 子节点发生变化后的version值cversion = -1# 当前节点数据的version，修改后累加1dataVersion = 0# 权限aclVersion = 0# ephemeralOwner = 0x0# 数据长度dataLength = 0# 子节点个数（ls /）numChildren = 1 get | stat stat命令：ls2 = ls + stat get：取出当前节点数据，如果没有数据，与上述内容一至 节点操作命令讲述该节内容前，我们先阐述session的基本原理： 客户端与服务端之间的连接存在会话 每个会话都可设置一个超时时间（30分钟不操作session失效）：心跳结束，则session过期 session过期，临时节点znode会被抛弃 心跳机制： 客户端向服务端的ping包请求 create 创建默认节点节点（持久化节点） 123456789[zk: localhost:2181(CONNECTED) 11] create /imooc immoc-data Created /imooc[zk: localhost:2181(CONNECTED) 12] get /immoc# 当前节点的持久化数据immoc-data..ephemeralOwner = 0x0# 数据长度dataLength = 10 创建节点后目录为： 12[zk: localhost:2181(CONNECTED) 4] ls / [zookeeper, imooc] 创建临时节点: create -e /imooc/tmp immoc-data 创建顺序节点: 每个节点后缀都会增加数值 1234[zk: localhost:2181(CONNECTED) 5] create -s /imooc/sec seq Created /imooc/sec0000000001[zk: localhost:2181(CONNECTED) 6] create -s /imooc/sec seqCreated /imooc/sec0000000002 set | delete set path data [version]：修改节点如果默认不设置版本号，直接删除。加上版本号可实现乐观锁(只能修改最新的数据) delete path [version]: 直接删除节点, 加上版本号只能删除最新数据 四字命令 four letter wordszookeeper可通过它自身提供的简写命令来和服务器进行交互, 可查看服务器的一些状态信息。使用运维来进行监控 需要使用nc命令，安装yum install nc 语法： echo [commod] | nc [ip] [port] stat它可查看zookeeper的状态信息，以及是否mode（集群还是单机） 12345678910111213[root@zhongjinlang /]# echo stat | nc 192.168.211.136 2181Zookeeper version: 3.4.11-37e277162d567b55a07d1755f0b31c32e93c01a0, built on 11/01/2017 18:06 GMTClients: /192.168.211.136:34346[0](queued=0,recved=1,sent=0)Latency min/avg/max: 0/0/27Received: 2696Sent: 2701Connections: 1Outstanding: 0Zxid: 0x45Mode: standaloneNode count: 8 ruok查看当前zk服务是否启动，启动返回imok 12[root@zhongjinlang /]# echo ruok | nc localhost 2181imok[root@zhongjinlang /]# dump列出未经处理的会话和临时节点 12345[root@zhongjinlang /]# echo dump | nc localhost 2181SessionTracker dump:Session Sets (0):ephemeral nodes dump:Sessions with Ephemerals (0): conf查看服务器配置 123456789[root@zhongjinlang /]# echo conf | nc localhost 2181clientPort=2181dataDir=/usr/local/server/zookeeper/zookeeper-3.4.11/bin/../dataDir/version-2dataLogDir=/usr/local/server/zookeeper/zookeeper-3.4.11/bin/../dataLogDir/version-2tickTime=2000maxClientCnxns=60minSessionTimeout=4000maxSessionTimeout=40000serverId=0 cons展示连接到服务器的客户端信息 12[root@zhongjinlang /]# echo cons | nc localhost 2181 /0:0:0:0:0:0:0:1:47224[0](queued=0,recved=1,sent=0) mntr监控zookeeper的健康信息 12345678910111213141516[root@zhongjinlang /]# echo mntr | nc localhost 2181zk_version 3.4.11-37e277162d567b55a07d1755f0b31c32e93c01a0, built on 11/01/2017 18:06 GMTzk_avg_latency 0zk_max_latency 27zk_min_latency 0zk_packets_received 2703zk_packets_sent 2708zk_num_alive_connections 1zk_outstanding_requests 0zk_server_state standalonezk_znode_count 8zk_watch_count 0zk_ephemerals_count 0zk_approximate_data_size 85zk_open_file_descriptor_count 30zk_max_file_descriptor_count 4096 wchs展示watch信息 123[root@zhongjinlang /]# echo wchs | nc localhost 21810 connections watching 0 pathsTotal watches:0 总结 ls / 查看zk目录 ls2 / 查看节点信息 get / 取出当前节点信息 zookeeper存储了节点的各种状态，如数据的大小、修改时间等 ephemeralOwner = 0x0属性如果为0x0那么为临时节点，否则为持久节点（后面是一串数据）。临时节点在断开连接后消失（10秒左右延迟 - 心跳机制） create path data创建持久化节点 set path data [version]修改节点 delete path data [version]删除节点 使用set和delete时候，建议根据version删除，可达到乐观锁的效果，不会删除到之前旧的数据 zookeeper提供四字命令可查看服务器的一些状态信息，语法：echo [命令] | nc [ip] [port]]]></content>
      <categories>
        <category>zookeeper</category>
      </categories>
      <tags>
        <tag>zookeeper</tag>
        <tag>乐观锁</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zookeeper基本数据模型]]></title>
    <url>%2F2019%2F04%2F17%2Fzookeeper%2Fzookeeper%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[zookeeper模型介绍 数据为树形结构，可理解为Linux的目录结构 /usr/local/.. 每一个节点成为znode，它可有子节点，也可以有数据 每个节点分为临时节点和永久节点，临时节点在客户端断开连接后消失。永久节点是一个持久化的节点 每个zk节点都有各自的版本号，可通过命令显示节点信息 每当节点数据发生变化时，那么该节点的版本号就会累加（乐观锁） 删除/修改过时的节点，版本号不匹配则会报错 每一个zk节点存储的数据不易过大，几k即可 节点可设置权限ACL，可通过权限来限制用户访问 数据模型基本操作 客户端连接 - 查看znode结构 - 关闭客户端连接 连接客户端123456[root@zhongjinlang bin]# ./zkCli.sh# 提示一推信息...WATCHER::WatchedEvent state:SyncConnected type:None path:null# 这里需要回车[zk: localhost:2181(CONNECTED) 0] zookeeper命令 查看znode12[zk: localhost:2181(CONNECTED) 4] ls /zookeeper/quota[] zookeeper的作用 master节点选举，当主节点挂了，从节点就会接手工作，从而保证集群是高可用的 统一配置文件管理，即只需要部署一台服务器，则可以把相同的配置文件同步更新到其他所有服务器，例如在一个集群的生产环境下，修改了一个redis的配置那么其他服务都需要进行修改，这样就很麻烦 发布订阅模式，类似消息队列MQ, dubbo发布者把数据数据存储到znode节点上，订阅者会读取这个数据 提供分布式锁，分布式环境中不同进程之间争夺资源，类似于多线程中的锁 当A处理完B、C、D 集群管理，集群中保证数据的强一致性 总结 zookeeper的结构为树形结构，节点分为临时节点和永久节点。前者会在客户端断开后消失，后者是一个持久化的节点 zookeeper可保证集群高可用、提供了分布式锁保证数据一致性、可以统一管理集群中的配置文件进行同步]]></content>
      <categories>
        <category>zookeeper</category>
      </categories>
      <tags>
        <tag>zookeeper</tag>
        <tag>分布式锁</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zookeeper概述]]></title>
    <url>%2F2019%2F04%2F17%2Fzookeeper%2Fzookeeper%E6%A6%82%E8%BF%B0%2F</url>
    <content type="text"><![CDATA[简介ZooKeeper是一个分布式的，开放源码的分布式应用程序协调服务，是Google的Chubby一个开源的实现，它是集群的管理者，监视着集群中各个节点的状态根据节点提交的反馈进行下一步合理操作。最终，将简单易用的接口和性能高效、功能稳定的系统提供给用户 分布式系统 很多台计算机组成一个整体，一个整体一致对外并处理同一个请求 内部的每台计算机都可相互通信（rest/rpc） 客户端到服务端的一次请求到响应结束会历经多台计算机 zookeeper特性 一致性：数据一致性，将数据按照顺序分批入库 原子性： 事务要么成功要么失败，不会局部化 单一视图： 客户端连接集群中的任一zookeeper节点，数据都是一致的 可靠性： 每次对zookeeper的操作状态都会保存在服务端 实时性: 客户端可以读取到zookeeper服务端的最新数据 zookeeper的安装JDK依赖 安装解压好后配置环境变量，java-version查看是否安装成功 12345# set java# java安装路径export JAVA_HOME=/usr/local/server/java/jdk1.8export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jarexport PATH=$PATH:$JAVA_HOME/bin zookeeper配置 下载地址：https://archive.apache.org/dist/zookeeper/ 安装解压后配置环境变量 1234export JAVA_HOME=/usr/local/server/java/jdk1.8export ZOOKEEPER_HOME=/usr/local/server/zookeeper/zookeeper-3.4.11export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar export PATH=$PATH:$ZOOKEEPER_HOME/bin:JAVA_HOME/bin 核心配置文件123456789101112#用于计算时间的单元, 比如session超时（N * tickTime）tickTime: #用于集群，允许从节点连接并同步到master节点的初始化连接时间，以tickTime的倍数来表示initLimit: #用于集群，master主节点与从节点之间的消息通信，请求和答应的时间（心跳机制）syncLimit:#必须要配置的。用来zookeeper存储的数据(手动创建) dataDir: #日志目录，如果不配置会和data目录公用（手动创建）dataLogDir: #连接服务器的端口，默认2181clientPort: 启动 ./zkServer.sh 命令帮助 ./zkServer.sh start 启动1234[root@zhongjinlang bin]# ./zkServer.sh startZooKeeper JMX enabled by defaultUsing config: /usr/local/server/zookeeper/zookeeper-3.4.11/bin/../conf/zoo.cfgStarting zookeeper ... STARTED 查看启动状态 ./zkServer.sh status12345[root@zhongjinlang bin]# ./zkServer.sh statusZooKeeper JMX enabled by defaultUsing config: /usr/local/server/zookeeper/zookeeper-3.4.11/bin/../conf/zoo.cfg# 表示单机状态Mode: standalone 总结 zookeeper用于提供协调服务，作用与分布式，发挥其优势，可为大数据服务 一次请求历经了多台服务器，这是分布式系统的最简单 zookeeper协调服务可理解为交通堵塞时交警的作用]]></content>
      <categories>
        <category>zookeeper</category>
      </categories>
      <tags>
        <tag>zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis缓存使用与优化]]></title>
    <url>%2F2019%2F04%2F16%2Fredis%2Fredis%E7%BC%93%E5%AD%98%E4%BD%BF%E7%94%A8%E4%B8%8E%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[缓存的收益与成本收益 加速读写：CPU L1/L2/L3 Cache、Linux page Cache加速硬盘读写、浏览器读写、Ehcache缓存数据库结果 降低后端负载：降低MySQL的负载等 成本 数据不一致：缓存层和数据层有时间窗口不一致，和更新策略有关。也就是说，需要将数据库中的数据存入redis进行缓存，如果数据库更新了，那么缓存如何更新呢? 代码维护成本高： 多了一层缓存逻辑 运维成本：例如redis-cluster，或者使用云服务 使用场景 降低后端负载：对高消耗的SQL, 如join结果集 / 分组结果集 加速请求响应：优化IO响应时间 大量写合并为批量写： 计数器先在redis累加，再批量写入DB 缓存更新策略当数据库数据更新时，那么缓存将如何进行更新维护呢？ 先进先出算法剔除：例如maxmemory-policy(最大内存限制)，当超过指定值之后，删除过期的key。不需担心每一个key是如何删除的。适用场景：控制内存 超时剔除：设置过期时间expire。适用场景：存储不是很重要的数据 主动更新：开发控制生命周期，由自己来控制每一个key的更新周期 开发建议： 超时剔除 + 主动更新 缓存颗粒控制通常我们都是这样设计一个缓存系统的：先从redis查询数据，如果有直接返回。如果没有则从数据库中查询然后再加入缓存中。伪代码如下：123set userid 'select * from user where id=1'set userid 'select column.. from user where id=1' 那么到底要缓存select * 还是部分字段的数据？该问题为缓存粒度问题 缓存粒度控制 - 三个角度 通用性：全部属性更好 占用空间：部分数据更好 代码维护：表面上全部属性更好 生产环境通常采用部分属性，缓存需要考虑到性能问题、序列化问题 缓存穿透问题通常情况下缓存设计是这样的：第一次访问redis没有数据就去从数据库中查询，然后将数据加入缓存中，当下此访问redis时就直接从缓存中获取了。这是通常的情况下，如果第二个步骤访问数据库没有数据会怎样？如下如图结构： 此时就失去了缓存的意义，因为缓存就是用来保存持久层。 原因 业务代码问题： 本身你编写的接口就拿不到持久层数据或是调用别的接口拿不到持久层数据 恶意攻击、爬虫等等: 根据URI一定的规则访问到接口 如何发现 业务的相应时间 业务本身问题 相关指标：总调用数、缓存层命中数、存储层命中数 解决缓存空对象如果从数据库中查询的值不存在，进行一个判断直接将null就作为’数据’存入缓存中 但是这种解决方案还是有问题，持久层和缓存层数据”短期”不一致。比如业务上的接口问题调用时可能出现网络原因拿不到结果，此时你将它作为null缓存了。如果恢复了，此时缓存是一个null的状态 伪代码12345678910111213141516// 从redis中取数据public String getValueByRedis(String key)&#123; String cacheValue = cache.get(key); if(StringUtils.isBlank(cacheValue) )&#123; // 为空从持久层获取数据 String storageValue = storage.get(key); // 加入缓存 jedis.set(key, storageValue); // 防止缓存穿透, 如果数据库值真为空，设置过期时间 if(StringUtils.isBlank(storageValue) )&#123; jedis.expire(key, 60 * 5); &#125; &#125;else&#123; return cacheValue; &#125;&#125; 布隆过滤器拦截通过很少的内存对数据的过滤, 例如在一个电话本中判断一个电话是否在电话本中，通常不会将电话本存储到内存中，占用内存可能会很大。布隆过滤器就是解决这种类似的问题，它通过一些算法，将电话本存入过滤器，当要判断电话是否在电话本中时，通过很少的算法来进行解决 布隆过滤器用于检索一个元素是否在一个集合中 缓存无底洞问题 2010年，Facebook有3000个memcache节点 发现问题： 加机器性能没有提升反而下降 问题关键点 更多的j机器 != 更高的性能 批量接口需求（mget、mset等） 数据增长与水平扩展需求 缓存雪崩问题当缓存服务承载大量请求，如果缓存服务异常/宕机，流量直接压向后端DB，造成级联故障 优化方案 保证缓存高可用：个别节点、个别机器、甚至是机房 依赖隔离组件为后端限流 提前演练：压力测试 cache服务高可用：redis-sentinel、redis-cluster、redis-VIP 热点key重建优化缓存重建过程：我们知道使用缓存首先从缓存中获取,如果获取不到从数据库中获取，如果获取到了将数据写入缓存，该过程为缓存的重建的过程。该过程可能会出现的问题 热点key（访问量大） + 较长的重建时间： 大量的线程作查询数据源和缓存重建的工作。解决方案： 互斥锁第一个获取缓存的线程需要做重建的时候，将重建过程加锁。完成了重建工作再将锁解开。在这期间其他线程的发现重建过程处于等待状态，直到最后一个发现锁解开就可直接获取缓存进行输出 该解决方案没有大量的重建过程，但有等待的问题 伪代码12345678910111213141516171819202122// 从redis中取数据public String getValueByRedis(String key)&#123; String cacheValue = cache.get(key; if(cacheValue == null)&#123; // 重建工作 // 设置互斥锁key String mutexKey = "mutexKey:" + key; //setnx命令：key不存在才进行设置 if(redis.set(mutexKey, "1", "ex 180", "nx") )&#123; // 开始重建 value = db.get(key); redis.set(key, value); // 删除锁 redis.delete(mutexKey); &#125;else&#123; // 存在该key，让其他线程休眠 Thread.sleep(50); // 再次尝试获取key get(key); &#125; &#125; return cacheValue; &#125; 永不过期 缓存层面： 没有设置过期时间 功能层面： 为每一个value添加逻辑过期时间，发现过期了，使用单独线程去完成缓存的重建工作 该方案相比互斥锁没有等待的过程 总结 缓存的收益: 加速读写、降低后端存储负载 缓存成本: 缓存和存储数据不一致性、代码维护成本、运维成本 缓存更新策略：超时删除 + 主动更新 缓存穿透问题：使用缓存空对象和布隆过滤器解决，注意他们各自使用场景 缓存雪崩问题： 缓存层的高可用、客户端降级、提前压力测试 热点key重建问题： 互斥锁、”永不过期” 来解决]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL架构与存储引擎]]></title>
    <url>%2F2019%2F04%2F15%2Fmysql%2FMySQL%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%E6%A6%82%E8%BF%B0%2F</url>
    <content type="text"><![CDATA[MySQL逻辑架构本章节来自 高性能MySQL 第一章 MySQL架构与历史 最上层服务是多数基于网络的客户端/服务器都有类似的架构 第二层是MySQL核心服务功能，查询解析、分析、优化、缓存、内置函数、存储过程、触发器、视图等 第三层包含存储存储引擎，它负责MySQL中数据的存储和提取，存储引擎API包含几十个底层函数，例如执行开始一个事务等操作。注意：存储引擎并不会提取SQL MySQL的存储引擎InnoDBInnoDB是mysql的默认事务型引擎, 使用最为广泛的的存储引擎。它的作用是处理大量的短期事务，短期事务大部分情况是正常提交的，很少会被回滚。 MyISAM在MySQL5.1及之前的版本，默认使用MyISAM存储引擎。它提供了全文索引、压缩、空间函数等特性，它不支持事务和行级锁。不要默认开启此引擎，应当使用InnoDB。 MySQL内建的其他存储引擎Archive它只支持insert、select操作，archive引擎会缓存所有的写并利用zlib对插入的行进行压缩，比MyISAM更少的IO Blackhole它没有实现任何存储机制，它会丢弃所有插入的数据，不做任何保存。可用于复制数据库进行备份，可在复制架构和日志审核时发挥作用。但是并不推荐 CSV它可将普通的CSV文件（逗号分隔的文件）作为MySQL的表来处理，但这种表不支持索引。可将excel中的数据存储为CSV文件然后复制到MySQL数据目录。它可作为一种数据交换的机制 Federated该引擎是访问其他MySQL服务器的一个代理，默认是禁用的，它有一个后续的版本为FederatedX Memory如果需要快速访问数据，且这些数据不会被修改，它把数据保存在内存, 重启之后表结构还存在但是数据会丢失。使用场景： 查询或映射表 缓存周期性聚合数据的结果 保存数据分析中产生的中间数据 memory支持hash索引，因此查询很快 MergeMyISAM的变种引擎，由多个表合并出来的虚拟表，该引擎已被放弃 NDB当时的MySQL AB公司从索尼爱立信公司收购了NDB数据库，开发了自己的NDB集群存储引擎 第三方引擎MySQL从2007年提供了插件式的存储引擎API，因此由大多数的第三方产品或开源项目 OLTP类引擎InnoDB是该类型的引擎，还有其他比如支持事务和MVCC的其中一个由PBXT 面向列的存储引擎MySQL默认是面向行的，没一行的数据是一起存储的，查询也是以行为单位处理。而在大数据量处理时，面向队列方式可能效率更高infobright 是一种面向列的存储引擎，在非常大的数据量（数十TB）时，该引擎工作良好。它为数据分析和数据仓库而设计。该引擎不支持索引，不过在这么大的数据量，索引也很难发挥作用 社区存储引擎社区所提供的存储引擎很多，这里只介绍常见的 Groonga： 全文索引引擎，号称可以提供准确高效的全文索引 OQGraph: 支持图操作，比如最短路径问题，用SQL很难实现该问题 Q4M：该引擎在MySQL内部实现了队列操作，用SQL很难实现该问题 SphinxSE: 该引擎为Sphinx全文索引搜索服务器提供了SQL接口 Spider: 该引擎可将数据切分为不同的分区，高效透明的实现了分片，并可分片执行并行查询 VPForMySQL: 该引擎支持垂直分区，指的是将表分成不同列的组合，进行单独存储。但是对于查询来说，看到的还是一张表 选择合适的引擎多数情况下，innoDB都是正确的选择, Oracle在MySQL5.5将innoDB作为默认引擎。如何选择归纳一句话 除非要用到innoDB不具备的特性，并且没有其他办法可替代 , 如果需要事务，InnoDB是目前最稳定的选择 如果不需要要事务，并主要是SELECT和INSERT那么使用MyISAM 转换表的引擎每种方法都有优缺点，以下只讲述三种方法： alter table1ALTER TABLE mytable ENGINE = InnoDB 上诉语法可适用任何存储引擎，但有一个问题：需要执行很长时间，MySQL会按行将数据从原表复制一张新的表中，在复制期间可能会消耗系统所有的IO资源，同时原来的表会加上读锁 导出于导入 创建于查询（create、select） 总结 MySQL拥有分层架构，上层是服务器层的服务、和查询执行引擎。下层存储引擎 mysql的引擎和区别：InnoDB、MyISAM, 5.1之前的版本采用MyIsAM。InnoDB支持事务而MyISAM不支持事务，如果需要大量的插入数据操作使用MyISAM，其他情况优先使用InnoDB 如果要处理大数据量使用第三方引擎 infobright]]></content>
      <categories>
        <category>高性能MySQL读书笔记</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis集群总结]]></title>
    <url>%2F2019%2F04%2F15%2Fredis%2Fredis%E9%9B%86%E7%BE%A4%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[集群总结redis集群高可用实现方式：首先我们知道如果A节点如果发送故障，那么期望它的从节点来接管主节点的任务，也就是说可以进行读写服务 那么从节点的数据怎么和主节点的数据达到一致性呢？首先从节点拿到数据的原理是通过RDB传输(主从复制原理) 的方式来获取数据，而主从数据的一致性通过偏移量来判断数据的一致性。 数据一致性问题解决了，而故障转移redis是如何做到的？ 官方的两种方案： redis-sentinel 和 redis-cluster，redis-sentinel（哨兵）是一个独立的程序，它的作用是监控多个主从节点，如果发现主节点挂了会进行内部选举的模式让一个从节点成为主节点。而redis-cluster专门用于搭建集群模式的情况下使用，因此它本身就具备了高可用的特性。 rediscluster总结 rediscluster数据分区规则使用虚拟槽（16384），每个节点负责一部分槽和相关数据，实现数据的和请求的均衡负载 搭建集群步骤：准备节点、节点握手、分配槽、复制。redis.trib.rb工具用于快速搭建集群 集群伸缩实现是通过节点之间移动槽和相关数据的实现 加入：把槽从原来的节点迁移到新节点 退出：如果要退出集群的节点中槽有数据，那么将它迁移到其他节点，在通过cluster forget命令广播集群让所有节点忘记 集群故障转移过程为故障发现和节点恢复。节点的下线分为主观下线和客观下线，当半数主节点认为你是故障了标记为客观下线。从节点负责故障恢复的过程，保证集群可用性]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[rediscluster常见运维问题]]></title>
    <url>%2F2019%2F04%2F15%2Fredis%2Frediscluster%E5%B8%B8%E8%A7%81%E8%BF%90%E7%BB%B4%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[前言本章讲述搭建rediscluster后常见的问题，理解这些问题，使我们对redis分布式集群的架构有一定的帮助 集群完整性也就是我们在rediscluster篇章中配置的 cluster-require-full-coverage 默认true它表示是否需要集群中的所有节点都是一个在线的状态，所有的0-16384槽都在一个服务的状态，才认为整个集群是完整的，才会对外提供服务 但是对于大多数的业务都无法容忍，如果我们有1000主从节点，当其中一节点进行故障转移的期间（clusterdown the cluster is down）那么此时整个集群就不可用了 在实际生产过程中设置为 no 为何默认为yes？ 集群中16384个槽全部不可用，这也设计就是为了保证集群完整性 带宽消耗我们知道集群节点之间使用信息的交换(gossip)，所以一定有带宽的开销。官方建议：最多1000个节点当节点规模较大时候，会有不容忽视的带宽消耗 消息发送的频率：节点发现与其他节点最后通信时间超过cluster-node-timeout/2时会直接发送ping消息 消息数据量：消息会槽信息，槽数组(2kb)，集群的1/10状态数据(10个节点1kb) 集群规模越高带宽越高 优化： cluster-node-timeout带宽和故障转移的速度的均衡 发布/订阅广播类似于mq的生产消息于订阅消息。当某个节点要通知集群中其他节点的时候，例如故障恢复。其他节点就会收到该消息，这样会产生一个问题，节点的带宽开销会很大。 publish在集群每个节点广播，会加重带宽 解决: 如果只需要做到高可用，单独使用redissentinel 数据倾斜如果将原来节点的数据分布到多个节点上，可能会产生数据的倾斜，有如下原因 节点和槽分配不均匀 不同槽对应键值数量差距大 包含bigkey 内存相关配置不一致 读写分离 只读连接：集群模式的从节点不接受任何读写请求，会跳转到数据对应槽的主节点上，如果需要读（每次客户端执行readonly） 读写分离跟为复杂不建议在集群模式下实现，需要考虑复制延迟、读取过期数据、从节点故障。如果真要实现需要维护slave（思路类似redis-sentinel） 数据迁移如果我们需要将原来的单机节点迁移到rediscluster，这种模式如何实现？ redis-trib.rb import可将单节点数据迁移到集群。不支持在线迁移，b不支持断点续传，单线程迁移 在线迁移：唯品会&gt;redis-migrate-tool、豌豆荚&gt;redis-port 集群VS单机 集群批量操作有限：如mget、mset必须在一个槽 集群事务和lua无法跨节点使用 集群模式只有一个db0，没有16个数据库 集群模式复制只支持一层，不支持树形复制结构 rediscluster满足容量和新能的扩展性，但很多业务达不到一定的QPS，很多场景下redis-sentinel已经足够好]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[rediscluster高可用]]></title>
    <url>%2F2019%2F04%2F15%2Fredis%2Frediscluster%E9%AB%98%E5%8F%AF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[故障转移rediscluster不需要到sentinel即可完成故障转移，实现高可用的集群特性。它与sentinel很相似，分为故障发现和故障恢复的过程 故障发现依赖节点之间的通信使用ping/pong消息实现故障的发现，不需要sentinel 主观下线定义：某个节点认为另一个节点不可用，”偏见”，代表一个节点对另一个节点的认知流程： 当某个节点断开连接之后，超过node-timeout超时时间，那么标记为pfaill 客观下线定义： 持有半数以上的槽的节点都标记某个节点时，就认为那个节点不可用流程： 记录每个节点的状态，如果状态不可用，会将信息添加到故障列表中，列表用于维护故障列表，后再尝试客观下线。之后通知集群内所有节点标记故障节点为客观下线，通知故障节点的从节点准备执行转移 故障恢复客观下线通知从节点，从节点接收到消息开始准备进行故障的恢复，从而保证集群的高可用，实现流程有： 资格检查检查哪些从节点可能成为主节点的资格条件： 每个从节点检查与故障主节点的断线时间 超过cluster-node-timeout(15) * cluster-slave-validity-factory(10)取消资格 选举具备更大的偏移量（更接近主节点）成为主节点的可能性更大，选举的时间更小且投票个数更高，收集3张选票大于N/2+1，那么执行替换主节点工作 替换主节点 当前节点取消从节点复制，变为主节点（slaveof one one） 执行clusterDelSlot撤销故障主节点负责的槽，并执行clusterAddSlot把这些槽分配给自己 集群广播消息，表明已经替换了故障从节点 故障转移实验环境: springboot + 3主3从节点目的: 不断的从节点中set值, 中途将其中一个master kill观察情况 maven依赖和配置1234567891011121314151617&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;io.lettuce&lt;/groupId&gt; &lt;artifactId&gt;lettuce-core&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt;&lt;/dependency&gt; TODO: spring-boot-starter-data-redis内部使用的不是jedis实现的连接池，经过之前的测试，如果使用lettuce-core这个连接池没有达到故障转移的效果, 所以这次实验使用jedis内部的连接池完成 application.yml12345678910spring: redis: cluster: nodes: - 192.168.211.136:7001 - 192.168.211.136:7002 - 192.168.211.136:7003 - 192.168.211.136:7004 - 192.168.211.136:7005 - 192.168.211.136:7006 测试类12345678910111213141516171819202122232425262728@RunWith(SpringRunner.class)@SpringBootTestpublic class SpringbootRedisApplicationTests &#123; @Autowired private RedisTemplate redisTemplate; private Logger logger = LoggerFactory.getLogger(SpringbootRedisApplicationTests.class); @Test public void contextLoads() &#123; while (true) &#123; try &#123; // 不断的set值 int index = new Random().nextInt(10000); String key = "k-" + index; String value = "v-" + index; redisTemplate.boundValueOps(key).set(value); // 输出日志 logger.info("&#123;&#125; value is &#123;&#125;", key, redisTemplate.boundValueOps(key).get()); Thread.sleep(500); &#125; catch (Exception e) &#123; logger.error(e.getMessage(), e); &#125; &#125; &#125;&#125; 此时节点状态： 开始不断的set值，在进行kill主节点，观察日志输出：]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springboot原理]]></title>
    <url>%2F2019%2F04%2F14%2Fspringboot%2Fspringboot%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[前言Spring Boot是Spring旗下众多的子项目之一。其理念是约定优于配置，它通过实现了自动配置（大多数用户平时习惯设置的配置作为默认配置）的功能来为用户快速构建出标准化的应用。内置了嵌入式的Tomcat、Jetty等Servlet容器，应用可以不用打包成War格式，而是可以直接以Jar格式运行 特点：spring boot不是对spring的增强，而是提供了一种快速使用spring的方式 核心：起步依赖、自动配置 快速搭建使用idea快速搭建一个springboot项目： 创建springboot项目 指定包名和项目名 选择需要的依赖文件 项目结构如下 pom依赖文件如下 编写一个controller 123456789@RestController@RequestMapping("/user")public class UserController &#123; @RequestMapping("/info.do") public String info() &#123; return "这是我的第一个spring boot程序"; &#125;&#125; 启动spring boot引导类 123456@SpringBootApplicationpublic class SpringBootDemoApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringBootDemoApplication.class, args); &#125;&#125; 访问8080 原理起步依赖起步依赖是spring boot的核心功能之一，起步依赖本质是maven定义了对其他库的传递依赖，简单的说，起步依赖就是将具备某种功能的坐标打包在一起，并提供一些默认的功能 springboot的起步依赖核心坐标123456&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.4.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;&lt;/parent&gt; 它提供了大量的Maven默认依赖。使用它之后，常用的包依赖可以省去version标签 自动配置spring boot默认配置了一些用户常用的配置，因此不需要我们先编写xml（如web.xml）在编写代码进行开发，那么它是如何做到的呢? 我们开发一个spring boot都会有如下启动类123456@SpringBootApplicationpublic class SpringBootDemoApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringBootDemoApplication.class, args); &#125;&#125; SpringBootApplication注解结构 @SpringBootConfiguration: 继承了Configuration（可进入查看），作用是取代xml的方式(spring的纯注解开发) @ComponentScan：组件扫描，表示其他包可使用spring组件 EnableAutoConfiguration注解:开启springboot的注解功能，springboot的四大神器之一，其借助@import的帮助，将所有符合自动配置条件的bean定义加载到IOC容器中。EnableAutoConfiguration有如下信息 AutoConfigurationImportSelector类该类用于管理加载默认的配置信息，例如我们使用springmvc必须会经过dispatchservlet，那么spring boot会将这些配置存储到如下文件中：可发现这些类都AutoConfiguraion作为结尾, spring boot会将这些存有自动配置的类获取并加载, 我们分析其源代码：可发现@bean，作用是取代xml的bean标签(spring的纯注解开发) EnableConfigurationProperties注解该注解的作用是加载ServerProperties服务器相关配置属性类，例如上述搭建的程序，访问tomcat默认端口为8080，这些默认配置存储在如下文件中： 当需要覆盖默认配置，在application.xml中指定即可 总结springboot的启动类会加载SpringBootApplication注解，该注解包含了@configuration（该类为配置类，取代xml）、@import（加入其他配置类）、自动装配的核心注解EnableAutoConfiguration，它用于完成记录默认的配置信息（web.xml）、服务器的配置信息(tomcat)]]></content>
      <categories>
        <category>springboot</category>
      </categories>
      <tags>
        <tag>springboot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis集群伸缩]]></title>
    <url>%2F2019%2F04%2F12%2Fredis%2Fredis%E9%9B%86%E7%BE%A4%E4%BC%B8%E7%BC%A9%2F</url>
    <content type="text"><![CDATA[引入上一篇章中，我们分析了节点取余和一致性哈希产生数据迁移的问题，而rediscluster并不会有这种情况，因为每个节点负责槽的范围都是固定的，每个节点与槽的分配都具备权力 集群伸缩原理它的原理其实就是rediscluster的基本架构（在rediscluster文章所讲述）： 节点: 每个节点负责读写 meet: 完成节点之间通信工作 A meet C; A meet B; B &gt; C 指派槽: 只有给节点指派了槽才可以进行读写 复制: 为了达到高可用，有主从复制概念 集群伸缩 = 槽和数据在节点之间的移动 集群扩容首先加入集群的作用有：实现扩容、作为从节点负责故障转移，实现扩容的步骤： 准备新的节点 集群模式 配置和其他节点统一 启动后是孤儿节点 加入集群（meet）将两个孤儿节点加入到集群中，(可通过cluster-meet完成，不推荐)，推荐使用redis-trib.rb加入集群，它会检测你加入的节点是否为孤儿节点，是才可进行加入 迁移槽和数据 把其他节点负责的槽均匀的迁移到新节点，让它工作起来 槽迁移规划 我们需要将槽进行均衡的分配 迁移数据 让目标节点准备导入槽的数据: cluster setslot {slot} importing {sourceNodeId} 对源节迁移出槽数据：cluster setslot {slot} migrating {targetNodeId} 对源节点循环遍历槽，获取count个槽的key：cluster getkeysinslot {slot} {count} 在源节点执行：migrate {targetIp} {targetPort} key 0 {timeout} 重复执行步骤3-4直到槽下所有的键数据迁移到目标节点 通知槽分配个目标节点：cluster setslot {slot} node {targetNodeId} 加入集群实战 此时的集群状态 12345678910111213141516171819202122232425262728293031323334353637# 启动7006和7007(拷贝文件和修改配置文件不在阐述)root 52263 1 0 05:10 ? 00:00:00 redis-server *:7006 [cluster]root 52272 1 1 05:10 ? 00:00:00 redis-server *:7007 [cluster]# 此时为孤立状态[root@zhongjinlang redis]# redis-cli -p 7006127.0.0.1:7006&gt; cluster nodesd65a5d7b0dcc09542761ac746ab4058fd002a5a4 :7006 myself,master - 0 0 0 connected# 加入集群[root@zhongjinlang redis]# redis-cli -p 7000127.0.0.1:7000&gt; cluster meet 192.168.211.136 7006127.0.0.1:7000&gt; cluster meet 192.168.211.136 7007127.0.0.1:7000&gt; cluster nodes# 此时已经加入了集群0936d215f3adc8aad93f935ba5ea72c7d6cc7bd0 192.168.211.136:7007 master - 0 1555017424796 7 connectedd65a5d7b0dcc09542761ac746ab4058fd002a5a4 192.168.211.136:7006 master - 0 1555017423368 0 connected# 7007（从）复制 7006（主）配置[root@zhongjinlang redis]# redis-cli -p 7007 cluster replicate d65a5d7b0dcc09542761ac746ab4058fd002a5a4OK# 为7006主节点分配槽，在/usr/local/bin[root@zhongjinlang bin]# redis-trib reshard 192.168.211.136:7000# 提示输入How many slots do you want to move (from 1 to 16384)? 4096What is the receiving node ID? d65a5d7b0dcc09542761ac746ab4058fd002a5a4Please enter all the source node IDs. Type 'all' to use all the nodes as source nodes for the hash slots. Type 'done' once you entered all the source nodes IDs.Source node #1:all# 查看槽信息[root@zhongjinlang bin]# redis-cli -p 7006 cluster nodes# 可发现槽有三份数据d65a5d7b0dcc09542761ac746ab4058fd002a5a4 192.168.211.136:7006 myself,master - 0 0 8 connected 0-1364 5461-6826 10923-12287 收缩集群收缩集群就是对一个节点进行下线，实现步骤如下： 下线迁移槽我们将下线7006和7007，并将他们的槽均匀的给其他节点 1234567891011121314151617181920212223242526# 查看集群redis-cli -p 7000 cluster nodes# 将7006节点的槽（有三段）迁移给主节点7000[root@zhongjinlang bin]# redis-trib reshard --from d65a5d7b0dcc09542761ac746ab4058fd002a5a4 --to 5fe9ca13ded00d87f3271380f9e0c7278ec8c483 --slots 1366 192.168.211.136:7006# 迁移给7001[root@zhongjinlang bin]# redis-trib reshard --from d65a5d7b0dcc09542761ac746ab4058fd002a5a4 --to d0941ed132c5a495545e1e30808cefd243942309 --slots 1365 192.168.211.136:7006# 迁移给7002[root@zhongjinlang bin]# redis-trib reshard --from d65a5d7b0dcc09542761ac746ab4058fd002a5a4 --to 3f3b1a02189aa7b27d5ebc2038a07441933b7327 --slots 1365 192.168.211.136:7006# 先下线7006的从节点7000[root@zhongjinlang bin]# redis-trib del-node 192.168.211.136:7000 0936d215f3adc8aad93f935ba5ea72c7d6cc7bd0...&gt;&gt;&gt; Sending CLUSTER FORGET messages to the cluster...&gt;&gt;&gt; SHUTDOWN the node.# 下线7006[root@zhongjinlang bin]# redis-trib del-node 192.168.211.136:7000 d65a5d7b0dcc09542761ac746ab4058fd002a5a4# 此时集群状态[root@zhongjinlang bin]# redis-cli -p 7000 cluster nodesbf5e78c9bc9728a2af1ac4077a539207146963a9 192.168.211.136:7004 slave d0941ed132c5a495545e1e30808cefd243942309 0 1555021435868 10 connected3a959f75d04e953b71c80f74f4d5c63b9fd319fd 192.168.211.136:7003 slave 5fe9ca13ded00d87f3271380f9e0c7278ec8c483 0 1555021438977 9 connected3f3b1a02189aa7b27d5ebc2038a07441933b7327 192.168.211.136:7002 master - 0 1555021437945 11 connected 10924-163835fe9ca13ded00d87f3271380f9e0c7278ec8c483 192.168.211.136:7000 myself,master - 0 0 9 connected 0-5461d0941ed132c5a495545e1e30808cefd243942309 192.168.211.136:7001 master - 0 1555021440005 10 connected 5462-10923a9b8f471b99a598cf295f3c15dcb12325302d1bd 192.168.211.136:7005 slave 3f3b1a02189aa7b27d5ebc2038a07441933b7327 0 1555021434839 11 connected rediscluster客户端当我们对一个rediscluster执行set或get时，rediscluster的计算规则是怎样的? move重定向 当客户端拿到moved异常后，需要对目标执行命令，注意此时客户端并不会自动找到目标节点进行重定向发送(如果使用redis-cli)。而redis-cli-c内部完成了重定向 槽命中和不命中情况计算某个key所对应的槽位置的命令: cluster keyslot key 如果set值，并在槽的范围内，返回OK 如果不在槽返回为返回moved异常 + 槽位置 + 节点位置。 1234567891011121314# 使用redis-cli设置值127.0.0.1:7000&gt; set hello worldOK# 因为php不在7000负责的槽范围内127.0.0.1:7000&gt; set php one(error) MOVED 9244 192.168.211.136:7001# 使用redis-cli-c集群模式连接127.0.0.1:7000&gt; set php best-&gt; Redirected to slot [9244] located at 192.168.211.136:7001OK192.168.211.136:7001&gt; get php"best" ask重定向当进行集群缩容和扩容时，由于槽处于迁移的过程。例如：一个slot存在三个key，分别为hello1、hello2、hello3，假设此时槽正在处于迁移状态，hello1已经迁移到了目标节点，此时如果在源节点获取hello1，则会报出ask重定向错误 move异常和ask异常 两者都是客户端重定向 moved: 槽已经确定迁移 ask： 槽还在迁移的过程中]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redisCluster]]></title>
    <url>%2F2019%2F04%2F11%2Fredis%2FredisCluster%2F</url>
    <content type="text"><![CDATA[sentinel问题引入上一篇章中，我们讲述了redis sentinel实现高可用。我们发现使用哨兵，每个slave都是全量存储数据，每个redis存储的内容都是完整的数据，浪费内存且有木桶效应。我们希望最大化的利用内存，采用集群，分布式存储。即每台redis都存储不同的内容。redisCluster是redis3.0推出的功能，有效的解决了redis分布式方面的需求，当遇到单机内存、并发、流量等瓶颈时，可采用cluster架构达到均衡负载的目的。 sentinel和clustersentinel与cluster是两个独立的功能，从特性来看sentinel可视为集群的子集，当不需要数据分片或已在客户端分片的场景下，sentinel足够使用了。如果需要进行水平扩容，那么cluster是一个很好的选择 数据分布集群首要解决把整个数据集按照分区规则映射到多个节点的问题，即把数据集划分到多个节点上，每个节点负责整个数据的一个子集 顺序分区 | 哈希分区 顺序分区保证每个节点的数据均衡 哈希分区 对每一个数字进行哈希函数，按照节点取余(实现之一) 对比 哈希分区探究redis-cluster采用哈希分区的方式进行数据分布，为此我们将进一步分析 节点取余分区对每一个key对3（节点个数）取余，如果余数为0则分布到第一个节点，余数为2则分布到第二个节点，余数为3则分布到第三个节点 客户端分片: 哈希 + 取余 节点伸缩： 节点变化，数据迁移量巨大 一致性哈希分区解决了节点取余的缺点token表示一个数据范围，为每一个节点分配一个token，每一个节点负责一部分token数据。当对key进行hash计算后按照顺时针的规则寻找离它最近的节点 客户端分片: 哈希 + 取余(优化取余) 节点伸缩： 只影响临近节点，但还是有数据迁移 虚拟槽分区Redis Cluster中有一个16384长度的槽的概念, 每个槽映射一个数据子集, 按照一定的hash计算对16383取余, 如果它落在某个槽的范围内，那么就证明这个槽必须所管理的数据，它是由服务端管理接节点槽之间的关系 节点取余分区和一致性哈希分区当节点伸缩时，都会进行数据的迁移，而rediscluster并不会有这种情况，因为每个节点负责槽的范围都是固定的，每个节点与槽的分配都具备权力 redisCluster架构 服务端有多个节点，每个节点都负责读写，节点之间是彼此通信的。如果节点A覆盖0－5460、节点B覆盖5461－10922、节点C覆盖10923－16383。 如果存入一个值，按照redis cluster哈希槽的算法： CRC16(‘key’)384 = 6782。 那么就会把这个key 的存储分配到 B 上了。同样，当我连接(A,B,C)任何一个节点想获取’key’这个key时，也会这样的算法，然后内部跳转到B节点上获取数据 基本架构 节点: 每个节点负责读写 meet: 完成节点之间通信工作 A meet C; A meet B; B &gt; C 指派槽: 只有给节点指派了槽才可以进行读写 复制: 为了达到高可用，有主从复制概念 rediscluster特性：复制、高可用、分片 原生命令安装 环境 3主3从 &gt; 192.168.211.134:7000(主) &gt; 192.168.211.134:7001(主) &gt; 192.168.211.134:7002(主) &gt; 192.168.211.134:7003(从) &gt; 192.168.211.134:7004(从) &gt; 192.168.211.134:7005(从) redis-[7000-70005].conf1234567891011port 7000daemonize yesdir ./logfile "7000.log"dbfilename "dump-7000.rdb"# 开启clustercluster-enabled yes# cluster配置文件cluster-config-file nodes-7000.conf# 如果有一个master宕机，没有故障恢复，整个集群不可用（默认true）cluster-require-full-coverage no 其他配置文件只需修改端口即可 启动123456789101112131415161718[root@localhost cluster]# redis-server redis-7000.conf[root@localhost cluster]# redis-server redis-7001.conf[root@localhost cluster]# redis-server redis-7002.conf[root@localhost cluster]# redis-server redis-7003.conf[root@localhost cluster]# redis-server redis-7004.conf[root@localhost cluster]# redis-server redis-7005.conf[root@localhost cluster]# ps -ef | grep redisroot 57254 1 0 01:44 ? 00:00:00 redis-server *:7000 [cluster]root 57258 1 0 01:44 ? 00:00:00 redis-server *:7001 [cluster]root 57262 1 0 01:44 ? 00:00:00 redis-server *:7002 [cluster]root 57266 1 0 01:44 ? 00:00:00 redis-server *:7003 [cluster]root 57270 1 0 01:44 ? 00:00:00 redis-server *:7004 [cluster]root 57274 1 0 01:44 ? 00:00:00 redis-server *:7005 [cluster]# 测试连接[root@localhost cluster]# redis-cli -p 7000127.0.0.1:7000&gt; set hello world(error) CLUSTERDOWN The cluster is down 我们可发现当set值时，错误表示当前集群是一个下线状态，因为在集群模式下，只有成功分配了槽且16383都进行了完整的分配，才可进行对外提供服务 meet port meet port完成节点之间的通信 1234567891011121314151617[root@localhost cluster]# redis-cli -p 7000 cluster meet 192.168.211.134 7001OK[root@localhost cluster]# redis-cli -p 7000 cluster meet 192.168.211.134 7002OK[root@localhost cluster]# redis-cli -p 7000 cluster meet 192.168.211.134 7003OK[root@localhost cluster]# redis-cli -p 7000 cluster meet 192.168.211.134 7004OK[root@localhost cluster]# redis-cli -p 7000 cluster meet 192.168.211.134 7005OK[root@localhost cluster]# redis-cli -p 7000 cluster nodes9c736c0733323151ee5aeaa8444cf177ab9b312b 192.168.211.134:7005 master - 0 1554832945389 5 connected97ba85211fa2d68ebff5ae4848eb4a52a899be5a 192.168.211.134:7003 master - 0 1554832943331 4 connected0ed9079a0d32b7e926a96d6a03d431c1228deffb 192.168.211.134:7000 myself,master - 0 0 1 connected89d495be82b618256b5c79a56f6894658db4cfa8 192.168.211.134:7004 master - 0 1554832942315 3 connectedb4c274d2501d4d105c8b7acf7787a66287a7406a 192.168.211.134:7001 master - 0 1554832941298 0 connected8465de32a8e17d23134d8ae8d62f2c78c9e40ef2 192.168.211.134:7002 master - 0 1554832944358 2 connected 此时6个节点已经达成相互通信! 分配槽点redis总共有16384个槽点，并且只有主节点需要分配槽点，这里我们使用的是三主三从，因此将槽点均分为三等分:0–5460，5461–10922，10923–16383 首先我们编写一个sh脚本 123456789start=$1end=$2port=$3for slot in `seq $&#123;start&#125; $&#123;end&#125;`do echo "slot:$&#123;slot&#125;" redis-cli -h 192.168.211.134 -p $&#123;port&#125; cluster addslots $&#123;slot&#125;done 分别为7000、7001、7002三个从节点分配槽节点 123sh add_slots.sh 0 5460 7000sh add_slots.sh 5461 10922 7001sh add_slots.sh 10923 16383 7002 查看槽信息 设置值123redis-cli -c -p 7000127.0.0.1:7000&gt; set hello worldOK 主从关系分配 cluster replicate node-id完成 7000-&gt;7003、7001-&gt;7004、7002-&gt;7005 12345678910111213141516[root@localhost cluster]# redis-cli -p 7003 cluster replicate 0ed9079a0d32b7e926a96d6a03d431c1228deffbOK[root@localhost cluster]# redis-cli -p 7004 cluster replicate b4c274d2501d4d105c8b7acf7787a66287a7406aOK[root@localhost cluster]# redis-cli -p 7005 cluster replicate 8465de32a8e17d23134d8ae8d62f2c78c9e40ef2OK[root@localhost cluster]# redis-cli -p 7000 cluster nodes# 可以发现7005-7004都成为了salve9c736c0733323151ee5aeaa8444cf177ab9b312b 192.168.211.134:7005 slave 8465de32a8e17d23134d8ae8d62f2c78c9e40ef2 0 1554833875305 5 connected97ba85211fa2d68ebff5ae4848eb4a52a899be5a 192.168.211.134:7003 slave 9c736c0733323151ee5aeaa8444cf177ab9b312b 0 1554833874286 5 connected89d495be82b618256b5c79a56f6894658db4cfa8 192.168.211.134:7004 slave b4c274d2501d4d105c8b7acf7787a66287a7406a 0 1554833871215 3 connected# 3个主节点0ed9079a0d32b7e926a96d6a03d431c1228deffb 192.168.211.134:7000 myself,master - 0 0 1 connectedb4c274d2501d4d105c8b7acf7787a66287a7406a 192.168.211.134:7001 master - 0 1554833873263 0 connected8465de32a8e17d23134d8ae8d62f2c78c9e40ef2 192.168.211.134:7002 master - 0 1554833876331 2 connected Ruby搭建集群ruby是官方推荐的搭建集群方式，自动分配槽和主从复制 安装ruby环境12345678# ruby依赖yum install ruby rubygems -y# gem-redis安装 https://rubygems.org/gems/redis/versions/3.0.0gem install -l redis-3.0.0.gem # 此时redis3.0.0/src目录有 redis.trib.rb文件，将它拷贝到/usr/lcoal/bincp redis-trib.rb /usr/local/bin/redis-trib redis-trib用于管理集群的命令 配置6个节点并启动12345678port 7001daemonize yesdir ./logfile "7001.log"dbfilename "dump-7001.rdb"cluster-enabled yescluster-config-file nodes-7001.confcluster-require-full-coverage no 其他节点修改端口即可，分别启动： 使用redis-trib搭建集群1redis-trib create --replicas 1 192.168.211.136:7001 192.168.211.136:7002 192.168.211.136:7003 192.168.211.136:7004 192.168.211.136:7005 192.168.211.136:7006 启动状态如下 cluster info打印集群信息 cluster nodes列出集群已知节点]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis集群——哨兵]]></title>
    <url>%2F2019%2F04%2F08%2Fredis%2Fredis%E9%9B%86%E7%BE%A4%E2%80%94%E2%80%94%E5%93%A8%E5%85%B5%2F</url>
    <content type="text"><![CDATA[主从复制问题引入当master和slave节点出现故障时，我们需要如何处理呢？首先我们知道故障是不可避免的。我们希望可做到高可用的故障转移，也就是说如果有一个服务宕机了，希望有另一台服务可顶替。通俗的将就是将故障进行转移，保证redis整体服务是可运行的 master故障如果slave出现故障，问题并不是很大，因为可以从master进行读写操作。如果master故障了，那么其他从节点将会断开与master的连接，此时客户端只可进行读的操作 master宕机处理首先我们要保证有写数据，可以将一台slave成为master，另外一台成为从节点 上述问题并没有解决自动故障转移的主要问题：自动让slave成为master，让其他slave同步master redis sentinel架构 Redis-Sentinel是Redis官方推荐的高可用性(HA)解决方案, Redis-sentinel本身也是一个独立运行的进程，它能监控多个master-slave集群，发现master宕机后能进行自动切换。它的主要功能有如下几点 不时地监控redis是否按照预期良好地运行 如果发现某个redis节点运行出现状况，能够通知另外一个进程(例如它的客户端) 能够进行自动切换。当一个master节点不可用时，能够选举出master的多个slave(如果有超过一个slave的话)中的一个来作为新的master,其它的slave节点会将它所追随的master的地址改为被提升为master的slave的新地址 sentinel核心配置12345678910111213# 去掉注释查看文件[root@localhost config]# cat sentinel.conf | grep -v "#" | grep -v "^$"# sentinel默认端口port 26379dir /tmp# 监控主节点 2标识你需要几个sentinel对master进行发现问题sentinel monitor mymaster 127.0.0.1 6379 2# 故障时间sentinel down-after-milliseconds mymaster 30000# 复制同时并发执行sentinel parallel-syncs mymaster 1# 故障转移时间sentinel failover-timeout mymaster 180000 sentinel实验实现如下配置 master-7000、slave-7001、slave-7002 sentinel-26379(默认端口)、sentinel-26380、sentinel-26381 开启主从节点redis-7000.conf(master) vim redis-{port}.conf: 分别添加如下配置12345port 7000daemonize yespidfile /var/run/redis-7000.pidlogfile "7000.log"dir ./ redis-7001.conf(slave)123456port 7001daemonize yespidfile /var/run/redis-7001.pidlogfile "7001.log"dir ./slaveof 192.168.211.134 7000 redis-7002.conf修改端口即可 启动一主二从123456789101112131415[root@localhost config]# redis-server redis-7000.conf [root@localhost config]# redis-server redis-7001.conf [root@localhost config]# redis-server redis-7002.conf [root@localhost config]# redis-cli -p 7000 pingPONG[root@localhost config]# redis-cli -p 7001 pingPONG[root@localhost config]# redis-cli -p 7002 pingPONG[root@localhost config]# redis-cli -p 7000 info replication# Replicationrole:masterconnected_slaves:2slave0:ip=192.168.211.134,port=7001,state=online,offset=197,lag=0slave1:ip=192.168.211.134,port=7002,state=online,offset=197,lag=1 开启sentinelsentinel-26379.conf12345678port 26379daemonize yesdir /tmplogfile "26379.log"sentinel monitor mymaster 192.168.211.134 7000 2sentinel down-after-milliseconds mymaster 30000sentinel parallel-syncs mymaster 1sentinel failover-timeout mymaster 180000 其他sentinel-26380.conf、sentinel-26381.conf修改端口即可 测试sentinel启动sentinel123[root@localhost config]# redis-sentinel redis-sentinel-26379.conf [root@localhost config]# redis-sentinel redis-sentinel-26380.conf [root@localhost config]# redis-sentinel redis-sentinel-26381.conf sentinel info12345678910111213[root@localhost config]# redis-cli -p 26379127.0.0.1:26379&gt; set hello world(error) ERR unknown command 'set'127.0.0.1:26379&gt; pingPONG127.0.0.1:26379&gt; info# Sentinel 的一些信息sentinel_masters:1sentinel_tilt:0sentinel_running_scripts:0sentinel_scripts_queue_length:0# sentinels=3 有三个sentinelmaster0:name=mymaster,status=ok,address=192.168.211.134:7000,slaves=2,sentinels=3 我们可发现sentinel监控的master和开启了多少个sentinel进行监控主从的信息 查看sentinel的变化1234567891011121314[root@localhost config]# cat redis-sentinel-26379.conf port 26379daemonize yesdir "/tmp"logfile "26379.log"sentinel monitor mymaster 192.168.211.134 7000 2sentinel config-epoch mymaster 0sentinel leader-epoch mymaster 0# 【关键的信息】：sentinel发现了master有两个从节点sentinel known-slave mymaster 192.168.211.134 7001# Generated by CONFIG REWRITE# 【关键的信息】：sentinel发现了master有两个从节点sentinel known-slave mymaster 192.168.211.134 7002sentinel current-epoch 0 sentinel会自动发现slave信息 客户端连接sentinel为什么我们不直接连接master? 因为我们采用高可用的方式，如果服务器端master宕机了，sentinel会完成自动的故障转移，那么此时客户端就不知道master节点的ip了。 基本原理： 故障转移实验我们将实现从master-7000端口中不断的set值，然后将master进程kill看看sentinel会不会自动处理故障转移 mavean依赖12345678910111213141516171819202122232425&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;version&gt;2.9.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;version&gt;1.7.25&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-classic&lt;/artifactId&gt; &lt;version&gt;1.1.9&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; ResisSentinelTest.java12345678910111213141516171819202122232425262728293031323334353637public class ResisSentinelTest &#123; private static Logger logger = LoggerFactory.getLogger(RedisPipelineTest.class); public static void main(String[] args) &#123; String masterName = "mymaster"; Set&lt;String&gt; sentinels = new HashSet&lt;&gt;(); sentinels.add("192.168.211.134:26379"); sentinels.add("192.168.211.134:26380"); sentinels.add("192.168.211.134:26381"); JedisSentinelPool sentinelPool = new JedisSentinelPool(masterName, sentinels); int count = 0; while (true) &#123; count++; Jedis jedis = null; try &#123; // 获取连接 jedis = sentinelPool.getResource(); // 不断的set值 int index = new Random().nextInt(10000); String key = "k-" + index; String value = "v-" + index; jedis.set(key, value); if (count % 100 == 0) &#123; logger.info("&#123;&#125; value is &#123;&#125; ", key, jedis.get(key)); &#125; TimeUnit.MICROSECONDS.sleep(100); &#125; catch (Exception e) &#123; logger.error(e.getMessage(), e); &#125; finally &#123; if (jedis != null) &#123; jedis.close(); &#125; &#125; &#125; &#125;&#125; 执行上述代码之后会不断的输出如下日志信息 当我们在进行kill master之后控制台会输出如下日志信息 当过了30秒之后sentinel会进行故障转移，恢复set的操作 我们可以查看salve-7001和slave和7002哪个成为了master1234[root@localhost config]# redis-cli -p 7002127.0.0.1:7002&gt; info replication# Replicationrole:master sentinel原理sentinel可以对redis节点作失败判定以及故障转移，在sentinel内部有三个定时任务作为基础来实现上述所描述的 每10秒每个sentinel对master和slave执行info 发现slave 确认主从关系 每两秒每个sentinel和master进行发布订阅模式的形式，达成整体的信息交互平台 通过sentinel:hello频道交互 交互对节点的”看法”和自身信息 每一秒每个sentinel对其他sentinel和redis执行ping 心跳检测、失败判定的依据 主观下线|客观下线sentinel核心配置1234sentinel monitor mymaster 127.0.0.1 6379 2 sentinel down-after-milliseconds mymaster 30000sentinel parallel-syncs mymaster 1sentinel failover-timeout mymaster 180000 monitor1sentinel monitor [master-group-name] [ip] [port] [quorum] 这一行用于告诉Redis监控一个master叫做mymaster，它的地址在127.0.0.1，端口为6379，票数是2，票数个数建议为奇数, 且个数=1/2+1 quorun：票数，sentinel需要协商同意master是否可到达的数量，举个例子，redis集群中有5个sentinel实例，其中master挂掉啦，如果这里的票数是2，表示有2个sentinel认为master挂掉啦，才能被认为是正真的挂掉啦 down-after-millisecondssentinel会向master发送心跳PING来确认master是否存活，如果master在“一定时间范围”内不回应PONG 或者是回复了一个错误消息，那么这个sentinel会主观地认为这个master已经不可用了。而这个down-after-milliseconds就是用来指定这个“一定时间范围”的，单位是毫秒。 主观下线：每个sentinel节点对redis节点的失败的”偏见” 客观下线：所有sentinel节点对redis节点失败”达成共识”（超过票数个统一） parallel-syncs在发生failover主从切换时，这个选项指定了最多可以有多少个slave同时对新的master进行同步，这个数字越小，完成主从故障转移所需的时间就越长，但是如果这个数字越大，就意味着越多的slave因为主从同步而不可用。可以通过将这个值设为1来保证每次只有一个slave处于不能处理命令请求的状态。 领导则选举我们知道之际上完成故障转移的任务只需要一个sentinel即可。选举通过sentinel is-master-down-by-addr命令都希望成为领导者，此命令的作用: 一确认下线判定，二是进行领导者选举 选举过程1）每个做主观下线的sentinel节点向其他sentinel节点发送上面那条命令，要求将它设置为领导者。 2）收到命令的sentinel节点如果还没有同意过其他的sentinel发送的命令（还未投过票），那么就会同意，否则拒绝。 3）如果该sentinel节点发现自己的票数已经过半且达到了quorum的值，就会成为领导者 4）如果这个过程出现多个sentinel成为领导者，则会等待一段时间重新选举 总结 redis-sentinel是redis实现高可用的方案：故障发现、故障自动转移、配置中心、客户端通知 redis-sentinel是redis2.8版本才开始正式使用 尽可能在不同的物理机上部署redis-sentinel所有节点 redis-sentinel中的sentinel节点个数应该为大于等于3且最好为奇数 客户端初始化连接的是sentinel节点集合，不再是具体的redis节点，但是sentinel只是配置中心不是代理 redis-sentinel通过三个定时任务实现了sentinel节点对主从节点、其余sentinel节点的监控 redis-sentinel在对节点做失败判定时分为主管下线和和客观下线]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis集群——复制]]></title>
    <url>%2F2019%2F04%2F07%2Fredis%2Fredis%E9%9B%86%E7%BE%A4%E2%80%94%E2%80%94%E5%A4%8D%E5%88%B6%2F</url>
    <content type="text"><![CDATA[主从复制 单机部署redis所存在的问题：机器故障数据转移、容量瓶颈、QPS瓶颈 主节点master负责写数据，从节点slave负责读数据，主节点定期把数据同步到从节点保证数据的一致性 主从复制的作用：数据副本（高可用分布式基础）、读写分离提高性能 两种实现方式命令slaveof和配置文件的方式 slaveof1234# 6380节点（从）复制6379节点（主）redis-6380 &gt; slaveof 192.168.211.134:6379 OK# 取消复制（不希望成为从），此时会断开连接（从数据并不会丢失，而是主的数据不会同步给从）redis-6380 &gt; slaveof no one OK 主从复制实验 我们通过配置文件的方式实现 6379作为主节点、6380为从节点 其中有两个中要的配置slaveof ip port、slave-read-only yes（期望从节点只作读操作）目的是达到主从复制数据的一致性效果。保证主节写操作，而从节点只作为读操作 cp redis.conf两份分别命名为 redis-6379.conf、redis-6380.conf redis-6379.conf12345678910111213141516# 后台启动daemonize yes #进程idpidfile /var/run/redis-6379.pid# 主节点密码masterauth &lt;master-password&gt;# 当前节点端口port 6379# 日志文件logfile "6379.log"# rdb文件dbfilename dump-6379.rdb# 设置主从关系slaveof &lt;masterip&gt; &lt;masterport&gt;# 只读，主节点不关心slave-read-only yes 开启服务并连接客户端1234567redis-server redis-6379.confredis-cli# 查看分片信息127.0.0.1:6379&gt; info replication role:master # 主节点connected_slaves:0 # 所连接的从节点个数 redis-6380.conf12345678daemonize yes # 开启守护者进程pidfile /var/run/redis-6380.pid #进程idport 6380logfile "6380.log"dbfilename dump-6380.rdb # rdb文件slaveof 192.168.211.134 6379 # 成为6379的从节点# 从节点只作为读操作slave-read-only yes 开启服务并连接客户端123456redis-server redis-6379.confredis-cli -p 6380127.0.0.1:6379&gt; info replication # 查看分片信息role:slave # 已成为从节点master_host:192.169.211.134 # 主节点地址master_port:6379 # 主节点端口 测试从主节点6379端口中set值，从节点会复制主节点的数据 日志分析主从复制的读写分离实际上内部使用命令的方式进行数据的同步，我们可以分析两个日志文件 6379.log 123456# 表示6380需要进行复制操作Slave 192.168.211.134:6380 asks for synchronization# resync 全量复制操作Full resync requested by slave 192.168.211.134:6380# 可以发现复制操作是使用RDB进行实现的，实际就是将快照进行同步Starting BGSAVE for SYNC with target: disk 6380.log 123456789101112131415# 连接主节点Connecting to MASTER 192.168.211.134:6379# 主从复制MASTER &lt;-&gt; SLAVE sync started# 拿到master的runid（每一个redis启动时的随机ID）Full resync from master: f45a09af5ab5fe887ad7a33b451e4955b1dafebd:1# 拿到master节点数据(rbd)receiving 31 bytes from master# 清空之前的数据(全量复制的情况下)Flushing old data# 加载rdbLoading DB in memory# 加载成功Finished with success 验证Flushing old data我们可以看到上述6380日志，当拿到master节点之后做的事情，清空旧的数据、加载RDB，如下实验验证是否安装该流程进行的 先将6380成为master 12redis-cli -p 6380&gt; slaveof no one 切换到6379添加数据 12redis-cli -p 6379mset a b c d 再切换到6380执行如下操作 1234567891011# 此时成为master当然不能同步数据keys *(empty list or set)# 设置一些数据127.0.0.1:6380&gt; set abc6380 hello127.0.0.1:6380&gt; slaveof 192.168.211.134 6379OK127.0.0.1:6380&gt; keys *1) "c"2) "a" 我们可以看到当slaveof继续成为从节点时候，再获取数据时之前的abc6379已被删除 全量复制我们在分析日志的时候发现，master有resync(全量复制)、slave有获取masterRUNID的一些操作，引入我们引入两个概念 runid 以及 偏移量 runid每一个redis服务启动时，都会随机一个字符串id，作为一个标识。如果重启之后，runid会消失 查看runid1234[root@localhost config]# redis-cli -p 6379 info server | grep runrun_id:f45a09af5ab5fe887ad7a33b451e4955b1dafebd[root@localhost config]# redis-cli -p 6380 info server | grep runrun_id:e93481fdcc9e791516c77f8a61a3e7e5e2db4f9e 当复制时发现和之前的 run_id不同时（重启），将会对数据全量同步，一般用于初次复制场景 偏移量一个数据写入量的字节(如 set a b)，此时从节点会同步记录偏移量，当主从偏移量达到一至时，那么就完成了数据同步的过程。简言之：通过对比主从节点的复制偏移量，可以判断主从节点数据是否一致 如果主、从偏移量不一至。master &gt; slave可能会出现主从不一致 查看偏移量12[root@localhost redis-3.0.7]# redis-cli -p 6379 info replicationmaster_repl_offset:48425 当我们添加值时，偏移量也会随着增加 查看主、从偏移量1234[root@localhost redis-3.0.7]# redis-cli -p 6379 info replicationmaster_repl_offset:49146[root@localhost redis-3.0.7]# redis-cli -p 6380 info replicationslave_repl_offset:49170 为什么主从偏移量不一致呢？实际上主从的偏移量是一个同步更新的状态，从节点会将一些状态向主节点上报。我们也可查看主从的同步状态：123[root@localhost redis-3.0.7]# redis-cli -p 6379 info replicationslave0:ip=192.168.211.134,port=6380,state=online,offset=49482,lag=2master_repl_offset:49482 通常offset差距不会太大，否则可能有其他问题如网络、阻塞 原理 如果对于一个存了很多数据的master，slave期望复制master中的数据，并且这些数据是时刻同步的、完整的。这样就可达到完整的数据同步效果。 首先将本身的RDB文件同步给slave，为了达到时刻同步，在此期间，master写入的命令也会记录下来。当slave将RDB加载完后，会通过偏移量的对比将这期间master写入的值同步给slave 首先slave发送命令psync ? -1，参数1:runid，参数2：偏移量（报告主节点偏移量）。由于第一次复制不知道runid和偏移量，所以参数为?和-1 master接收到此命令，将runid和偏移量发送给slave slave保存master的基本信息 master会执行bgsave（rdb生成） 此时怎么将RDB发送给salve呢？master内部有复制缓冲区reple_back_buffer，它可记录最新的数据 经过了缓冲区的过滤，将RDB和缓存的一些信息发送给slave(5-6步骤) slave先清空自己old数据 加载RDB以及缓存数据完成同步 部分复制经过上述分析，我们可以明显感受到，全量复制的开销是巨大的。有如下几个问题 bgsave时间，需要生成RDB RDB文件网络传输时间 slave清空old的时间 slave加载RDB的时间 可能的AOF重写时间 为什么需要部分复制 在redis2.8版本之前，如果master和slave之间的网络发生了抖动连接断开，就会导致slave完全不知道master的动作，同步就会出问题，而为了保证数据一致，等网络恢复后进行一次全量复制。而全量复制的开销是很大的，redis2.8版本就提个了一个部分复制的功能 部分复制的实现原理当master和slave断开连接时，master会将期间所做的操作记录到复制缓存区当中（可以看成是一个队列，其大小默认1M）。待slave重连后，slave会向master发送psync命令并传入offset和runId，这时候，如果master发现slave传输的偏移量的值，在缓存区队列范围中，就会将从offset开始到队列结束的数据传给slave，从而达到同步，降低了使用全量复制的开销]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[elasticsearch+filebeat+kibana日志收集]]></title>
    <url>%2F2019%2F04%2F06%2Felasticsearch%2FELK%E6%97%A5%E5%BF%97%E6%94%B6%E9%9B%86%2F</url>
    <content type="text"><![CDATA[日志对大规模日志数据进行采集、追踪、分析及处理 目前主流的分布式日志框架有： Logstash ELK(ElasticsSearch, Logstash, Kibana) – 一套强大的日志收集系统，由于Logstash消耗资源过大，官方推荐使用filebeat取代 Flume – 由Apache基金会提供的一个分布式、高可靠、高可用的服务 filebeat用于日志的收集、elasticsearch用于存储日志、kibana实现数据的展示 download: https://www.elastic.co/cn/downloads/past-releases elasticsearch install es启动不能使用root，因此需要创建一个用户组 123groupadd esuseradd es -g espasswd es 切换root进入es目录为es文件给予权限 1chown -R es:es es es-5.6.16 修改/conf/elasticsearch.yml 1234567# Network # 绑定ipnetwork.host: ip # 默认http端口http.port: 9200# 默认tcp端口transport.tcp.port: 9300 修改jvm内存大小 /conf/jvm.options 12-Xms1g-Xms1g 由于es启动需要开启大量线程，需要修改系统文件 1234567891011121314# vi /etc/security/limits.conf* soft nofile 65536* hard nofile 131072* soft nproc 2048* hard nproc 4096* soft memlock unlimited* hard memlock unlimited# cd /etc/security/limits.dvi 20-nproc.confroot soft nproc 2048# vi /etc/sysctl.confvm.max_map_count=655360 su es &gt; ./elasticsearch 如果启动不了设置防火墙 filebeatFilebeat是一个轻量型日志采集器，在你的服务器上安装客户端后，filebeat会监控日志目录或者指定的日志文件，追踪读取这些文件（追踪文件的变化，不停的读），并且转发这些信息到elasticsearch或者logstarsh中存放 安装完之后编辑核心配置文件filebeat.yml 12345678910111213# 指定被探测的日志文件, 可添加多个该配置paths: - /install/logs/*.log# 配置多行合并multiline.pattern: ^\[multiline.negate: truemultiline.match: after # 指定es的位置，将日志收集到es存储output.elasticsearch: # Array of hosts to connect to. hosts: ["192.168.211.134:9200"] ./filebeat 启动 日志收集测试 : 当配置的探测日志文件发生变化时，filebeat会将数据发送给ES进行存储 kibanakibana可取代elastic-head，提供了更为专业的可视化界面、日志分析系统，它是ES的成员之一 安装完之后配置kibana.yml核心配置文件12345678# 默认端口server.port: 5601# 绑定ipserver.host: "192.168.211.134"# 指定es的地址elasticsearch.url: "http://192.168.211.134:9200"# 启动cd bin &gt; ./kibana]]></content>
      <categories>
        <category>elasticsearch</category>
      </categories>
      <tags>
        <tag>elasticsearch</tag>
        <tag>Kibana</tag>
        <tag>Logstash</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis的持久化]]></title>
    <url>%2F2019%2F04%2F06%2Fredis%2Fredis%E7%9A%84%E6%8C%81%E4%B9%85%E5%8C%96%2F</url>
    <content type="text"><![CDATA[持久化的作用redis的所有数据存储到内存中，如果redis-server进程退出，那么数据将丢失。为了解决这个问题 Redis 提供了两种持久化的方案，将内存中的数据保存到磁盘中，避免数据的丢失 RDB该机制使用快照方式，在指定的时间内将内存中的数据写入到硬盘（rdb文件），也可手动执行命令 文件策略：如果存在老的RDB文件，会进行替换 优点：RBD作为一个备份文件容易恢复，性能好，通过子进程fork生成rdb，用于备份 缺点：容易造成数据丢失，如果fork花费时间大，那么将会阻塞redis服务、耗时耗性能 触发机制 save命令（同步 ） — 可能会产生阻塞 bgsave命令（异步）— 创建一个子进程fork() 生成rdb文件（阻塞发生在fork），创建完毕返回给主进程bgsave successfully 自动 — 根据save配置自动生成，例如如果在60秒内改变了1w条数据则生成rdb、300-10、900-1满足任一个条件（底层使用fork） 在redis.conf中节点为SNAPSHOTTING中有如下配置 12345678910111213save 900 1save 300 10save 60 10000# bgsave发生错误是否停止写入stop-writes-on-bgsave-error yes# rdb是否采用压缩格式rdbcompression yes# rbd校验rdbchecksum yes# 默认rbd文件名，在/bin目录dbfilename dump.rdb# 日志等文件存储位置dir ./ 推荐配置 12345678# 不采用自动生成# rbd文件名称采用+端口形式区分dbfilename dump-$&#123;port&#125;.rdb# 建议指定容量较大硬盘位置dir /bigdiskpath# 其他默认 不容忽略的方式：主从复制、debug reload、shutdown可能会触发 AOFRDB快照方式并不是很可靠，如果服务器宕机，那么最新的数据就会丢失。而AOF文件提供一种更为可靠的的持久化方式。当进行set操作时，会追加到AOF文件中。当redis重启之后，AOF中的命令会被重新执行一次，重建数据 AOF的三种策略 always：每条命令都会持久化一次（执行写操作时，先进入缓冲区后写入到硬盘） everysec：每秒持久化一次 no：缓冲区的刷新策略根据OS决定 AOF重写由于每条命令都会追加到AOF文件中，随着时间的推移，AOF文件必然逐渐变大。AOF重写解决了这一问题 例 ：命令优化、过期数据 123set hello oneset hello twoset hello three 当连续执行上诉命令最终的结果为three，而AOF并不会写入三次命令，而只会追加有效的命令set hello three AOF重写实现的两种方式 bgrewriteaof命令：（类似RDB的bgsave）开启子线程完成AOF重写 AOF重写配置 在/redis.conf配置文件有APPEND ONLY MODE节点 123456789101112# 要完成aof功能开启为yesappendonly no# 文件名appendfilename "appendonly.aof"# 三种同步策略# appendfsync alwaysappendfsync everysec -- 每秒写入（默认）# appendfsync no# 写入aof文件，不等待磁盘同步（安全，但可能阻塞）no-appendfsync-on-rewrite no RDB和AOF的抉择 比较 RDB最佳策略 “关闭”rdb 集中管理，指定时间内进行大量的数据备份 从节点开启 分片 AOF最佳策略 “开启” ： 缓存和存储 AOF重写集中管理 everysec策略 分片 问题fork当进行 RDB的bgsave操作和AOF的bgrewriteaof会产生子线程进行持久化的相关操作，如果fork操作执行慢，此时会将redis主线程阻塞。 查看fork持久化的时间 1latest_fork_usec 改善 物理机或支持fork操作的虚拟化技术 控制redis实例最大可用内存：maxmemory 合理配置Linux内存分配策略：vm.overcommit_memory=1（默认0） 放宽AOF重写自动触发机制，不必全量复制 进程外开销 bgsave和bgrewriteaof是将内存中的数据写入到硬盘，此时会集中消耗CPU、rork内存开销、硬盘 优化 不做CPU绑定，不和CPU密集部署，单机部署不要大量的AOF和RDB持久化的过程 echo never &gt; 追加配置文件 不要和高硬盘负载服务部署在一起：存储服务、消息队列等 配置no-appendfsync-on-rewrite yes ssd介质 AOF追加阻塞如果我们使用了AOF的每秒刷盘策略，如果fork执行大于2秒，那么主线程阻塞 阻塞定位 redis日志 info persistence收集记录]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[瑞士军刀redis]]></title>
    <url>%2F2019%2F04%2F05%2Fredis%2F%E7%91%9E%E5%A3%AB%E5%86%9B%E5%88%80redis%2F</url>
    <content type="text"><![CDATA[慢查询许多存储系统（例如MySQL）提供慢查询日志帮助开发和运维人员定位系统存在的慢操作。所谓慢查询日志就是系统在命令执行前后计算每条命令的执行时间，当超过预设阈值，就将这条命令的相关信息（例如：发生时间、耗时、命令的详细信息）记录下来，Redis也提供了类似的功能。 首先我们需要先了解client和serve的生命周期 慢查询发生在第三阶段 客户端超时不一定慢查询，但慢查询是客户端超时的一个可能因素 Pipeline多数情况下，我们会通过请求-响应的机制来操作redis。当要执行多个命令时，由于redis是单线程的，那么下一次请求必须等待上一次请求完成之后才可继续执行。而pipeline模式，客户端可一次性将命令打包发送， 无需等待服务端返回。这样就减少了网络往返时间。 使用传统方式 123456789@Testpublic void test1() &#123; long start = System.currentTimeMillis(); for (int i = 0; i &lt; 10000; i++) &#123; jedis.hset("hashKey:" + i, "field" + i, "value" + i); // hashkey1 -&gt; field:1 : value:1 &#125; long end = System.currentTimeMillis(); System.out.println("花费时间为: " + (end - start)); //2983&#125; 使用pipeline 12345678910@Testpublic void test2() &#123; Pipeline pipeline = jedis.pipelined(); long start = System.currentTimeMillis(); for (int i = 0; i &lt; 10000; i++) &#123; pipeline.hset("hashKey: " + i, "field" + i, "value" + i); // hashkey1 -&gt; field:1 : value:1 &#125; long end = System.currentTimeMillis(); System.out.println("花费时间为: " + (end - start)); // 38&#125; bitmap位图：基于最小的单位bit进行存储，非常省空间、二进制数据存储，计算快 12# 取出位图指定索引的值getbit element 0 使用场景：独立用户统计（一亿用户，五千万独立） set存储: 内存量200mb bitmap存储：内存量12.5mb]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis api]]></title>
    <url>%2F2019%2F04%2F05%2Fredis%2Fredis-api%2F</url>
    <content type="text"><![CDATA[通用命令 keys[patten]（查看所有的key） dbsiz（查看所有key的大小） exists key（判断一个key是否存在） del key [key ..] （删除key） expice key seconds（为key设置过期时间） type key（查看key类型） 内部编码架构 单线程架构 当我们在操作redis时，时刻要明白redis在一个瞬间只会执行一条命令，不会执行两条命令 单线程为何快？ 纯内存 非阻塞IO 避免线程之间的切换和竞态消耗 string redis所有的key都为字符串，value可存储普通字符串、数值、二进制 使用场景：缓存、计数器、分布式锁 字符串的value不能大于512MB 基本命令 get、set、del（O1）： 12345678# 获取key对应的valueget key # 设置key-valueset key value# 删除key-valuedel key 计数命令 incr 、decr、incrby、decrby（O1）： 123456789101112# key自增1，0开始incr key# 相反decr key# 期望自增指定值，key自增kincrby key k# 相反decrby key k# 浮点数的自增3.5incrbyfloat key 3.5 其他set命令 set、setnx、setxx 12345678# 不管key是否存在，都设置set key value# key不存在才进行设置（add操作）setnx key value# key存在才设置（update操作）set key value xx 批量处理命令：mget mset 12345# 批量获取keymget key1 key2 ..# 批量设置key-valuemset key1 value1 key2 value2 ... 如果传输n次get命令，那么 n次get = n次网络时间 + n次命令时间 如果1次将命令批量传输给服务端，那么 1次mget = 1次网络时间 + n次命令时间 其他命令 12345678# 为key设置新的值，并返回之前的值getset key newvalue# 为key追加值append key value# 返回字符串长度strlen key 使用场景： 记录网站每个用户个人主页的访问量 1incr userid:pageview 缓存视频的基本信息（数据源在mysql） 1231. 从redis中取数据，存在数据直接返回，则不需要访问mysql2. 若不存在，访问mysql，获取到数据，加入到redis缓存3. 当下此访问此接口时，会从redis中访问 hashhash键值结构： 基本命令 12345678# 获取hash key对应的field的valuehget key field# 设置hash key对应file的valuehset key field value# 删除hash key对应file的valuehdel key field value hexists、hlen 12345# 判断hash key是否有filedhexists key filed# 获取hash key fiedl的数量hlen key 批量操作 12345# 批量获取hash key的一批field对应的值hmget key field1 field2...# 批量设置hash key的一批field valuehmset key field1 value2 ... 其他命令 12345678# 返回hash key对应的所有field和valuehgetall key# 返回所有的值hvals key# 返回所有的fieldhkeys key 使用场景 和string 的使用场景类似、数据缓存等 listlist 队列结构：有序、可重复、左右两边插入弹出 增加操作 12345678# 从列表左边插入值lpush key val1 val2# 从列表右边插入值rpush key val1 val2 # 在列表指定值的前|后插入新的值linsert key before|after value newvalue 删除操作 123456789101112# 从列表左边弹出一个元素lpop key# 从列表右边弹出一个元素rpop key# 从列表删除所有value相等的值# count=0删除所有、count&gt;0左边开始删除、count&lt;0右边开始删除lrem key count value# 保留指定索引内的列表元素ltrim key start end 查询操作 12345678# 获取索引内范围的元素lrange key start end(包含)# 根据指定索引获取元素lindex key index# 列表长度llen key 修改操作 12# 设置指定索引的值lset key index newvalue 使用场景 用户抢购进入排队状态（加入队列） 你关注的人更新文博（LPUSH可看到最新状态、lrange范围查询） set集合特点：无序、无重复、可进行集合间操作（交集、并集） 基本命令 1234567891011121314151617181920# 向集合key添加元素（如果元素存在添加失败）sadd key element# 删除集合中某个元素srem key element# 计算集合sizescard key# 判断元素是否在在集合中存在sismember key element# 从集合中挑选一个元素（不删除）srandmember key# 从集合中弹出一个元素(删除)spop key # 取出集合中所有元素smembers key]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis初识]]></title>
    <url>%2F2019%2F04%2F05%2Fredis%2Fredis%E5%88%9D%E8%AF%86%2F</url>
    <content type="text"><![CDATA[引入redis是一款开源的nosql,基于key-value的键值对存储服务系统，支持多种数据结构。 redis的特性 多种数据结构 其中还扩展数据结构有 bitmaps：位图 ，（布隆过滤器可使用位图来实现） hyperloglog：超小内存唯一值计数（12k geo：地理信息位置 速度快 redis可达到10w读写速度，将数据存储到内存中，使用C语言编写（50000 line），单线程 持久化 功能丰富 主从复制 高可用、分布式 redis使用场景 缓存系统 先从cache中获取数据，如果有返回数据，没有则从数据库中取数据并加入到缓存中 计数器 消息队列系统 排行榜 社交网络 实时系统 redis的安装 http://download.redis.io/releases/ 1234567891011# 依赖yum install gcc-c++# 下载wget http://download.redis.io/releases/redis-3.0.7.tar.gz# cd到redis目录编译，会产生redis.conf、src等文件make# 安装到指定目录产生bin文件make install PREFIX=/install/redis# 如果客户端连接不了请关闭防火墙systemctl stop firewalld bin目录下6个可执行文件 redis-server：redis服务器 redis-cli：redis命令行客户端 redis-benchmark：基准测试 redis-check-aof：持久化aof文件修复工具 redis-check-dump：持久化rdb文件修复工具 redis-sentinel：sentinel服务器（2.8version） 三种启动redis方式 redis-serve（默认配置） redis-serve – port 6380（动态参数启动，默认端口是6379） redis-serve &amp;confipath（参与配置文件启动）]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
</search>
