<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title></title>
    <url>%2F2019%2F04%2F06%2Felasticsearch-filebeat-kibana%E6%97%A5%E5%BF%97%E6%94%B6%E9%9B%86%2F</url>
    <content type="text"><![CDATA[title: elasticsearch+filebeat+kibana日志收集date: 2019-04-06 21:18:14 tags: es日志对大规模日志数据进行采集、追踪、分析及处理 目前主流的分布式日志框架有： Logstash ELK(ElasticsSearch, Logstash, Kibana) – 一套强大的日志收集系统，由于Logstash消耗资源过大，官方推荐使用filebeat取代 Flume – 由Apache基金会提供的一个分布式、高可靠、高可用的服务 filebeat用于日志的收集、elasticsearch用于存储日志、kibana实现数据的展示 download: https://www.elastic.co/cn/downloads/past-releases elasticsearch install es启动不能使用root，因此需要创建一个用户组 123groupadd esuseradd es -g espasswd es 切换root进入es目录为es文件给予权限 1chown -R es:es es es-5.6.16 修改/conf/elasticsearch.yml 1234567# Network # 绑定ipnetwork.host: ip # 默认http端口http.port: 9200# 默认tcp端口transport.tcp.port: 9300 修改jvm内存大小 /conf/jvm.options 12-Xms1g-Xms1g 由于es启动需要开启大量线程，需要修改系统文件 1234567891011121314# vi /etc/security/limits.conf* soft nofile 65536* hard nofile 131072* soft nproc 2048* hard nproc 4096* soft memlock unlimited* hard memlock unlimited# cd /etc/security/limits.dvi 20-nproc.confroot soft nproc 2048# vi /etc/sysctl.confvm.max_map_count=655360 su es &gt; ./elasticsearch 如果启动不了设置防火墙 filebeatFilebeat是一个轻量型日志采集器，在你的服务器上安装客户端后，filebeat会监控日志目录或者指定的日志文件，追踪读取这些文件（追踪文件的变化，不停的读），并且转发这些信息到elasticsearch或者logstarsh中存放 安装完之后编辑核心配置文件filebeat.yml 12345678910111213# 指定被探测的日志文件, 可添加多个该配置paths: - /install/logs/*.log# 配置多行合并multiline.pattern: ^\[multiline.negate: truemultiline.match: after # 指定es的位置，将日志收集到es存储output.elasticsearch: # Array of hosts to connect to. hosts: ["192.168.211.134:9200"] ./filebeat 启动 日志收集测试 : 当配置的探测日志文件发生变化时，filebeat会将数据发送给ES进行存储 kibanakibana可取代elastic-head，提供了更为专业的可视化界面、日志分析系统，它是ES的成员之一 安装完之后配置kibana.yml核心配置文件12345678# 默认端口server.port: 5601# 绑定ipserver.host: "192.168.211.134"# 指定es的地址elasticsearch.url: "http://192.168.211.134:9200"# 启动cd bin &gt; ./kibana]]></content>
  </entry>
  <entry>
    <title><![CDATA[redis的持久化]]></title>
    <url>%2F2019%2F04%2F06%2Fredis%E7%9A%84%E6%8C%81%E4%B9%85%E5%8C%96%2F</url>
    <content type="text"><![CDATA[持久化的作用redis的所有数据存储到内存中，如果redis-server进程退出，那么数据将丢失。为了解决这个问题 Redis 提供了两种持久化的方案，将内存中的数据保存到磁盘中，避免数据的丢失 RDB 该机制使用快照方式，在指定的时间内将内存中的数据写入到硬盘（rdb文件），也可手动执行命令 文件策略：如果存在老的RDB文件，会进行替换 优点：RBD作为一个备份文件容易恢复，性能好，通过子进程fork生成rdb，用于备份 缺点：容易造成数据丢失，如果fork花费时间大，那么将会阻塞redis服务、耗时耗性能 触发机制 save命令（同步 ） — 可能会产生阻塞 bgsave命令（异步）— 创建一个子进程fork() 生成rdb文件（阻塞发生在fork），创建完毕返回给主进程bgsave successfully 自动 — 根据save配置自动生成，例如如果在60秒内改变了1w条数据则生成rdb、300-10、900-1满足任一个条件（底层使用fork） 在redis.conf中节点为SNAPSHOTTING中有如下配置 12345678910111213save 900 1save 300 10save 60 10000# bgsave发生错误是否停止写入stop-writes-on-bgsave-error yes# rdb是否采用压缩格式rdbcompression yes# rbd校验rdbchecksum yes# 默认rbd文件名，在/bin目录dbfilename dump.rdb# 日志等文件存储位置dir ./ 推荐配置 12345678# 不采用自动生成# rbd文件名称采用+端口形式区分dbfilename dump-$&#123;port&#125;.rdb# 建议指定容量较大硬盘位置dir /bigdiskpath# 其他默认 不容忽略的方式：主从复制、debug reload、shutdown可能会触发 AOFRDB快照方式并不是很可靠，如果服务器宕机，那么最新的数据就会丢失。而AOF文件提供一种更为可靠的的持久化方式。当进行set操作时，会追加到AOF文件中。当redis重启之后，AOF中的命令会被重新执行一次，重建数据 AOF的三种策略 always：每条命令都会持久化一次（执行写操作时，先进入缓冲区后写入到硬盘） everysec：每秒持久化一次 no：缓冲区的刷新策略根据OS决定 AOF重写由于每条命令都会追加到AOF文件中，随着时间的推移，AOF文件必然逐渐变大。AOF重写解决了这一问题 例 ：命令优化、过期数据 123set hello oneset hello twoset hello three 当连续执行上诉命令最终的结果为three，而AOF并不会写入三次命令，而只会追加有效的命令set hello three AOF重写实现的两种方式 bgrewriteaof命令：（类似RDB的bgsave）开启子线程完成AOF重写 AOF重写配置 在/redis.conf配置文件有APPEND ONLY MODE节点 123456789101112# 要完成aof功能开启为yesappendonly no# 文件名appendfilename "appendonly.aof"# 三种同步策略# appendfsync alwaysappendfsync everysec -- 每秒写入（默认）# appendfsync no# 写入aof文件，不等待磁盘同步（安全，但可能阻塞）no-appendfsync-on-rewrite no RDB和AOF的抉择 比较 RDB最佳策略 “关闭”rdb 集中管理，指定时间内进行大量的数据备份 从节点开启 分片 AOF最佳策略 “开启” ： 缓存和存储 AOF重写集中管理 everysec策略 分片 问题fork当进行 RDB的bgsave操作和AOF的bgrewriteaof会产生子线程进行持久化的相关操作，如果fork操作执行慢，此时会将redis主线程阻塞。 查看fork持久化的时间 1latest_fork_usec 改善 物理机或支持fork操作的虚拟化技术 控制redis实例最大可用内存：maxmemory 合理配置Linux内存分配策略：vm.overcommit_memory=1（默认0） 放宽AOF重写自动触发机制，不必全量复制 进程外开销 bgsave和bgrewriteaof是将内存中的数据写入到硬盘，此时会集中消耗CPU、rork内存开销、硬盘 优化 不做CPU绑定，不和CPU密集部署，单机部署不要大量的AOF和RDB持久化的过程 echo never &gt; 追加配置文件 不要和高硬盘负载服务部署在一起：存储服务、消息队列等 配置no-appendfsync-on-rewrite yes ssd介质 AOF追加阻塞如果我们使用了AOF的每秒刷盘策略，如果fork执行大于2秒，那么主线程阻塞 阻塞定位 redis日志 info persistence收集记录]]></content>
  </entry>
  <entry>
    <title><![CDATA[瑞士军刀redis]]></title>
    <url>%2F2019%2F04%2F05%2F%E7%91%9E%E5%A3%AB%E5%86%9B%E5%88%80redis%2F</url>
    <content type="text"><![CDATA[慢查询许多存储系统（例如MySQL）提供慢查询日志帮助开发和运维人员定位系统存在的慢操作。所谓慢查询日志就是系统在命令执行前后计算每条命令的执行时间，当超过预设阈值，就将这条命令的相关信息（例如：发生时间、耗时、命令的详细信息）记录下来，Redis也提供了类似的功能。 首先我们需要先了解client和serve的生命周期 慢查询发生在第三阶段 客户端超时不一定慢查询，但慢查询是客户端超时的一个可能因素 Pipeline多数情况下，我们会通过请求-响应的机制来操作redis。当要执行多个命令时，由于redis是单线程的，那么下一次请求必须等待上一次请求完成之后才可继续执行。而pipeline模式，客户端可一次性将命令打包发送， 无需等待服务端返回。这样就减少了网络往返时间。 使用传统方式 123456789@Testpublic void test1() &#123; long start = System.currentTimeMillis(); for (int i = 0; i &lt; 10000; i++) &#123; jedis.hset("hashKey:" + i, "field" + i, "value" + i); // hashkey1 -&gt; field:1 : value:1 &#125; long end = System.currentTimeMillis(); System.out.println("花费时间为: " + (end - start)); //2983&#125; 使用pipeline 12345678910@Testpublic void test2() &#123; Pipeline pipeline = jedis.pipelined(); long start = System.currentTimeMillis(); for (int i = 0; i &lt; 10000; i++) &#123; pipeline.hset("hashKey: " + i, "field" + i, "value" + i); // hashkey1 -&gt; field:1 : value:1 &#125; long end = System.currentTimeMillis(); System.out.println("花费时间为: " + (end - start)); // 38&#125; bitmap位图：基于最小的单位bit进行存储，非常省空间、二进制数据存储，计算快 12# 取出位图指定索引的值getbit element 0 使用场景：独立用户统计（一亿用户，五千万独立） set存储: 内存量200mb bitmap存储：内存量12.5mb]]></content>
  </entry>
  <entry>
    <title><![CDATA[redisAPI]]></title>
    <url>%2F2019%2F04%2F05%2FredisAPI%2F</url>
    <content type="text"><![CDATA[通用命令 keys[patten]（查看所有的key） dbsiz（查看所有key的大小） exists key（判断一个key是否存在） del key [key ..] （删除key） expice key seconds（为key设置过期时间） type key（查看key类型） 内部编码架构 单线程架构 当我们在操作redis时，时刻要明白redis在一个瞬间只会执行一条命令，不会执行两条命令 单线程为何快？ 纯内存 非阻塞IO 避免线程之间的切换和竞态消耗 stringstring的value可存储普通字符串、数值、二进制、JSON。使用场景：缓存、计数器、分布式锁 基本命令 get、set、del（O1）： 12345678# 获取key对应的valueget key # 设置key-valueset key value# 删除key-valuedel key 计数命令 incr 、decr、incrby、decrby（O1）： 123456789101112# key自增1，0开始incr key# 相反decr key# 期望自增指定值，key自增kincrby key k# 相反decrby key k# 浮点数的自增3.5incrbyfloat key 3.5 其他set命令 set、setnx、setxx 12345678# 不管key是否存在，都设置set key value# key不存在才进行设置（add操作）setnx key value# key存在才设置（update操作）set key value xx 批量处理命令：mget mset 12345# 批量获取keymget key1 key2 ..# 批量设置key-valuemset key1 value1 key2 value2 ... 如果传输n次get命令，那么 n次get = n次网络时间 + n次命令时间 如果1次将命令批量传输给服务端，那么 1次mget = 1次网络时间 + n次命令时间 其他命令 12345678# 为key设置新的值，并返回之前的值getset key newvalue# 为key追加值append key value# 返回字符串长度strlen key 使用场景： 记录网站每个用户个人主页的访问量 1incr userid:pageview 缓存视频的基本信息（数据源在mysql） 1231. 从redis中取数据，存在数据直接返回，则不需要访问mysql2. 若不存在，访问mysql，获取到数据，加入到redis缓存3. 当下此访问此接口时，会从redis中访问 hashhash键值结构： 基本命令 12345678# 获取hash key对应的field的valuehget key field# 设置hash key对应file的valuehset key field value# 删除hash key对应file的valuehdel key field value hexists、hlen 12345# 判断hash key是否有filedhexists key filed# 获取hash key fiedl的数量hlen key 批量操作 12345# 批量获取hash key的一批field对应的值hmget key field1 field2...# 批量设置hash key的一批field valuehmset key field1 value2 ... 其他命令 12345678# 返回hash key对应的所有field和valuehgetall key# 返回所有的值hvals key# 返回所有的fieldhkeys key 使用场景 和string 的使用场景类似、数据缓存等 listlist 队列结构：有序、可重复、左右两边插入弹出 增加操作 12345678# 从列表左边插入值lpush key val1 val2# 从列表右边插入值rpush key val1 val2 # 在列表指定值的前|后插入新的值linsert key before|after value newvalue 删除操作 123456789101112# 从列表左边弹出一个元素lpop key# 从列表右边弹出一个元素rpop key# 从列表删除所有value相等的值# count=0删除所有、count&gt;0左边开始删除、count&lt;0右边开始删除lrem key count value# 保留指定索引内的列表元素ltrim key start end 查询操作 12345678# 获取索引内范围的元素lrange key start end(包含)# 根据指定索引获取元素lindex key index# 列表长度llen key 修改操作 12# 设置指定索引的值lset key index newvalue 使用场景 用户抢购进入排队状态（加入队列） 你关注的人更新文博（LPUSH可看到最新状态、lrange范围查询） set集合特点：无序、无重复、可进行集合间操作（交集、并集） 基本命令 1234567891011121314151617181920# 向集合key添加元素（如果元素存在添加失败）sadd key element# 删除集合中某个元素srem key element# 计算集合sizescard key# 判断元素是否在在集合中存在sismember key element# 从集合中挑选一个元素（不删除）srandmember key# 从集合中弹出一个元素(删除)spop key # 取出集合中所有元素smembers key]]></content>
  </entry>
  <entry>
    <title><![CDATA[redis初识]]></title>
    <url>%2F2019%2F04%2F05%2Fredis%E5%88%9D%E8%AF%86%2F</url>
    <content type="text"><![CDATA[引入redis是一款开源的nosql,基于key-value的键值对存储服务系统，支持多种数据结构。 redis的特性 多种数据结构 其中还扩展数据结构有 bitmaps：位图 ，（布隆过滤器可使用位图来实现） hyperloglog：超小内存唯一值计数（12k geo：地理信息位置 速度快 redis可达到10w读写速度，将数据存储到内存中，使用C语言编写（50000 line），单线程 持久化 功能丰富 主从复制 高可用、分布式 redis使用场景 缓存系统 先从cache中获取数据，如果有返回数据，没有则从数据库中取数据并加入到缓存中 计数器 消息队列系统 排行榜 社交网络 实时系统 redis的安装 http://download.redis.io/releases/ 123456# 下载wget http://download.redis.io/releases/redis-3.0.7.tar.gz# cd到redis目录编译，会产生redis.conf、src等文件make# 安装到指定目录产生bin文件make install PREFIX=/install/redis bin目录下6个可执行文件 redis-server：redis服务器 redis-cli：redis命令行客户端 redis-benchmark：基准测试 redis-check-aof：持久化aof文件修复工具 redis-check-dump：持久化rdb文件修复工具 redis-sentinel：sentinel服务器（2.8version） 三种启动redis方式 redis-serve（默认配置） redis-serve – port 6380（动态参数启动，默认端口是6379） redis-serve &amp;confipath（参与配置文件启动）]]></content>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2019%2F04%2F04%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
